<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[平静和沉淀]]></title>
      <url>%2F2017%2F05%2F17%2Fcalm-down%2F</url>
      <content type="text"><![CDATA[焦虑。 其实我觉得我有毅力做一件事，但是太急功近利了，没有耐心。而且，懒。这个是人的天性啊，但是为了要达到你想追求的目标，就必须要和天性斗争。不能老是拿顺其自然的话语来安慰自己，目前在自己身上这两者是竞品。 在这个追求快速制胜的时代，连NBA联盟都流行小球，快准狠的风格了，做一只马刺队一样的清流还是很难的啊。 毕竟人家波波老爷子用了20年打造的文化基奠。 浮躁。 受大环境影响，往往迷失了自己。我感觉现在虚活着，什么都想干，但不知道干嘛。 静。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[install hadoop]]></title>
      <url>%2F2017%2F04%2F14%2Finstall-hadoop%2F</url>
      <content type="text"><![CDATA[借鉴的文档： 【hadoop】ssh localhost 免密码登陆（图解）主要就是先要有sudo权限，如果没有用root账户的时候。How To Create a Sudo User on CentOS 这个usermod命令后，要重启终端。 Have you logged in again after the usermod? IIRC, groups are only looked up when you log in (e.g. opened a new terminal window). 然后就是那两个命令，创建isa-pub.主要就是要有权限。 关闭SElinux CentOS7中关闭selinux这个设置后重启没用，还是开着的]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[vim的字符编码]]></title>
      <url>%2F2017%2F04%2F10%2Fvim-encoding%2F</url>
      <content type="text"><![CDATA[vim中的编码vim 有四个跟字符编码方式有关的选项，encoding、fileencoding、fileencodings、termencoding (这些选项可能的取值请参考 Vim 在线帮助 :help encoding-names) encoding: Vim 内部使用的字符编码方式，包括 Vim 的 buffer (缓冲区)、菜单文本、消息文本等。默认是根据你的locale选择.用户手册上建议只在 .vimrc 中改变它的值，事实上似乎也只有在.vimrc 中改变它的值才有意义。你可以用另外一种编码来编辑和保存文件，如你的vim的encoding为utf-8,所编辑的文件采用cp936编码,vim会自动将读入的文件转成utf-8(vim的能读懂的方式），而当你写入文件时,又会自动转回成cp936（文件的保存编码). fileencoding: Vim 中当前编辑的文件的字符编码方式，Vim 保存文件时也会将文件保存为这种字符编码方式 (不管是否新文件都如此)。 fileencodings: Vim自动探测fileencoding的顺序列表， 启动时会按照它所列出的字符编码方式逐一探测即将打开的文件的字符编码方式，并且将 fileencoding 设置为最终探测到的字符编码方式。因此最好将Unicode 编码方式放到这个列表的最前面，将拉丁语系编码方式 latin1 放到最后面。 termencoding: Vim 所工作的终端 (或者 Windows 的 Console 窗口) 的字符编码方式。如果vim所在的term与vim编码相同，则无需设置。如其不然，你可以用vim的termencoding选项将自动转换成term的编码.这个选项在 Windows 下对我们常用的 GUI 模式的 gVim 无效，而对 Console 模式的Vim 而言就是 Windows 控制台的代码页，并且通常我们不需要改变它。 最主要的就是关注一下encoding和fileencoding，总结就是前者是vim内部处理字符的用的。vim中可能会处理不一样的编码的字符，然后都化为统一的格式进行处理是最明智的。后者是文件的编码格式。 上面也说的很清楚了，文件读入时，若是fileencoding和encoding不一致，会先转化成encoding，统一处理，最后保存的时候再转化回fileencoding。转化的过程就是通过unicode这个第二层过渡。看编码总结 vim的多字符编码方式支持工作流程 Vim 启动，根据 .vimrc 中设置的encoding 的值来设置 buffer、菜单文本、消息文的字符编码方式。 读取需要编辑的文件，根据fileencodings 中列出的字符编码方式逐一探测该文件编码方式。并设置fileencoding为探测到的，看起来是正确的 字符编码方式。 对比fileencoding和encoding的值，若不同则调用iconv将文件内容转换为encoding所描述的字符编码方式，并且把转换后的内容放到为此文件开辟的buffer里，此时我们就可以开始编辑这个文件了。注意，完成这一步动作需要调用外部的iconv.dll，你需要保证这个文件存在于$VIMRUNTIME或者其他列在PATH环境变量中的目录里。 编辑完成后保存文件时，再次对比fileencoding和encoding的值。若不同，再次调用iconv将即将保存的 buffer 中的文本转换为fileencoding所描述的字符编码方式，并保存到指定的文件中。同样，这需要调用iconv.dll由于Unicode能够包含几乎所有的语言的字符，而且Unicode的UTF-8编码方式又是非常具有性价比的编码方式 (空间消耗比UCS-2小)，因此建议encoding的值设置为utf-8。这么做的另一个理由是encoding设置为utf-8时，Vim 自动探测文件的编码方式会更准确 (或许这个理由才是主要的 ;)。我们在中文 Windows 里编辑的文件，为了兼顾与其他软件的兼容性，文件编码还是设置为GB2312/GBK 比较合适，因此fileencoding建议设置为 chinese (chinese 是个别名，在 Unix 里表示 gb2312，在 Windows 里表示cp936，也就是 GBK 的代码页)。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[用r做一个简单的统计词频的程序]]></title>
      <url>%2F2017%2F04%2F08%2Fr-text-mining-word-frequency%2F</url>
      <content type="text"><![CDATA[要求：假设文件1中有内容a b c c,文件2中有a b d现在要统计成如下的样子： a b c d 文件1 1 1 2 0 文件2 1 1 0 1 用到R中的table函数 预备table table uses the cross-classifying factors to build a contingency table of the counts at each combination of factor levels. 123456&gt; f1[1] "a" "b" "c" "c"&gt; table(f1)f1a b c 1 1 2 文档中说了table使用facter中的level来生成统计项，然后记录各项出现的次数。 factor123set.seed(102) # This yields a good illustration.x &lt;- sample(1:3, 15, replace=TRUE)education &lt;- factor(x, labels=c("None", "School", "College")) 123456&gt; x[1] 2 2 3 2 1 2 3 1 3 2 3 3 3 2 2&gt;education[1] School School College School None School College None College[10] School College College College School School Levels: None School College 上面可以看出labels就是实现一种转化么。默认是lables = levels(x) 解题思路因为文件1中没有d，但统计的时候还是要有它的项，当然值是0。所以我们要有一个level是包含所有的项的1234&gt; table(factor(f1,levels=c('a','b','c','d')))a b c d 1 1 2 0 这里有另一个话题就是读取文件还可以用readLines函数，不过12&gt; readLines(file.choose())[1] "a b c c" 可以看到，这是一个向量，scan读进来直接是分开的。所以如果用readLines的话，还要用strsplit函数进行分割，就和python中的split函数一样还有我这里用file.choose()来手动选择文件，因为在mac上不知道为什么绝对路径传进去都有问题。[Todo] 简单情况现在将情况简单化一点，现在假设只有一个文件，现在统计的文件1等就是第1行，依次类推。 先得到所有的词，每个词是一个元素，像scan那样12345678dat &lt;- readLines(file.choose())rownum &lt;- length(dat)word &lt;- NULLfor(i in 1:rownum)&#123; di &lt;- dat[i] di &lt;- strsplit(di,split=' ')[[1]] word &lt;- c(word,di)&#125; 得到所有的项其实也就是数学里面的集合么。估计Levels就是集合实现的123&gt; factor(word)[1] a b c c a b dLevels: a b c d 这样就得到了所需要的所有项a,b,c,d 那其实因子a b c c a b d它是按顺序来的，那其实对第一行的统计就可以table(factor(word[1:len_row_1]))那len_row_1怎么得来，就可以在原来的for循环中直接用length计算出12345678910dat &lt;- readLines(file.choose())rownum &lt;- length(dat)len &lt;- rep(0,rownum) #word &lt;- NULLfor(i in 1:rownum)&#123; di &lt;- dat[i] di &lt;- strsplit(di,split = ' ')[[1]] word &lt;- c(word,di) len[i] &lt;- length(di) #&#125; 多了有#号标记的这两行 统计事先先生成rownum行然后length(levels(factor(word)))列的矩阵，之后往里面塞就行了123f &lt;- factor(word)l &lt;- levels(f)m &lt;- matrix(0,nrow = rownum,ncol = length(l)) 1234&gt; m [,1] [,2] [,3] [,4][1,] 0 0 0 0[2,] 0 0 0 0 因为我们现在有了len12&gt; len[1] 4 3 4意思是文件第一行的元素个数，3就是第二行的然后我们可以用数组的知识，也就是类似c语言中的两个指针来移动了123456start &lt;- 1for(i in 1:rownum)&#123; # 这里我一开始忘了写1:，只是rownum，导致一直bug end &lt;- start+len[i] - 1 m[i,]&lt;-table(factor(word[start:end],levels = l)) start &lt;- end+1&#125; 1234&gt; m [,1] [,2] [,3] [,4][1,] 1 1 2 0[2,] 1 1 0 1 弄的好看一点12345&gt; colnames(m)&lt;-c('a','b','c','d')&gt; m a b c d[1,] 1 1 2 0[2,] 1 1 0 1 复杂情况就是要前面的步骤，要读取多个文件。其实后面步骤都是一样的。只是一个是将多文件的内容放在一个文件的每一行，同样我们需要知道所有的项，也就是levels。多出来的工作也就是我们要读多个文件，然后进行拼接而已。没什么难度，只是代码的优雅程度不一样而已。 R下的文件目录操作 dir.create(&#39;newdir&#39;)：创建文件夹 unlink(&#39;directory&#39;,recursive=TRUE):删除文件夹，若有文件一并删除 file.create(&#39;newfile&#39;): 创建一个新文件，若存在则会覆盖原文件 cat(&#39;hello world&#39;,file=&#39;newfile&#39;,append=TRUE): 文件加入一行内容 file.append(&#39;file1&#39;,&#39;file2&#39;): 将file2的内容添加到file1的后面 file.copy(&#39;source&#39;,&#39;des&#39;):拷贝文件source到文件des file.show(&#39;filename&#39;)： 显示文件内容 file.remove(&#39;filea&#39;,&#39;fileb&#39;): 删除文件 list.files()：显示当前工作目录下的文件列表 这里可以借助list.files()来搭桥。知道了目录下的文件列表，我们就可以用循环了 合并数据123456789f &lt;- function(x)&#123; data &lt;- readLines(x) return(strsplit(data,split=' '))&#125; dir_path &lt;- '/Users/Crayon_277/Develop/Project/R/homework/3'files &lt;- list.files(dir_path,pattern = '[0-9]+.txt$',full.names = T) result &lt;- lapply(files,f) list.files中的full.names参数为false的时候12&gt; files[1] "1.txt" "2.txt" 当为T的时候123&gt; files[1] "/Users/Crayon_277/Develop/Project/R/homework/3/1.txt"[2] "/Users/Crayon_277/Develop/Project/R/homework/3/2.txt" 区别就一目了然了 123456789&gt; result[[1]][[1]][[1]][1] "a" "b" "c" "c"[[2]][[2]][[1]][1] "a" "b" "d" 然后可以在用for语句拼接，或者一开始直接用for遍历 lapply returns a list of the same length as X, each element of which is the result of applying FUN to the corresponding element of X.lapply就类似python中的map]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[用R画出下面这样子的形式的图]]></title>
      <url>%2F2017%2F04%2F07%2Fr-lines%2F</url>
      <content type="text"><![CDATA[用到什么学什么 plot的使用官方的description Generic function for plotting of R objects. For more details about the graphical parameter arguments, see par. For simple scatter plots, plot.default will be used. However, there are plot methods for many R objects, including functions, data.frames, density objects, etc. Use methods(plot) and the documentation for these. plot(x, y, …) 这里先用到plot的一个type参数 what type of plot should be drawn. Possible types are “p” for points, “l” for lines, “b” for both, “c” for the lines part alone of “b”, “o” for both ‘overplotted’, “h” for ‘histogram’ like (or ‘high-density’) vertical lines, “s” for stair steps, “S” for other steps, see ‘Details’ below, “n” for no plotting. 这里有个&quot;n&quot;的参数值可以选择，也就是什么都不会打印，先看个例子1234x &lt;- seq(-pi,pi,length = 100)plot(x,sin(x),type='p')plot(x,sin(x),type='l')plot(x,sin(x),type='n') 分别是这样色儿的看最后一个，也就是什么都没画。什么都没有有什么用！？存在即合理，它可以用来弄一个画布，然后再在上面画其他图形 比如：1&gt; plot(c(0,10),c(0,10)) 这里plot的x,y参数是用向量指定的，x坐标的放一起，y坐标的放一起，其实坐标点是(0,0),和(10,10)，在这两个坐标上，默认是画了两个小圆圈。但是如果我想要一个有坐标系的这样的一个画布，我就可以 1&gt; plot(c(0,10),c(0,10),type='n') 而这里x,y的作用就是撑开画布坐标系的大小，我如果plot(c(0,50),c(0,50),type=&#39;n&#39;)，那坐标系就变大了。 lines A generic function taking coordinates given in various ways and joining the corresponding points with line segments.lines(x, …) Default S3 method:lines(x, y = NULL, type = “l”, …) 就是根据像plot那样x,y解释的意思，将两点连起来，同时用type指定的样式画出这点线这个说法有点不正确，好像是说type指定的是线的样式，比如实线，虚线，不是的。lty这个参数才是指定“线样式的” 我这里看到了lines(x,...)说明可以不用指定y，那画出来是什么？？123456&gt; plot(c(0,10),c(0,10),type='n')&gt; lines(c(0,1))&gt; lines(c(5,9))&gt; lines(c(2,4))&gt; lines(c(10,1))&gt; lines(c(4,7)) 可以看出来给出的c(a,b)，a,b都是表示纵坐标，默认好像横坐标是1到2，那这样就是画(1,a)到(2,b)的线？至少实验出来是这样的1&gt; lines(c(4,7,6)) 三个向量元素，那上面的猜测是对的，现在是画(1,a),(2,b),(3,c)的线段，估计向量元素增多，就是横坐标到4，5，6了吧 lines 的type lines(x, y, type = “l”, …)typecharacter indicating the type of plotting; actually any of the types as in plot.default. 说是根据plot的type来，一开始我觉得这不跟lty参数重复了么，其实两个是不一样的1234&gt; plot(c(0,10),c(0,10),type='n')&gt; lines(c(2,4),c(3,8),type = "s")&gt; lines(c(6,7),c(3,8),type = "s",lty=2)&gt; lines(c(6,7),c(3,8),type = "l",lty=3) 当type=&quot;s&quot;是，画的是折线！！！，s解释为step，相当于画的是曼哈顿路径。lty才是线是什么样子的形式的。而type应该是画的什么什么形状吧，不知道怎么描述 lty的实验1234plot(c(1,6),c(1,1),type='l',lty=1,ylim=c(0,8))for(i in 2:6)&#123; lines(c(1,6),c(i,i),type = 'l',lty=i)&#125; text在画布上写文本吧直接看实验123&gt; plot(c(0,10),c(0,10),type='n')&gt; text(c(5,1),c(3,3),1)&gt; text(c(5,8),c(2,3),c("A","B")) points画点。主要是pch,cex这两个参数有点意思 pchplotting ‘character’, i.e., symbol to use. This can either be a single character or an integer code for one of a set of graphics symbols. The full set of S symbols is available with pch = 0:18, see the examples below. (NB: R uses circles instead of the octagons used in S.) Value pch = “.” (equivalently pch = 46) is handled specially. It is a rectangle of side 0.01 inch (scaled by cex). In addition, if cex = 1 (the default), each side is at least one pixel (1/72 inch on the pdf, postscript and xfig devices). For other text symbols, cex = 1 corresponds to the default fontsize of the device, often specified by an argument pointsize. For pch in 0:25 the default size is about 75% of the character height (see par(“cin”)). cexcharacter (or symbol) expansion: a numerical vector. This works as a multiple of par(“cex”). 目前我的理解就是pch就是点的样式，cex就是指定大小 pch 实验12345678plot(c(0,10),c(0,10),type='n')line.draw = 9for(i in 1:25)&#123; if((i-1) %% 5==0)&#123; line.draw = line.draw - 1 &#125; points((i-1)%%5,line.draw,pch=i)&#125; 回到题目画这样的一个三角形。思路就是用points画大一点的圆圈，text来写A这中标签，然后lines来画线，没什么难度12345678910plot(c(0,10),c(0,10),type = 'n')lines(c(3,5),c(4,9),type = 'l',lty=1)lines(c(5,7),c(9,4),type = 'l',lty=1)lines(c(3,7),c(4,4),type = 'l',lty=1,xlim=c(2.5,6.7))points(5,9,pch=1,cex = 5)text(5,9,'A')points(3,4,pch=1,cex = 5)text(3,4,'B')points(7,4,pch=1,cex = 5)text(7,4,'C') 不过我这样，太啰嗦了啊 R中的最常用的对象就是向量，很多运算都支持向量操作。可以用向量123456plot(c(0,10),c(0,10),type = 'n')x &lt;- c(3,5,7)y &lt;- c(4,9,4)points(x,y,cex=5)text(x,y,c("A","B","C"))lines(x,y,type='l') lines(x,y) , 这个x，y的坐标，相当于这里，两个坐标的x都提取出来到x，两个坐标的y都提取出来到y，相当于起始点终点的x坐标放一起，起始点终点的y坐标放一起.感觉python中的map(None,x,y) 后就是[(3,4),(5,9),(7,4)] 其实就是各点的坐标 但是是不闭合的，为什么，其实两个组合确定一条线，可能lines中的向量，x先是(3,5),在是(5,7),y对应，但后面没有回去(7，3)。要手动添加1lints(c(x,3),c(y,4),type='l') 这样就和开篇的fancybox的图片里面一样了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[自我约束-开会]]></title>
      <url>%2F2017%2F04%2F06%2Fself-discipline-meeting%2F</url>
      <content type="text"><![CDATA[如果不能做到以下，那么你就把你的屁股老老实实的坐到那该死的团会上，体验如坐针毡的感觉。 自己真的做的惜时如金的时候，真的做到压榨每一分每一秒的时候，真的做到push self的时候，当感觉到跑在计划前面的时候。 不能不趁三十之前，立志猛进也 野蛮生长]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Intro to hadoop and MapReduce -- hdfs & mapreduce (二)]]></title>
      <url>%2F2017%2F04%2F06%2Fhdfs-mapreduce%2F</url>
      <content type="text"><![CDATA[Quiz： Is there a problem [x] network failure [x] disk failure on datanode [] not all datanode used (Why do you think that all nodes have to be used. What if you have hundreds of Data Nodes?) [] block sizes differ (If block sizes would have to be the same, what would happen if the file could not be divided in same size blocks?) [x] disk failure on namenode what if namenode had hardware problem Quiz: any problems now [x] data inaccessible (when network failure) [x] data lost forever (when disk failure) [] no problem so, depends.]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Intro to hadoop and MapReduce -- Big Data(一)]]></title>
      <url>%2F2017%2F04%2F04%2Fbig-data%2F</url>
      <content type="text"><![CDATA[Definition of Big Data可能有些人认为几个terebytes的数据量是大数据，但这个量不是标准的，所以一个合理的定义是 It’s data that’s too big to be processed on a single machine. Quiz: Chanllenges with Big Data- most data is worthless data is created fast data from different sources in various formats most data is not worthless, but actually does have a lot of value. The 3 V’s of big dataVolume总结：量大。需要考虑那些能提供有用信息 But in order to store it, you’ll need a way to scale your storage capacity up to massive volume. Hadoop, which stores data in a distributed way across multiple machines, does that Variety就是说我们如果用像MySQL,Oracle这种数据库，数据必须要适合他们的格式，但是现在我们处理的数据很大部分都是unstructured或者是semi-structured.比方说现在打客服热线不都有一个提示说是会录音，一种存储是语音识别成文字保存起来，另一种是直接存储成mp3格式然后让相应的软件解码如果后面要用的话。那hadoop不管你的数据是什么样的格式， you can just store the data in its raw format, and manipulate and reformat it later. example Sometimes the most unlikely data can be extremely useful and lead to savings due to better planning. 比方说现在要通知附近的货车到中心取货，基于位置的系统就会通知最近的车辆过来。但往往，这个最近，不是最佳的选择。也许那里有交通堵塞，也许最近的车辆过来需要过羊肠小道，那里的路比较难走，也许是要绕一大圈才能到中心。更需要考虑的是，这辆车上也许没有足够的空间了，这辆车没有油了。所以以下都是需要考虑的 Current GPS location fromi all trucks Current itineraries for all trucks Current traffic speed in related areas as reported by services such as waze Current load of trucks by volume and weight Fuel efficiency of the different vehicles The world we live in is extremely complex, and there are a lot of variables to consider that you can tweak to get large benefits. Velocity实时更新？？If we can’t store it as it arrives, we’ll end up discarding some of it, and that’s what we absolutely want to avoid. history of hadoop来自hadoop 之父 Doug Cutting So, let me tell you how Hadoop came to be. About ten years ago in around 2003, I was working on an Open Source web search engine called Nutch, and we knew it needed to be something very scalable, because the Web was you know, billions of pages. terabytes, petabytes, of data, that we needed to be able to process, and we set about doing the best job we could and it was tough. We got things up and running on four or five machines, not very well, and around that time Google published some papers about how they were doing things internally. Published a paper about their distributed file system, TFS. and about their processing, framework, MapReduce. So my partner and I, at the time, in this project, Mike Cafarella. said about trying to reimplement these in Open Source. So that more people could use them than just folks at Google. Took us a couple of years, and we had Nutch up and running on, instead of four or five machines, on, 20 to 40 machines. It wasn’t perfect, it wasn’t totally reliable, but it worked. And we realize that to get it to the point where it was scaled to thousands of machines, and be as bullet proof as it needed to be, would take more than just the two of us, working part time. Around that time, Yahoo approached me and said they were interested in investing in this. So I went to work for Yahoo in January of 2006. First thing I did there, was, we took the parts of Nutch that were a distributed computing platform, and put them into a separate project. A new project christened Hadoop. Over the next couple years, with, Yahoo’s help, and the help of others, we took Hadoop, and really got it to the point where it did scale to petabytes, and running on thousands of processors. And doing so quite reliably. It spread to lots of companies, and mostly in the Internet sector, and became quite a success. after that, we, we started to see a bunch of other projects grow up around it. And Hadoop’s grown to be the kernel of a, which, pretty much an operating system for big data. We’ve got tools that, allow you to, more easily do, MapReduce programming, so, you can develop using SQL or a data flow language called Pig. And we’ve also got the beginnings of higher­level tools. We’ve got interactive SQL with Impala. We’ve got Search. and so we’re really seeing this develop to being a general purpose platform for data processing. that scale’s much better and that it is much more flexible than anything that’s, that’s, else is out there. hadoop clusterhadoop存储数据的方法是一个分布式的文件系统叫做HDFS。处理数据是通过MapReduce。核心思想就是将数据分块，然后在集群中存储，也就是各个计算机搭建的一个网络吧。那这样的好处就是我们不用从中心取数据然后再操作，我们直接在集群中就地处理数据，后续还可以继续扩大集群的规模 hadoop Ecosystem Core hadoop consists of HDFS and MapReducehadoop的生态系统。以hadoop为核心的，打造的周边产品，主要的目的就是降低使用hadoop的难度和门槛。比如编写MapReduce的程序不是一件容易的事，有些没有编程经验的就可以用Pig，Hive，这种类似SQL语句来操作数据，但这两个都是将语句翻译为MapReduce然后再到集群上执行。因为Hive和Pig它们本质上还是MapReduce的工作量，所以花费的时间可能更多。所以另一个开源项目Impala，它是允许直接用SQL语句来操作数据，不用经过MapReduce（具体现在我也不懂），所以这样就很快了其他的也就类似了。 Cloudera hadoop版的其实就是把这些都给你打包好了，你不用在一个一个去弄了。 核心还是hadoop的HDFS和MapReduce]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[seven-principle]]></title>
      <url>%2F2017%2F04%2F04%2Fseven-principle%2F</url>
      <content type="text"><![CDATA[自带鸡血，能源源不断地给自己充电，遇到打击能迅速恢复，哪怕这种打击沉重而有力，也就是，抗压能力强。 不能给自己设限，既没有上限，也没有下限，凡事能想到的事，都敢做，给联合国秘书长写信也没啥不敢的 格局大，顺势而为.胸怀达到全宇宙，又能找到把猪吹上天的风口，从来站在更大的地位上思考问题，绝不想同事蹭吃了一盒酸奶之类的小时； 对自己高标准，永不满足，一旦自己陷入舒适圈，马上调整自己，给自己提更高的要求，让自己不舒适，让自己不高心，让自己不痛快，给自己找别扭，上升到更高的level 做不可替代的角色 极度自律，执行力超强（强调）。别跟我说自律，其实就是一个人呆着的时候，不放纵自己，做应当做的是，不玩游戏，不看电视剧，不在低附加值的事情上浪费时间。同时，你不能想着，我要有时间就好了，然后每天还能睡到中午12点，然后慵懒的发发朋友圈，谈谈诗和远方。 具备逆向思维，善于创新，说白了，就不跟大家一样思考，常人怎么想，总是反着想，具备创新精神。剑走偏锋]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[自我约束-你好]]></title>
      <url>%2F2017%2F03%2F30%2Fself-discipline%2F</url>
      <content type="text"><![CDATA[坐公交好几次都碰见她，一位穿着比较啰哩啰嗦的，时尚的。我想认识她 今天，我在看nba勇士队的比赛，她突然过来，没有一丝丝准备，都不知道我发型有没有乱的，问我能不能帮她刷下公交卡，她转支付宝给我，我下意识的说不用，现在老后悔了。 不过，从我过往的经验看，大多是我自己自作多情，人家也只是想寻求帮助，不要想太多了，今天不是你也是其他人。 但还是挺开心的，借此聊了一会，得知是大三外语系的。哈哈哈 这次的自我约束：如果你能静下心来，不要胡思乱想。进入自己的zone, 认认真真做自己的事情，专注！！看缘分，如果能做到专注，那么下次遇见的时候就厚着脸皮要个联系方式吧，不然就永远当个路人]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[python name and values]]></title>
      <url>%2F2017%2F03%2F29%2Fpython-name-and-values%2F</url>
      <content type="text"><![CDATA[阅读 Facts and myths about Python names and values 做的摘记内容不是很深，只是这里面提到了一些需要注意的点。最主要还是name和value的区别 Fact: Names have no type, values have no scope. Just as names have no type, values have no scope. When we say that a function has a local variable, we mean that the name is scoped to the function: you can’t use the name outside the function, and when the function returns, the name is destroyed. But as we’ve seen, if the name’s value has other references, it will live on beyond the function call. It is a local name, not a local value. 翻译： 就跟名字没有类型一样，数值是没有作用范围的。当我们说一个函数有局部变量的时候，我们只是说的是名字只在函数作用域中起作用而已，你不能在函数外使用这个名字，当函数返回的时候，这个名字也就摧毁了。但是，如果这个名字指向的数值还有其他引用，它就会继续生存下去，不管这个函数了。局部变量，而不是局部数值。 Fact: Values can’t be deleted, only names can. Python’s memory management is so central to its behavior, not only do you not have to delete values, but there is no way to delete values. You may have seen the del statement: 12nums = [1, 2, 3]del nums This does not delete the value nums, it deletes the name nums. The name is removed from its scope, and then the usual reference counting kicks in: if nums’ value had only that one reference, then the value will be reclaimed. But if it had other references, then it will not. Fact: Assignment never copies data. Mutable means that the value has methods that can change the value in-place. Immutable means that the value can never change, instead when you think you are changing the value, you are really making new values from old ones. 比如：12x = 3y = x x和y只是一起指向了3而已，并没有给y再来一个3。这里x,y是name，3是value上面说到的Mutable是什么意思，也就是因为这个赋值不拷贝数据的特性，当y变了的时候，比如y+=1，那x还变不变？这里就要考虑到可变类型和不可变类型了 Immutable values: numbers strings tuples Mutable values: lists dicts user-defined objects 那在上面y+=1之后，其实是给y重新reference到了4 关于mutable的直接截图： Fact: Python passes function arguments by assigning to them.123def my_func(x,y) return x+yprint(my_func(8,9)) The names x and y are local to the function, so when the function returns, those names go away. But if the values they refer to are still referenced by other names, the values live on. 注意，这里就出现name和value的区别了，可以这样理解，value就是一个实物，name只是这个实物的标签，我可以贴很多标签，而看到这个标签，我就联想到这个实物，实物可以有多个标签，一个标签只能对应一个实物。 1234567def augment_twice(a_list,val): a_list.append(val) a_list.append(val)nums = [1,2,3]augment_twice(nums, 4)print(nums) #[1,2,3,4,4] 虚线框表示本地name在一个新的frame里面，而参数传递只是一种赋值操作，a_list “指向” nums指向的value,而list类型是可变数据类型，所以任何name对它的改变都是就地的，可以通过id()操作来查看是否改变了地址 另外一个程序 12345def augment_twice_bad(a_list,val): a_list = a_list + [val,val]nums = [1,2,3]augment_twice_bad(nums,4)print(nums) #[1,2,3] 这个跟上面的程序就不同在函数里面一个是用.append()来增加元素，一个则用加法然后赋值，赋值，赋值，重要的事情说三遍，这是个赋值操作，一旦出现赋值，就相当于等式左边的namerebind出现在等式右边的value It’s really important to keep in mind the difference between mutating a value in place, and rebinding a name. augment_twice worked because it mutated the value passed in, so that mutation was available after the function returned. augment_twice_bad used an assignment to rebind a local name, so the changes weren’t visible outside the function. 其他的 facts, myths都知道了，上面的需要注意一下就可以了。过]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[用R来找最大连通子图]]></title>
      <url>%2F2017%2F03%2F25%2Fr-maximal-connected-subgraph%2F</url>
      <content type="text"><![CDATA[求上图的最大连通子图，其实就是图的遍历，图的遍历有深度优先和广度优先图有很多种对应的存储结构，在R里面最简单的就是邻接矩阵了。 -update- 用深度优先搜索做 在深度优先里面涉及到的R中的全局，局部变量 构造邻接矩阵1234567m &lt;- matrix(0,5,5)m[1,2] &lt;- 1m[1,3] &lt;- 1m[2,3] &lt;- 1m[4,5] &lt;- 1m &lt;- m + t(m) 1234567&gt; m [,1] [,2] [,3] [,4] [,5][1,] 0 1 1 0 0[2,] 1 0 1 0 0[3,] 1 1 0 0 0[4,] 0 0 0 0 1[5,] 0 0 0 1 0 主要也就是m&lt;-m+t(m)这一步，因为是无向图，是对称矩阵，可以先构造一半然后与转置相加。这是对称矩阵的性质的应用！！ 在线性代数中，实对称矩阵是一个方形矩阵，其元素都为实数，且转置矩阵和自身相等实对称矩阵 广度优先遍历主要思想就是它分两个部分，一个部分保存已经访问过的，一个部分是未访问的，未访问部分是用一个队列来存储，每次从队头出一个元素i，然后将这个元素的能够够到的节点依次加到队尾去。这一步其实就是邻接表中的第i行中为1的元素加进来 先考虑简单的情况，从第1个节点出发，寻找包含1的最大联通子图，其实就是1能够直接或间接够到的所有节点，在图中我们可以直观的看到是1，2，3，三个节点。 错误的代码12345678910111213visited &lt;- c(1)unvisited &lt;- m[1,]while(length(unvisited)&gt;0)&#123; now &lt;- unvisited[1] unvisited &lt;- unvisited[-1] candidate &lt;- m[now,] candidate &lt;- setdiff(candidate,visited) unvisited &lt;- union(candidate,unvisited) visited &lt;- c(visited,now)&#125;print(visited) 这里我犯了一个错误，unvisited &lt;- m[1,],这是unvisited里面保存的是什么？？12&gt; unvisited[1] 0 1 1 0 0 那我想要的是什么？应该是visisted中一开始是1,unvisisted中将1的邻接节点加进来是2,3,然后后面每次循环体内做的是队头元素出队列。但是加进来的元素应该是代表这个节点的符号,反应在矩阵中的应该是下标。矩阵里面存的其实是边信息，1代表有边,0代表无边，其实要的是0 1 1 0 0对应的下标！！！需要的是节点信息，这其实是两个概念 初始化我欠缺的也就是我知道我想要的是什么，但是不熟悉R语法，或者说不知道怎么用R语言来实现，虽然我熟悉python语法，但我也不能保证我能写出很优雅的代码，因为跟别人差就差在，他们不仅精通语法，还知道他们的性能，能有很多组合。 这里我需要的是读进来第1行矩阵元素有1的下标，取下标怎么取 有关下标的函数,目前只注意到下面的三个 which:Give the TRUE indices of a logical object, allowing for array indices. which.min:最小值的下标 which.max:最大值的下标 按照条条大路通罗马的理论，只要这个函数跟目标有点沾边的肯定能实现，只是看你的想象力，是否能突破天际因为which是需要一组逻辑向量，在R中逻辑值只有TRUE和FALSE,然后它会返回TRUE的下标只要把0 1 1 0 0转换为逻辑值就行了。查了一下12&gt; as.logical(c(-1,0,1,2))[1] TRUE FALSE TRUE TRUE 可以看到as.logical认为只有0是FALSE，其它为TRUE,这样路就通了12visited &lt;- c(1)unvisited &lt;- which(as.logical(m[1,])) 因为只要得到逻辑向量就可以了，那逻辑操作还可以用m[1,] == 1来得到逻辑向量值。这也可以还有没有其他方案？ 因为我注意到这里要么是0,要么是1,可以用向量1 2 3 4 5去乘，就得到了0 2 3 0 0,然后只要大于0的就行了123index &lt;- c(1:5)edge2node &lt;- index*m[1,]unvisited &lt;- edge2node[edge2node &gt; 0] edge2node[edge2node &gt; 0] 中的edge2node&gt;0计算完之后是逻辑值，然后用[]下标操作取逻辑值只为TRUE的元素 上面两种得到的12&gt; unvisited[1] 2 3 就是我想要的 遍历上面一开始写的错误的代码中也就是和上面一样的问题。只要改了这一部分就行了。12345678910while(length(unvisited)&gt;0)&#123; now &lt;- unvisited[1] unvisited &lt;- unvisited[-1] # 队头元素出队列 #candidate &lt;- m[now,] candidate &lt;- which(as.logical(m[now,])) candidate &lt;- setdiff(candidate,visited) unvisited &lt;- union(candidate,unvisited) # 将队头元素的邻接节点加入队列 visited &lt;- c(visited,now) # 将队头元素加入已访问的&#125;print(visited) 这里setdiff和union是集合运算，因为可以在图上直观的看到，1这个节点可以找到2,3。到2这个节点，可以找到1,3,但此时，1这个节点是已经访问了的，如果不处理，还是加进队列里面的话，那就不断在循环了！！！ setdiff是取差值，注意参数的位置，是将visited里面有的元素从candidate中消掉union是取并集，没什么好说的了还有一个intersect(x, y)就是取交集 最后的结果12&gt; print(visited)[1] 1 2 3 全图对每个节点进行同样的操作图的最大连通子图，那就对每个节点都进行上面的操作，然后图包含节点最多的就是这个图的最大联通子图了 12345678910111213141516171819202122max_node_num &lt;- 0maximal_connected_subgraph &lt;- NULLfor(i in 1:5)&#123; visited &lt;- c(i) unvisited &lt;- which(as.logical(m[i,])) while(length(unvisited)&gt;0)&#123; now &lt;- unvisited[1] unvisited &lt;- unvisited[-1] candidate &lt;- which(as.logical(m[now,])) candidate &lt;- setdiff(candidate,visited) unvisited &lt;- union(candidate,unvisited) visited &lt;- c(visited,now) &#125; current_node_num &lt;- length(visited) if(current_node_num &gt; max_node_num)&#123; max_node_num &lt;- current_node_num maximal_connected_subgraph &lt;- visited &#125;&#125;sort(maximal_connected_subgraph)print(m[maximal_connected_subgraph,maximal_connected_subgraph]) result:12345&gt; print(m[maximal_connected_subgraph,maximal_connected_subgraph]) [,1] [,2] [,3][1,] 0 1 1[2,] 1 0 1[3,] 1 1 0 深度优先遍历深度优先就是一条道走到底，无路可走的时候，及时浪子回头，然后又不听教诲又去浪到底，直到玩累了，回家的过程。 思路涉及到一个回朔。这样就需要一个parent_node来保存父节点的信息。这里我想到，是不是要回去的时候要重新计算父节点的邻接节点，因为这样才能知道其他节点啊。 同样还需要一个visited来保存已经访问过的节点。然后在访问完一个节点，要将这个节点加入visited中，在要遍历下一个节点的时候，需要取一个节点。那这个时候需要看这个节点是不是已经访问了。这里我想到了两个方案： 一个一个取。意思是下标操作，取一个对比一下是不是在visited中，可以用any(visited == current_node)如果是FALSE就是还未访问过。visisted == current_node返回的是一个逻辑向量，然后用any函数如果有一个是TRUE那返回值是TRUE，返回FALSE说明没有一个是相等的。 一下子全取出来。然后用集合运算，做差，然后再取出一个。 然后我用笔在纸上模拟的时候，发现这应该是个递归的过程。那visisted需要全局来维护，那这样函数体内就用循环可以了，遍历一个节点的所有邻接节点，然后对每一个节点再进入这个函数。这样就不需要parent_node来维护了，但是需要一个边界条件来终止递归。那就是一个节点的所有邻接节点都被访问过了。 发现的问题，visited全局变量1234567891011121314151617181920212223242526m &lt;- matrix(0,5,5)m[1,2] &lt;- 1m[1,3] &lt;- 1m[2,3] &lt;- 1m[4,5] &lt;- 1m &lt;- m + t(m)visited &lt;- c(1)dfs &lt;- function(current_node)&#123; #browser() # 调试用的 candidate_node &lt;- which(as.logical(m[current_node,])) candidate_node &lt;- setdiff(candidate_node,visited) #print(candidate_node) if(length(candidate_node) == 0)&#123; return(0) #这个0返回的没有意义的，随便都可以，只是单纯的结束 &#125; for(i in candidate_node)&#123; visited &lt;- c(visited,i) #访问i节点 dfs(i) #递归 &#125;&#125;dfs(1)print(visited) 上面的结果出错了12Error: evaluation nested too deeply: infinite recursion / options(expressions=)?Error during wrapup: evaluation nested too deeply: infinite recursion / options(expressions=)? 那就是递归没返回调试了一下，发现问题出现在visited上，dfs(i)进去的时候，理想中visited应该是全局变量，在循环中我将i节点加入已访问的节点中，但是发现递归进去的时候，candidate_node &lt;- setdiff(candidate_node,visited)这时候的visited值是1,就是初始值。可是为什么呢？？？ 内部函数在它的环境中查找visited的值（查找的顺序为：首先函数体的局部变量，参数；然后是外部函数中的局域变量，参数；最后是全局变量） 所以当在函数内做赋值的时候，相当于就建立了一个局部变量，那在第一层的时候visited &lt;- c(visited,i)这个语句还没执行到的时候，此时的visited在函数体内还没有定义！那找到的就是外部的变量，所以调试的时候看到的是1，那其实相当于因为在递归的时候可以看作都是进入自己的函数，所以每一层的visited都是独立的。 方案 1 : return(visited)1234567891011121314dfs2 &lt;- function(current_node,vis=NULL)&#123; candidate_node &lt;- which(as.logical(m[current_node,])) candidate_node &lt;- setdiff(candidate_node,visited) if(length(candidate_node) == 0)&#123; return(NULL) &#125; for(i in candidate_node)&#123; if(!any(visited == i))&#123; visited &lt;- c(visited,dfs2(i)) &#125; return(visited) &#125;&#125; 这么写有两个问题！！！第一个是有闭环的时候，因为我在前面的代码计算candidate_node的时候是依赖visited的，在每一层的函数进去后，因为前面说了，每一层的visited是独立的，所以在没有赋值之前，也就是没有在下一层return之前，用的都是外部的visited &lt;- c(1)这个值，所以这时候计算的candidate_node肯定是不正确的，不是我们想要的，因为不能正确判断是否邻接节点已经访问过。这是根源，所以导致了在下面for循环的时候，在闭环的情况下，因为没有正确的将已经访问的排除掉，而无限的递归。 第二个是分叉，就最简单的情况，1连接2,3,但后两个不连接，因为到2中，visited是外部的1，所以这里是恰好，凑巧，刚刚好candidate_node计算为空，返回，但是！！！返回的是空！这样visited &lt;- c(visited,dfs2(i))这个语句就没有起作用，追其根源那就是return写的不正确。一方面是这里连return(visited)都没执行到，相当于在2层这里直接返回NULL，但是并没有把2这个节点加入visited中。而且，即使不管上面的情况，在2饭后会，后面直接return(visited)了，函数直接退出了。3根本就没做。 试错：12345678m &lt;- matrix(0,3,3)m[1,2] &lt;- 1m[1,3] &lt;- 1m + t(m) -&gt; mvisited &lt;- c(1)print(dfs2(1)) 结果12&gt; print(dfs2(1))[1] 1 [todo] 使用return 写递归应该是可以的，那就是我整体的递归应该不是按照原来的思路了。但目前还没有想到怎么写 方案 2 : 这个visited当作一个参数传递就行了但是发现，这个只是值传递参数，不是引用传递，也就是参数变了，最后visited自己没有改变没有用啊，print(visited)就没用，最后结果就只是1 &lt;&lt;-解决然后我查到里面提到了&lt;&lt;-，可能这个操作符才是将变量复制到全局变量中去，不然&lt;-就在函数体内生成了一个同名的局部变量然后我就将上面的visited &lt;- c(visited,i)改为visited &lt;&lt;- c(visited,i)得到的结果是12&gt; print(visited)[1] 1 2 3 3 多了一个3，这个是因为在第一层的时候也就是current_node为1的时候，邻接节点是2,3,在for循环中，先进入2节点，此时可以遍历的只有3,然后进入3,访问完，回朔，此时应该是在这个图下1,2,3都是遍历完了的，但是回朔到1节点的时候，for循环还有一个3没执行，所以在for循环里面还要再加一个条件，看是否已经遍历过。123456for(i in candidate_node)&#123; if(!any(visited == i))&#123; visited &lt;&lt;- c(visited,i) #访问i节点 &#125; dfs(i) #递归&#125; 结果：12&gt; print(visited)[1] 1 2 3 寻找最大连通子图那就是再用一个for循环封装一下，和上面BFS一样。 完整代码12345678910111213141516171819202122232425262728293031323334353637m &lt;- matrix(0,5,5)m[1,2] &lt;- 1m[1,3] &lt;- 1m[2,3] &lt;- 1m[4,5] &lt;- 1m &lt;- m + t(m)max_length &lt;- 0maximal_connected_subgraph &lt;- NULLnode_num &lt;- length(m[,1])dfs &lt;- function(current_node,vis=NULL)&#123; candidate_node &lt;- which(as.logical(m[current_node,])) candidate_node &lt;- setdiff(candidate_node,visited) if(length(candidate_node) == 0)&#123; return(NULL) #这个0返回的没有意义的，随便都可以，只是单纯的结束 &#125; for(i in candidate_node)&#123; if(!any(visited == i))&#123; visited &lt;&lt;- c(visited,i) #访问i节点 &#125; dfs(i) #递归 &#125;&#125;for(i in 1:node_num)&#123; visited &lt;- c(i) dfs(i) print(visited) current_length &lt;- length(visited) if(current_length &gt; max_length)&#123; max_length &lt;- current_length maximal_connected_subgraph &lt;- visited &#125;&#125;sort(maximal_connected_subgraph)print(m[maximal_connected_subgraph,maximal_connected_subgraph]) 测试复杂的用例构造一个新的图这么构造是因为多了一个闭环，以及让1,和2节点多了一个选择，测试回朔的过程12&gt; sort(maximal_connected_subgraph)[1] 1 2 3 6 7 8 9 10 结果正确，就是打印的时候有点歧义，因为打印出来的矩阵如果没指定名字，又是1,2,3..顺序来的，会误以为是那几个节点，改一下名字就可以了1234mresult &lt;- m[maximal_connected_subgraph,maximal_connected_subgraph]colnames(mresult) &lt;- maximal_connected_subgraphrownames(mresult) &lt;- maximal_connected_subgraphprint(mresult) 结果是：12345678910&gt; print(mresult) 1 2 3 6 9 7 8 101 0 1 1 0 0 1 0 12 1 0 1 1 0 0 0 03 1 1 0 0 0 0 0 06 0 1 0 0 1 0 0 09 0 0 0 1 0 1 0 07 1 0 0 0 1 0 1 08 0 0 0 0 0 1 0 010 1 0 0 0 0 0 0 0]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[naruto]]></title>
      <url>%2F2017%2F03%2F20%2Fnaruto%2F</url>
      <content type="text"><![CDATA[迈特凯语录 唯有努力，我不想输给他 真正的胜利，不是击败强者，而是保护对你而言最重要的东西。 不相信自己的人，连努力的价值都没有。 真正重要的东西，不管痛苦也好、悲伤也好…都要努力到底，就算失去生命也要用双手来保护到底!如此一来，就算死掉的话，也会永远留下男子汉活过的证据… 努力是绝不会背叛人的 你只要相信自己所走的路，大步向前走就好，然后就那样成为一个能让别人带着笑容守望着的人吧。 天资聪颖的人并非幸福，能够为自己所信任之人去努力拼搏的人才是幸福的！ 当新叶萌发，新春到来之时，才是青春的最高潮燃烧得最火热的时刻！ 既然我已经摆出帅哥的姿势来耍帅了,就必须要彻底地遵守约定! 小李,你要休息了吗? 青春的勋章离不开『热血』 我相信木叶的莲花一定会再次定放!! 青春的操场500圈!! 这就是青春!!! 李洛克：在一个有觉悟的男人面前，任何哀愁和悲伤都是对他的侮辱 在凯开八门遁甲，这个差点一脚踢出大结局的男人，令卡卡西尊敬不已，我反复看了好几遍。凯这个集逗逼与热血气质于一身的男人。 迈特凯父亲，迈特戴的语录 不要和你的努力说对不起，那样会多对不起你的努力啊！ 祝贺你从忍者 学校毕业，但青春可不能就此毕业啊。搜索青春什么时候结束？青春不会退缩，所以永远不会结束。那爸爸死的时候也不结束吗？那才是青春的最高潮！ 迈特戴：不过你的努力也不算错，就算只跑完一半，你也确实努力了。 迈特戴：你的忍术和体术不行，这才叫爸爸高兴，知道自己的短处，才能让长处发光， 迈特戴：爸爸很高兴，能让儿子在这么小的时候就发现长处， 迈特凯：爸爸，其实你在逞强吧， 迈特戴：短处也能变成长处，唠叨代表周到，啰嗦说明热门，顽固意味着专注， 迈特戴：所谓自我约束是指在向某些困难发起挑战时，故意给自己戴上一个枷锁，把自己逼到穷途末路， 制定只属于自己的规矩，正因为有了那个枷锁，你才会认真面对挑战，而一旦失败，你就能通过实践那个规矩，让自己得到严格的锻炼，使得自己不断进步，这才叫自我约束。 迈特戴为迈特凯的父亲，他影响了迈特凯的一生，而迈特凯也将这种影响传给了自己的徒弟李洛克 青春，热血！！！ 迈特戴经常在别人嘲笑他的时候，对别人说，谢谢支持。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[project of stackoverflow - python object(一)]]></title>
      <url>%2F2017%2F03%2F14%2Fstackoverflow_object_1%2F</url>
      <content type="text"><![CDATA[what does ‘super’ do in python下面两个的区别是？ 123class Child(SomeBaseClass): def __init__(self): super(Child, self).__init__() 和123class Child(SomeBaseClass): def __init__(self): SomeBaseClass.__init__(self) 我在单个继承中已经看到super 被用的很多了。我能知道为什么要在多重继承的时候用它，但是还是不清楚在这种情况用它的好处。 180票的回答：（John Millikin) 在单一继承用super的好处很小–只是你不再需要硬编码基类名字到方法里面去了 然后，在多重继承里，不用super()几乎是不可能的。这包括常见的习语，像是mixins，interface,abstract classes等，这能让你的代码在之后延伸。如果以后有人想写一个拓展Child 和 mixin的类，他们的代码不会很好的工作。 75票的回答： 区别是什么？ SomeBaseClass.__init__(self)意思是调用SomeBaseClass的__init__方法然后，super(Child,self).__init__()意思是从Child类的MRO的父类中调用一个绑定方法__init__如果实例是Child的子类，有可能在方法解释顺序中的下一个父类是不一样的？？？ 向前兼容间接 ？？ （Indirection with Forward Compatibility) 这能给你什么？对于单重继承，问题中给出的例子几乎等同于静态分析。然而使用super 提供了具有向前兼容性的间接层向前兼容对于经验丰富的开发者来说是很重要的。你希望你的代码在做出一些细微的改动之后还能工作。当您查看修订历史记录时，您希望准确地查看何时更改了哪些内容。 你可能先从单重继承开始，但是当你增加另外的基类，你只需要改变基类的顺序（change the line with the bases）（if the bases change in a class you inherit from）如果类继承关系变了（比如增加了一个mixin)，其实你就没做什么改变。尤其在python2中，要想给super正确的方法参数是很难的。如果你知道你在单重继承下正确的使用super，这样是的调试就容易一点了 依赖注入 Dependency Injection 其他人可以使用你的代码然后插入一些父类到方法解释中(method resolution): 12345678910111213class SomeBaseClass(object): def __init__(self): print('SomeBaseClass.__init__(self) called') class UnsuperChild(SomeBaseClass): def __init__(self): print('UnsuperChild.__init__(self) called') SomeBaseClass.__init__(self) class SuperChild(SomeBaseClass): def __init__(self): print('SuperChild.__init__(self) called') super(SuperChild, self).__init__() 现在你增加其他类，然后在Foo和Bar之间插入一个类 12345678class InjectMe(SomeBaseClass): def __init__(self): print('InjectMe.__init__(self) called') super(InjectMe, self).__init__() class UnsuperInjector(UnsuperChild, InjectMe): pass class SuperInjector(SuperChild, InjectMe): pass 使用un-super子类未能注入依赖，因为你是用的子类在自己执行打印后调用的是硬编码方法 123&gt;&gt;&gt; o = UnsuperInjector()UnsuperChild.__init__(self) calledSomeBaseClass.__init__(self) called 然而使用super的子类能正确的依赖注入 1234&gt;&gt;&gt; o2 = SuperInjector()SuperChild.__init__(self) calledInjectMe.__init__(self) calledSomeBaseClass.__init__(self) called (我：因为super按照MRO来寻找next类的，不是就是去找父类SomeBaseClass,因为SuperInjector的MRO是自身&gt; UnsuperChild &gt; InjectMe &gt; SomeBaseClass &gt; object 还有就是 super 不是在SuperChild内么，为什么要按SuperInjector的MRO来？？这里应该是因为SuperInjector的init没有定义，然后是用的supserchild的，但是还是按照自身的MRO来。怎么做实验 ) 结论一直使用super来引用父类就好了 你想要引用的父类是MRO下一个类，而不是你看到的继承的关系 不使用super 回让你代码的使用者多了很多不必要的限制 我的：一个例子就是123456from collections imoprt Counter, OrderedDictclass OrderedCounter(Counter, OrderedDict): passoc = OrderedCounter("abracadabra") 之前还一直奇怪这个为什么类里面pass，什么都不用写就能结合，现在知道是因为有super相当于我先把参数传递到Counter初始化，然后因为有super找到的是下一个MRO，然后到OrderedDict初始化相当于两个工序，先count再order。 How does Python’s super() actually work, in the general case?现在有很多有关super()的资源，包括这个博客写的，还有很多stackoverflow上的问题。但是我感觉它们都没有解释它在普遍情况下是怎么工作的，也就是底层的实现。 考虑下面的这个继承层次： 123456789101112131415161718192021class A(object): def foo(self): print 'A foo' class B(A): def foo(self): print 'B foo before' super(B, self).foo() print 'B foo after' class C(A): def foo(self): print 'C foo before' super(C, self).foo() print 'C foo after' class D(B, C): def foo(self): print 'D foo before' super(D, self).foo() print 'D foo after' 如果你读过python的方法解释顺序的规则，你就知道上面的MRO是（D,B,C,A,object)。 这是被D.mro决定的(&lt;class &#39;__main__.D&#39;&gt;, &lt;class &#39;__main__.B&#39;&gt;, &lt;class &#39;__main__.C&#39;&gt;, &lt;class &#39;__main__.A&#39;&gt;, &lt;type &#39;object&#39;&gt;)) 和12d = D()d.foo() 打印出的： 1234567D foo beforeB foo beforeC foo beforeA fooC foo afterB foo afterD foo after 结果符合MRO。 但是，考虑上面的B中的super(B,self).foo() 实际调用的是C.foo，这个是在b=B()中；b.foo() 会直接到A.foo 很显然使用super(B,self).foo()不是A.foo(self)的快捷键，虽然有时是 很显然super()是有意识的在意之前的调用，然后尝试着去跟随总的MRO链。我觉得有两个方法能完成这个。第一个是做了一些类似在链中将super对象传递给下一个方法的self参数,像原来self对象那样，但是包含了这个信息，但是这样似乎会破坏很多东西(super(D,d) is d是False)，然后做了一些实验，我觉得这个方法不可行。 另外一个方法是类似全局变量来保存MRO和现在的链上的位置。我想象中的super算法是这样的： 我们当前有工作的环境吗？如果没有，创建一个队列，获取MRO，将除了第一个之外的所有元素入队列 将当前上下文的MRO队列中pop一个元素，在构建super实例的时候将它作为当前的class 当访问super实例的一个方法的时候，在当前class上寻找，然后调用它 但是，这样却没有解释类似使用不一样的基类当作第一个参数来调用super，或者调用不同方法。（这段好别扭）我想知道这个的更普遍的算法。而且，如果这样的context存在的话，我能看吗？我能破坏他么？这当然是一个糟糕的想法，但是python希望你成为一个成熟的人尽管你不是。 这同样也引入了好多设计的考量。如果我写的B只考虑了它和A的联系，然后又有其他人写了C，还有其他人写了D，我的B.foo()方法必须找到一个能兼容C.foo()的方法来调用super，尽管我在写它的时候C不存在。如果我想要我的类能很简单的扩展，那我必须要考虑这些。但是我不清楚这是不是比简单的将所有的foo的特征设置成一样来的更复杂。还有一个问题就是什么时候将代码放在super之前，什么时候之后，即使在仅考虑B的基类的时候它没有什么区别 7票的回答： super() is then obviously aware of the previous calls before it 它不是。当你做super(B,self).foo,super知道你的MRO因为它会从type(self).__mro__中得到。然后它知道应该在MRO的B后面那里开始寻找foo，一个粗略的纯 python写的应该是这样的:12345678910111213141516171819202122232425class super(object): def __init__(self, klass, obj): self.klass = klass self.obj = obj def __getattr__(self, attrname): classes = iter(type(self.obj).__mro__) # search the MRO to find self.klass for klass in classes: if klass is self.klass: break # start searching for attrname at the next class after self.klass for klass in classes: if attrname in klass.__dict__: attr = klass.__dict__[attrname] break else: raise AttributeError # handle methods and other descriptors try: return attr.__get__(self.obj, type(self.obj)) except AttributeError: return attr If I wrote B thinking only of its relation to A, then later someone else writes C and a third person writes D, my B.foo() method has to call super in a way that is compatible with C.foo() even though it didn’t exist at the time I wrote it! 并不要求你要从随机的类中多种继承。除非foo是被特意设计成在多重继承的时候将兄弟类的重写。D不应该存在。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[understanding MRO]]></title>
      <url>%2F2017%2F03%2F13%2Fmro%2F</url>
      <content type="text"><![CDATA[其实我一直觉得遇到什么障碍再去学什么是效率比较高的，这时候是带着问题去解决问题，比起干看，没有与实际相结合，要有用多了。所以等你真正遇到这个问题了，再来看看。 这个MRO是理解super方法的前序 ,以下考虑的都是多重继承，单重继承讨论这个就没什么价值了。 Method Resolution Order In computing, the C3 superclass linearization is an algorithm used primarily to obtain the order in which methods should be inherited (the “linearization”) in the presence of multiple inheritance, and is often termed Method Resolution Order (MRO)from wikipedia – C3 linearization 这里引进这个概念。因为在继承中，会有子类继承父类当中的一些元素或方法，但是在多重继承中，到底是哪一个呢？这里就涉及到了MRO，方法解释顺序。可以想像一个列表，里面是继承关系的顺序，当调用子类的方法，或访问子类的元素的时候，就按照这个顺序依次的查找。 12345678class A(object): passclass B(object): passclass C(B): passclass D(A,B,C): pass 你可以试一下，这个D类是定义不了的，会报错12345Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;TypeError: Error when calling the metaclass bases Cannot create a consistent method resolutionorder (MRO) for bases object, B, C 这里是因为破坏了MRO的一个(monotomic)单调性规定： if C1 precedes C2 in the linearization of C, then C1 precedes C2 in the linearization of any subclass of C. 通过C3算法得出的MRO就可以满足上面的这个要求 C3 linearization先定义几个符号表示：C1C2....CN 表示一个[C1,C2,C3….CN]的解决顺序列表，在这样的一个列表中，head是C1，其余的都叫做tail。注意：是从C2到最后都算tail.C+(C1C2...CN) = CC1C2...CN 表示[C] + [C1,C2...CN]L[C]表示linearization of class C，规定L[O] = O,O表示object 算法可以描述为一个递归的过程： the linearization of C is the Sum of C plus the merge of the linearizations of the parents and the list of the parents.L[C(B1B2...BN)] = C + merge(L[B1],...L[BN],B1...BN)顺序很重要，一一对应的。 merge 算法描述为(原文)： take the head of the first list, i.e L[B1][0]; if this head is not in the tail of any of the other lists, then add it to the linearization of C and remove it from the lists in the merge, otherwise look at the head of the next list and take it. if it is a good head, then report the operation until all the class are removed or it is impossible to find good heads. If fail, python will refuse to create the class C and will raise an exception. 没看懂直接看例子。 写出各个的linearization（这个翻译成啥我也不知道）123456L[O] = OL[E] = EOL[D] = DOL[F] = FOL[B] = B + merge(L[D],L[E],DE) = B + merge(DO,EO,DE) 这里是要merge3个list，DO,EO,DE，从第一个DO开始，它的head是D，然后看D是否出现在其他list的tail中中，注意tail是指除了head其余的所有。比如有一个list是ADCBEF,那D出现在第2个位置也算是在tail中，而不是在最后一个位置才算是tail。也就是说只有D出现在其他list首位置的时候，或者就根本没有D，这个D算是一个good head，然后将D加入B的linearization中，如果D不满足上面的条件，那么顺推到下一个list EO中的E，如果再不满足，继续顺推，都不满足的话就raise an exception。 123456L[B] = B + merge(L[D],L[E],DE) = B + merge(DO,EO,DE) = B + D + merge(O,EO,E) #再从第一个list O 开始去第一个元素O，但O不满足，出现在了第二个EO的tail中，顺延 = B + D + E + merge(O,O) = B + D + E + O = BDEO 1234L[C] = C + merge(DO,FO,DF) = C + D + merge(O,FO,F) = C + D + F + merge(O,O) = CDFO 123456789L[A] = A + merge(L[B],L[C],BC) = A + merge(BDEO,CDFO,BC) = A + B + merge(DEO,CDFO,C) = A + B + C + merge(DEO,DFO) = A + B + C + D + merge(EO,FO) = A + B + C + D + E + merge(O,FO) = A + B + C + D + E + F + merge(O,O) = A + B + C + D + E + F + O = ABCDEFO 另一个例子– 不能生成mro 12345L[O] = OL[X] = XOL[Y] = YOL[A] = AXYO L[B] = BYXO #这两个其实也应该通过上面那个merge算法算出来的，只不过这里一眼就能看出来 关键看类C123L[C] = C + merge(AXYO,BYXO,AB) = C + A + merge(XYO,BYXO,B) = C + A + B + merge(XYO,YXO) 到了这里就做不下去了，这里XYO,YXO，不管第一个X还是第二个的Y，都不行！！ X is in the tail of YXO whereas Y is in the tail of XYO因此算法结束.raise an error refuese to create class C 快速判别能否生成MRO的方法以下来自 python Attributes and Methods现在要定义一个新的类class N(A,B,C)画的稍微歪了，第一排全是O，那ok，result中也生成O放在顶部，第二排，BBC，不一样，要全部一样才能放在最后的result中，所以这个是失败的。 如果将类N的定义改为class N(A,C,B) 以上深入了解以下这个机制就可以，在编程的时候可以调用__mro__属性来查看一个类的mro，了解这个更有助于你理解你写的程序，比如super，比如描述符当中也会用到这个概念 出处： The Python 2.3 Method Resolution Order python Attributes and Methods]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[python中的对象属性查找]]></title>
      <url>%2F2017%2F03%2F08%2Fobject-attribute-look-up%2F</url>
      <content type="text"><![CDATA[原文链接 这里面已经讲的很详细了。暂时还没有自己的深刻的思考和理解，就先搬运过来。 Instance attribute look up 实例属性查找 The implementation works through a precedence chain that gives data descriptors priority over instance variables, instance variables priority over non-data descriptors, and assigns lowest priority to getattr() if provided. 现在有一个类C和一个实例c = C()，现在调用c.name，相当于在实例c中查找name属性，流程如下：1234567891011121314151617181920212223Get the Class from InstanceCall the Class&apos;s special method __getattribute__.All objects have a default __getattribute__ Get the Class&apos;s __mro__ as ClassParents For each ClassParent in ClassParents if the Attribute is in the ClassParent&apos;s __dict__ if this attribute is data descriptor return the result from calling the data descriptor&apos;s special method __get__() Breaking the for each(do not continue searching the same Attribute any further) If the Attribute is in Instance&apos;s __dict__ return the value as it is(even if the value is a data descriptor) #这个意思是即使是描述符也直接返回这个对象，不会去调用__get__(),返回值类似&lt;__main__ descriptor object at Ox..&gt; For each ClassParent in ClassParents if the Attribute is in the ClassParent&apos;s __dict__ if is a non-data descriptor return the result from calling the non-data descriptor&apos;s special method __get__() if it is Not a descriptor return the value If Class has the special method __getattr__ return the result from calling the Class&apos;s special method __getattr__ Raise an AttributeError 有几个点要记住！ descriptors are invoked by the getattribute() method overriding getattribute() prevents automatic descriptor calls getattribute() is only available with new style classes and objects object.getattribute() and type.getattribute() make different calls to get() data descriptors always override instance dictionaries. non-data descriptors may be overridden by instance dictionaries. Class attribute look up 类属性的查找一个metaclass M，和一个M的实例，类C，这时候调用C.name的流程：其实和实例访问一一对应，就是各自都升了一个level12345678910111213141516171819202122232425262728Get the MetaClass from ClassCall the Metaclass&apos;s special method __getattribute__ Get the Metaclass&apos;s __mro__ as MetaParents For each MetaParent in MetaParents if the Attribute is in the MetaParent&apos;s __dict__ if is a data descriptor return the result from calling the data descriptor&apos;s special method __get__() Get the Class&apos;s __mro__ as ClassParents For each ClassParent in ClassParents if the Attribute is in the ClassParents&apos;s __dict__ if is a(data or non-data) descriptor return the result from calling the descriptor&apos;s special method __get__() # 实例在这层上不会调用__get__() else return the value For each MetaParent in MetaParents if the Attribute is in the MetaParents&apos;s __dict__ if is a non-data descriptor return the result from calling the non-data descriptor&apos;s special method __get__() if it is NOT a descriptor return the value If MetaClass has the special method __getattr__ return the result from calling the MetaClass&apos;s special method __getattr__ Raises an AttributeError 例子123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199#!/usr/bin/env python# coding=utf-8class Desc(object): # 定一个非数据描述符 def __init__(self, msg): self.msg = msg def __get__(self, instance, owner=None): return "&#123;0&#125;: &#123;1&#125;".format(self.typ, self.msg) # self.typ是啥？？？？ class NonDesc(Desc): # non-data descriptor typ = 'NonDesc'class DataDesc(Desc): # data descriptor typ = 'DataDesc' def __set__(self, instance, value): pass def __delete__(self, instance): passclass M(type): x = 'x from M' y = NonDesc('y from cls M') z = DataDesc('z from cls M') def __getattr__(self, name): return "getattr M &#123;0&#125;".format(name)class A(object): #t = 't from A' #u = NonDesc('u from cls A') #v = DataDesc('v from cls A') x = 'x from A' y = NonDesc('y from cls A') z = DataDesc('z from cls A')class B(A): """ metaclass is M """ __metaclass__ = M """ 这个metaclass什么用？？？？ """ class C(B): """ metaclass is inherited from C """ def __getattr__(self, name): return "getattr C: &#123;0&#125;".format(name) c = C()print '******'print 'c.__class__', c.__class__ #其实就是type(c), 还有注意c是新式类，格式应该是&lt;class '__main__.C'&gt;之类的print 'c.__class__.__getattribute__', c.__class__.__getattribute__ # 因为c.__class__也是一个对象# &lt;slot wrapper '__getattribute__' of 'object' objects&gt;print 'c.__class__.__mro__', c.__class__.__mro__ # method resolution order C B A Oprint '******'print 'c.x', c.x """父类们寻找顺序是根据c.__class__.__mro__ 来的c先去寻找父类们中有没有x的描述符，没有，然后在自己的__dict__中找x，也咩有，然后再去父类们的__dict__中找有没有这个属性名的non-data 描述符，没有，不是描述符而是直接属性的呢？A中有，返回A中的x值"""print 'c.y', c.y"""同上，父类的顺序不废话了最终在第三阶段找到A中的y，它是一个non-data descriptor，NonDesc: y from cls A"""print 'c.z', c.z"""在第一个阶段中的A中找到z 是一个data descriptor，饭后 DataDesc: z from cls A"""print 'c.nope', c.nope"""当前三个阶段都找不到的时候，如果类中有定义__getattr__，就到这里去，没有报错这里所有三个阶段没有nope属性，然后到了__getattr__，返回 getattr C: nope"""c.t = 't from obj c'c.u = NonDesc('u from obj c')c.v = DataDesc('v from obj c')c.x = 'x from obj c'c.y = NonDesc('y from obj c')c.z = DataDesc('z from obj c')print '******'print 'c.t', c.t"""如上，在第二个阶段找到t, 返回 t from obj c"""print 'c.u', c.u"""在第二个阶段在c字典里面找到，不管是值还是descriptor ，这里会调用__get__() NonDesc: u from obj cupdate:更正因为在"""print 'c.v', c.v"""在第二阶段c字典里找到, 调用__get__() ，返回 DataDesc: v from obj c"""print 'c.x', c.x"""因为在第一阶段是在类父类中找描述符，虽然A中有属性x但不是描述符，因此进入第二个阶段，在实例字典中找，不管是不是描述符只要名字对了就返回. 这里在这个阶段返回x from obj c"""print 'c.y', c.y"""同上，返回的是 NonDesc: y from obj c"""print 'c.z', c.z"""同上，返回的是 DataDesc: z from obj c"""print '******' # 这里是用到 class attribute look up 。 以上是对实例进行点运算print "C.x", C.x"""因为B的metaclass是M了，C继承B，C现在的metaclass也是M现在要将上面的所有概念都升级，原来class变成metaclass，原来instance变成class先根据metaclass里的mro决定先后顺序metaparents因为这里是类属性访问，C类的metaclass是M，M.__mro__ 是 (&lt;class '__main__.M'&gt;, &lt;type 'type'&gt;, &lt;type 'object'&gt;)按顺序找x的描述符，但M中没有x的描述符，然后type，object都没有。进入第二个阶段，先计算C.__mro__,按照顺序依次访问类字典C,B,A,O ， 如果有属性重名，先要描述符，不然只要是在__dict__中就返回c中没有x,然后去B，B里面也咩有x，到A中，有x但是不是描述符，没关系直接返回,因为也没有名字为x的描述符了。返回x from A"""print "C.y", C.y"""同上，虽然在M中有y但是是非数据描述符，在第2阶段中的A类中找到y非数据描述符,返回 NonDesc: y from cls A"""print "C.z", C.z"""这是在第一个阶段中的M里找到z数据描述符， 返回 DataDesc: z from cls M"""print "C.nope", C.nope"""上面三个阶段都没有，进入第四个阶段，这个阶段不是去C中的__getattr__，因为上面说了都升了一级，现在是在M中的__getattr__，如果M里面没有__getattr__，那么就回报错，现在M有，返回 getattr M nope"""C.t = 't from obj C'C.u = NonDesc('u from obj C')C.v = DataDesc('v from obj C')C.x = 'x from obj C'C.y = NonDesc('y from obj C')C.z = DataDesc('z from obj C')"""如果是类属性访问，好像没有A，B什么事 !!!!写在流程搞错之前，之前在第二阶段没有计算类的__mro__重新看一下流程"""print '******'print "C.t", C.t"""因为metaclass以及mro中都没有t，进入下一个阶段在第二阶段中现在C类中有t这个属性了，返回 t from obj C"""print "C.u", C.u"""同上，在第二阶段中C类的__dict__中找到，返回 NonDesc: u from obj C"""print "C.v", C.v"""同上，在第二阶段中返回 DataDesc: v from obj C"""print "C.x", C.x"""和M中有重名，但是因为M中的不是数据描述符，这个的优先级高，在第二阶段返回 x from obj C虽然A中也有x，但是mro顺序C排在A前面"""print "C.y", C.y"""同上，有重名，但是M中是非数据描述符，第一阶段过，到第二阶段，返回 NonDesc: y from obj C然后A中同理"""print "C.z", C.z"""重名，但是z在M中是数据描述符，在第一阶段就返回 DataDesc: z from cls M"""print "C.nope", C.nope"""这个没有变 getattr M nope""" 结果：1234567891011121314151617181920212223242526272829******c.__class__ &lt;class '__main__.C'&gt;c.__class__.__getattribute__ &lt;slot wrapper '__getattribute__' of 'object' objects&gt;c.__class__.__mro__ (&lt;class '__main__.C'&gt;, &lt;class '__main__.B'&gt;, &lt;class '__main__.A'&gt;, &lt;type 'object'&gt;)******c.x x from Ac.y NonDesc: y from cls Ac.z DataDesc: z from cls Ac.nope getattr C: nope******c.t t from obj cc.u &lt;__main__.NonDesc object at 0x1009b8f10&gt;c.v &lt;__main__.DataDesc object at 0x1009b8f50&gt;c.x x from obj cc.y &lt;__main__.NonDesc object at 0x1009b8f90&gt;c.z DataDesc: z from cls A******C.x x from AC.y NonDesc: y from cls AC.z DataDesc: z from cls MC.nope getattr M nope******C.t t from obj CC.u NonDesc: u from obj CC.v DataDesc: v from obj CC.x x from obj CC.y NonDesc: y from obj CC.z DataDesc: z from cls MC.nope getattr M nope]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[descriptor]]></title>
      <url>%2F2017%2F03%2F08%2Fdescriptor%2F</url>
      <content type="text"><![CDATA[其实自己没有深入的研究源码，这篇也是基于阅读一些官方文档和他人的博客做的总结。我这里的思路是从描述符的渊源到为什么有这个描述符，然后怎么用这里先直接给出描述符的定义，先有个印象，如果一开始阅读感觉没什么联系，没关系，最终那些点将连成线的。官方的定义： In general, a descriptor is an object attribute with “binding behavior”, one whose attribute access has been overridden by methods in the descriptor protocol. Those methods are get(), set(), and delete(). If any of those methods are defined for an object, it is said to be a descriptor.from – Descriptor HowTo Guide 也就是只要一个类定义了__get__(),__set__(),__delete__()当中的任意一个特殊方法,这个类就有了个别名“描述符”啦 描述符的由来首先，因为python是一种动态编译的语言，他能在运行中动态添加类属性或类对象属性。那这些属性是被保存在比如a.__dict__这个里面，这里a是一个实例a=A()。其实类也有一个__dict__属性，通过A.__dict__就可以访问到. 123456789101112131415&gt;&gt;&gt; class A(object):... def __init__(self):... self.attr = 1... def foo(self):... print self.attr...&gt;&gt;&gt; a = A()&gt;&gt;&gt; dir(a)['__class__', '__delattr__', '__dict__', '__doc__', '__format__', '__getattribute__', '__hash__', '__init__', '__module__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'attr', 'foo']&gt;&gt;&gt; dir(A)['__class__', '__delattr__', '__dict__', '__doc__', '__format__', '__getattribute__', '__hash__', '__init__', '__module__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'foo']&gt;&gt;&gt; a.__dict__&#123;'attr': 1&#125;&gt;&gt;&gt; A.__dict__dict_proxy(&#123;'__module__': '__main__', '__dict__': &lt;attribute '__dict__' of 'A' objects&gt;, 'foo': &lt;function foo at 0x101bba668&gt;, '__weakref__': &lt;attribute '__weakref__' of 'A' objects&gt;, '__doc__': None, '__init__': &lt;function __init__ at 0x101bba5f0&gt;&#125;) 注意到在A类中定义了一个foo函数，像这样的函数在C++语言中被称为成员函数，但是可以看到在a.__dict__中没有foo，在A.__dict__中有。其实通过访问，可以看出a.__dict__中保存的都是一些变量属性。这么理解，在C++中成员函数是被所有对象所共享的，不会为没个对象复制一份，这里也一样，可以看作是类的一个属性，不是实例的属性。那其实在python中，这么做是牵涉到了它的另外的两个概念，绑定，未绑定函数和描述符。先说一下，所有的类成员函数都是non-data despriptor。后面会继续解释 In a nutshell, a descriptor is a way to customize what happens when you reference an attribute on a model.from – Python Descriptors, Part 1 of 2 Descriptor are the mechanism behind properties, methods, static methods, class methods and super()from – Descriptor HowTo Guide 访问属性查找属性的访问顺序建议先把下面的看了再来看这个 我之所以说先看下面，又不得不把这个主题先放上来，是因为其实描述符归根结底，目前看到就是对属性的取值赋值操作，只不过是对这个操作封装了一下而已。12a.attr = 1tmp = a.attr 一般的取值赋值就是这样子的，如果attr事先在类里面定义好了的self.attr = arg 上面的a.attr = 1其实就是重新将“标签”a.attr贴到1数值上去，如果没有那就是动态生成attr属性。但是这样的赋值太单一了，什么意思，也就是说，如果我要对赋入的值做下额外的检查，比如学生的成绩，不可能出现负数，身高也不可能出现负数。所以想到了在__init__当中增加一些逻辑代码进行检查123def __init__(self,score): assert score&gt;=0,"value error" self.score = score 但是这样只是在初始化的时候，像a = A(-1)会报错，那之后如果a.score = -100像这样的误操作，也没人阻止。那我们又有了另一种思路123456def get_score(self): return self.scoredef set_score(self,new_score): assert new_score&gt;=0,"value error" self.score = new_score 通过a.set_score(-100)，调用一个函数，并在函数体内进行检查来进行赋值。 总的来讲，python的属性获取，设置，这个属性只是一个存储的地方，只是一个容器，但往往你可能需要更多的功能，比如赋值的时候检验，然后，一般的，是用一些方法来做这些事情，但是如果对于已经存在了的属性，你想用函数代替取值，赋值，你就要重写代码，找到所有用到这些属性的方法，然后改成函数，比如上面的所有a.score = 1像这样的操作改成a.set_score(1)。这样就增加了工作量，这也是为什么在java程序中一个简单的取值都要封装成一个函数，就是为了避免何种情况，常见的模式也就是属性定义为私有变量，然后开放一个公有接口。python中的描述符只不过是另一种方法来实现这种对属性额外控制的需求而已 描述符实例描述符的用法应该不局限于下面给出的例子，要多看其他高人的代码！！！12345678910111213class Positive(object): def __init__(self,name): self.name = name def __get__(self,instance,owner): if instance is None: return self #这里相当于如果通过类调用,Student.score，就返回是类似&lt;descriptor.Positive object at 0x123455..&gt;之类的 return instance.__dict__[self.name] def __set__(self,instance,value): if value &lt; 0: raise ValueError("negative value error...") instance.__dict__[self.name] = value 上面就定义了一个描述符。其实就是一个类，描述符只是个名称而已。在我的世界里，我想叫它皮皮虾都可以。只是全世界就这么流通规定了12345class Student(object): score = Positive('score') #这句话就将score属性让描述符代理了 def __init__(self,name,score): self.name = name self.score = score 现在如果有这么一个语句s = Student(&#39;cy&#39;,100);a = s.score，其实是相当于在做a = type(s).__dict__[&#39;score&#39;].__get__(s,type(s))可以查看Student.__dict__中的score属性是&#39;score&#39;: &lt;__main__.Positive object at 0x101bb8ed0&gt;这样子的。当作了type(s).__dict__[&#39;score&#39;]时其实就是获得了一个实例，之后还可以继续用点运算符往下接着做。 Q&amp;APositive 描述符中的__set__为什么参数中没有类？1234567&gt;&gt;&gt; Student.__dict__dict_proxy(&#123;'__module__': '__main__', 'score': &lt;__main__.Positive object at 0x101bb8ed0&gt;, '__dict__': &lt;attribute '__dict__' of 'Student' objects&gt;, '__weakref__': &lt;attribute '__weakref__' of 'Student' objects&gt;, '__doc__': None, '__init__': &lt;function __init__ at 0x101bbaaa0&gt;&#125;)#注意上面的score属性的值&gt;&gt;&gt; Student.score = 12 # 通过类访问&gt;&gt;&gt; Student.__dict__dict_proxy(&#123;'__module__': '__main__', 'score': 12, '__dict__': &lt;attribute '__dict__' of 'Student' objects&gt;, '__weakref__': &lt;attribute '__weakref__' of 'Student' objects&gt;, '__doc__': None, '__init__': &lt;function __init__ at 0x101bbaaa0&gt;&#125;)#再对比一下score的值 当类调用的时候，其实就是设置同名新值了，它将原来的描述符给替换覆盖了。 Student类里面的score和self.score,到底用的是哪个？？可以先看一下12345&gt;&gt;&gt; s = Student('cy','100')&gt;&gt;&gt; s.__dict__&#123;'score': '100', 'name': 'cy'&#125;&gt;&gt;&gt; Student.__dict__dict_proxy(&#123;'__module__': '__main__', 'score': &lt;__main__.Positive object at 0x101bb8ed0&gt;, '__dict__': &lt;attribute '__dict__' of 'Student' objects&gt;, '__weakref__': &lt;attribute '__weakref__' of 'Student' objects&gt;, '__doc__': None, '__init__': &lt;function __init__ at 0x101bbaaa0&gt;&#125;) 其实这里涉及到一个优先级的问题，也就是上面的访问属性的顺序链接。这里可以再跳回去看。因为描述符的优先级高！并且会改变默认的get,set方法。 If an instance’s dictionary has an entry with the same name as a data descriptor, the data descriptor takes precedence. If an instance’s dictionary has entry with the same name as a non-data descriptor,the dictionary entry takes precedence.from Descriptor HowTo Guide 什么是non-data descriptor后面会说明。 2引申的一个问题就是如果self.score = score没有定义会是什么情况1234567891011121314&gt;&gt;&gt; class Student(object):... score = Positive('score')... def __init__(self,name):... self.name = name...&gt;&gt;&gt; s = Student('cy')&gt;&gt;&gt; s.score = 10&gt;&gt;&gt; s.__dict__&#123;'score': 10, 'name': 'cy'&#125;&gt;&gt;&gt; s.score = -10Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "&lt;stdin&gt;", line 10, in __set__ValueError: negative error 还是照样行得通。因为instance.__dict__[self.name] = value.虽然初始化的时候没有score这个属性，但其实后面的字典操作，相当于动态增加了这个属性，而且访问的优先级照样根据那个顺序来 如果是self.score = Positive(&#39;score&#39;)会怎么样1234567891011&gt;&gt;&gt; class Student(object):... def __init__(self,name):... self.name = name... self.score = Positive('score')...&gt;&gt;&gt; s = Student('cy')&gt;&gt;&gt; s.__dict__&#123;'score': &lt;__main__.Positive object at 0x101bc70d0&gt;, 'name': 'cy'&#125;&gt;&gt;&gt; s.score = -10&gt;&gt;&gt; s.__dict__&#123;'score': -10, 'name': 'cy'&#125; 没有起到作用，这是必然的。如果你知道访问顺序了之后，访问s.score时，因为类中没有同名的描述符，所以到实例中的__dict__看，如果有这个key，返回，但这里是赋值操作，参考另一篇python name and values，s.scorei = -10只不过是将score这个name重新贴标签贴到数值-10上去。 __get__中参数owner什么用，也没有用到它啊？后面在classmethod中就会用到这个参数。其实函数参数写在哪里，也不一定都要用到，但更关心为什么要这么设计。后面看看源代码 看一个图： 应用场景python中有个叫修饰器的东西，property()，它是描述符的简介版123456789@propertydef score(self): return self.__score@score.setterdef score(self,score): if score &lt; 0: raise ValueError('negative') self.__score = score calling propery() is a succinct way of building a data descriptor that triggers function calls upon access to an attributefrom Descriptor HowTo Guide 上面的写法@property使用到了装饰器 但是如果一个类里面有很多属性是相同的限制，比如学生的身高不能负数，成绩不能负数，体重不能负数，如果用property的话，那就多了很多重复的代码，每个属性都要像上面一样写一遍。这时候就可以考虑用写一个描述符类来“一统天下”了 在之前说的对于已存在的属性，如果要对它们要进行限制，通过方法的话要找到每一处，这样很不方便，如果使用描述符只需要在类中加上tall = Positive(&#39;tall&#39;)像这样的语句就可以了，而且完全没有任何副作用！！ If looked-up value is an object defining one of the descriptor methods, then python may override the default behavior and invoke the descriptor method instead.from Descriptor HowTo Guide 描述符的种类 学习也要遵循20/80定律，学到的20%就足够写程序了，先跑起来再来完善接下来的80%– 尔东诚霍划夫斯基描述符分data descriptor和non-data descriptor两者之前的区别就是，后者只定义了__get__。也就是没有设置。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[zlt-project]]></title>
      <url>%2F2017%2F03%2F01%2Fzlt-project%2F</url>
      <content type="text"><![CDATA[最近一直在用python写，这个也用python试试。需求图示 用到： 正则表达式：用来匹配test.py中的test名的 shutil模块，shutil.copy复制 os模块，切换目录用的。os.listdir,os.path.isfile等 sys模块，sys.argv命令行参数 Tkinter，图形化界面 主要的拷贝逻辑写出来12345678910111213141516171819import reimport osimport shutilimport syspath_a = sys.argv[1]path_b = sys.argv[2]candidate_list = [x for x in os.listdir(path_b) if os.path.isfile(x) and x[0]!='.']p = re.compile('\w+')candidate = [p.match(file_name).group() for file_name in candidate_list]#先把B文件中的文件名提取出来for prefix in candidate: for every_file in os.listdir(path_a): if predix in every_file: file_path = path_a + '/' + every_file shutil.copy(file_path,path_b) print 'copy %s to %s'%(every_file,path_b) 接下来就是披上一件外衣了，Tkinter。下面是代码 zlt_main_frame_listbox.py 这个是显示文件夹功能的窗口123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112#!/usr/bin/python#-*- coding: utf-8 -*-# File Name: zlt.py# Created Time: Sun Mar 5 21:56:03 2017__author__ = 'Crayon Chaney &lt;mmmmmcclxxvii@gmail.com&gt;'import osfrom Tkinter import *from time import sleepimport pdbclass ShowList(Frame): # count = 0 def __init__(self,parent,initdir=None): # super(ShowList,self).__init__(parent) """ 上面这个为什么不行？？？ """ Frame.__init__(self,parent) self.parent = parent self.cwd = StringVar(self) self.wholecwd = StringVar(self) self.dir_display = Label(self,font = ('Helvetica',12,'bold'),fg = 'blue') self.dir_display.pack() self.dirfm = Frame(self) self.dirsb_y = Scrollbar(self.dirfm) self.dirsb_x = Scrollbar(self.dirfm,orient="horizontal") self.dirlb = Listbox(self.dirfm,yscrollcommand = self.dirsb_y.set,xscrollcommand = self.dirsb_x.set,height =20,width = 30 ) self.dirsb_y.config(command = self.dirlb.yview) self.dirsb_x.config(command = self.dirlb.xview) self.dirlb.bind('&lt;Double-1&gt;',func=self.selectAndGo) self.dirsb_y.pack(side = RIGHT,fill=Y) self.dirsb_x.pack(side = BOTTOM,fill=X) self.dirlb.pack(side=LEFT,fill=BOTH) self.dirfm.pack() self.input = Entry(self,textvariable=self.cwd) self.input.bind('&lt;Return&gt;',func = self.doLs) self.input.pack() self.dirbuttonfm = Frame(self) self.clrbutton = Button(self.dirbuttonfm,text='clear',command=self.clrEntry) self.clrbutton.pack(side=LEFT) self.listbutton = Button(self.dirbuttonfm,text='List Directory',command=self.doLs) self.listbutton.pack(side=LEFT) self.dirbuttonfm.pack() if initdir: self.cwd.set(initdir) self.doLs() def clrEntry(self,ev = None): self.cwd.set('') def selectAndGo(self,ev=None): self.last = self.cwd.get() self.dirlb.config(selectbackground='red') self.cwd.set(self.dirlb.selection_get()) self.doLs() def doLs(self,ev = None): cur = self.cwd.get() error = '' if not os.path.exists(cur): error = '%s is not exists'%cur elif not os.path.isdir(cur): error = "%s is not dir"%cur if error: self.cwd.set(error) self.parent.update() sleep(2) if not (hasattr(self,'last') and self.last): self.last = os.curdir self.cwd.set(self.last) self.dirlb.config(selectbackground='LightSkyBlue') return self.cwd.set('Fetching...') self.parent.update() dirfiles = os.listdir(cur) os.chdir(cur) self.dir_display.config(text=os.getcwd()) self.wholecwd.set(os.getcwd()) dirfiles.sort() self.dirlb.delete(0,END) self.dirlb.insert(END,os.curdir) self.dirlb.insert(END,os.pardir) for eachdirname in dirfiles: self.dirlb.insert(END,eachdirname) self.cwd.set(os.curdir) self.dirlb.config(selectbackground='LightSkyBlue')if __name__ == '__main__': root = Tk() ShowList(root,os.curdir).pack() root.mainloop() zlt_windows.py 主窗口123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106#!/usr/bin/python#-*- coding: utf-8 -*-# File Name: zlt_windows.py# Created Time: Mon Mar 6 14:13:52 2017__author__ = 'Crayon Chaney &lt;mmmmmcclxxvii@gmail.com&gt;'from zlt_main_frame_listbox import *import shutilimport reimport sysclass CopyDir(object): def __init__(self): self.top = Tk() self.top.title('你花大爷呕心沥血作') # ShowList(self.top).pack(side=LEFT) self.A = ShowList(self.top,os.curdir) self.A.pack(side=LEFT) self.topbuttonfm = Frame(self.top) self.copybutton = Button(self.topbuttonfm,text='&lt;--A copy B--&gt;',width = 15,command = self.confirmCopy) self.copybutton.pack() self.quitbutton = Button(self.topbuttonfm,text='退出',command = self.top.quit) self.quitbutton.pack() self.topbuttonfm.pack(side = LEFT,ipadx = 5) # ShowList(self.top).pack(side=LEFT) self.B = ShowList(self.top,os.curdir) self.B.pack(side=LEFT,ipadx = 5) def confirmCopy(self,ev = None): self.confirmtop = Toplevel(self.top) # pdb.set_trace() self.a_path = self.A.wholecwd.get() self.b_path = self.B.wholecwd.get() listfiles_a = os.listdir(self.a_path) listfiles_b = os.listdir(self.b_path) title_msg = '复制这些到%s'%self.b_path self.confirmtop.title(title_msg) # self.fm = Frame(self.confirmtop) # to be pack self.copy_candidates_info = Text(self.confirmtop,height=30,width = 20) # to be pack pattern = re.compile('\w+') self.to_be_copied_list = [] for to_be_copied in listfiles_b: try: prefix = pattern.match(to_be_copied).group() except AttributeError,e: continue # print e # if 'NoneType' in e: # continue # else: # sys.exit() for eachfile in listfiles_a: if prefix in eachfile :# and os.path.isfile(self.a_path+'/'+prefix): 可能在windows下不支持 self.to_be_copied_list.append(eachfile) # self.copy_candidates_info.delete(0,END) for item in self.to_be_copied_list: self.copy_candidates_info.insert(END,item+'\n') # window下换行符可能不一样 \r\n self.copy_candidates_info.pack(side = LEFT,padx = 10) information = 'copy to %s'%self.b_path self.other_information = Label(self.confirmtop,text = information) self.other_information.pack(side=LEFT,ipadx = 5,ipady = 13) self.fm = Frame(self.confirmtop) self.result_info = Label(self.fm,font = ('Helvetica',12,'bold'),fg='red') self.confirmbutton = Button(self.fm,text='确认',command = self.copyExecute) self.cancelbutton = Button(self.fm,text='取消',command = self.confirmtop.quit) """ 为什么点击取消会全体退出？？？ 想要的效果是只是这个确认窗口退出而已 """ self.result_info.pack(side=LEFT) self.confirmbutton.pack(side = LEFT) self.cancelbutton.pack(side=LEFT) self.fm.pack(side = BOTTOM) def copyExecute(self,ev=None): os.chdir(self.a_path) if not (hasattr(self,'to_be_copied_list') and len(self.to_be_copied_list)): self.result_info.config(text='Failed') return for item in self.to_be_copied_list: try: shutil.copy(item,self.b_path) except Exception,e: self.result_info.config(text=e) else: self.result_info.config(text='Successful') def main(): c = CopyDir() mainloop()if __name__ == '__main__': main() 发现的bug： 因为我现在是在一个窗口生成了两个文件夹展示的frame，但是在一个进程中，一个文件夹切换了路径，另一个就跟着切换了导致出现bug，解决方法，要用多线程]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[python types and objects]]></title>
      <url>%2F2016%2F12%2F03%2Fpython-types-and-objects%2F</url>
      <content type="text"><![CDATA[Python Types and Objects这篇文章解释了： 什么是&lt;type &#39;type&#39;&gt;和 用户自定义的类和实例是怎么联系在一起的以及和内建类型的联系 什么是metaclass元类 type和object从之前的学习面向对象编程来看，我们可以通过继承来定义一个类，也可以查看一个对象属于哪个类。其实这就可以抽象出两种关系图中虚线就是type，表示一个对象(又称‘实例’)的类型是尖头指向的那个图中的实线是base，表示一个类的基类是尖头指向的那个 the type and base(if exist) are important, coz they define special relationships an object with other objects. 因为在python中一切皆为对象，所以base到头了就是object，这个是在python中一切类的祖宗。而因为python中一切皆为对象, 它就有类型，object也是一个对象，它的类型就是type，type本身也是一个对象，为了满足python这样的设定，它的类型就是它自己。type既是一个对象，也是一个类。就说我们自己定义了一个类1234567&gt;&gt;&gt; class A(object):... pass...&gt;&gt;&gt; A.__bases__(&lt;type 'object'&gt;,)&gt;&gt;&gt; A.__class__&lt;type 'type'&gt; 他也有类型，就是type类型 keep in mind that the types and bases of objects just other objects 既然像类也是一种”对象”,那它是谁的对象？？答案就是metaclass，type就是metaclass。先有鸡还是先有蛋？ 类和类型的统一这个问题在知乎上有一个解答不错 旧式类的实现不够好，类是类，实例是实例，类的类型是classobj，实例的类型是instance，两者的联系只在于class，这和内置对象是不同的，int对象的类型就是int，同时int()返回的也是int类型的对象，内置对象和自定义对象不同就对代码统一实现带来很大困难。比如说有段代码输入一个对象，返回一个默认构造的同类型对象，本来应该写作type(obj)()，现在就必须写成：obj.class() if hasattr(obj, ‘class‘) else type(obj)()。如果想用自定义的类去替代一些系统内置类型，比如说自定义一个dictionary，这样的不一致就会出问题新式类之后自定义类和内置类型就一致了：1. 所有类型的类型都是type2. 所有类型调用的结果都是构造，返回这个类型的实例3. 所有类型都是object的子类这样就不再需要区分自定义类和类型了。实现这件事其实并不容易，理性上来想，type的基类是object，而object的类型是type，这是一个先有鸡还是先有蛋的问题。Python通过对这几个类的特殊处理实现了这样的逻辑。 作者：灵剑链接：https://www.zhihu.com/question/38803693/answer/103128686来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 自定义类和内建类型图片来自那个文章顶部那个链接,这篇文章写的很详细了 Dashed lines cross spacial boundaries (i.e. go from object to meta-object). Only exception is (which is good, otherwise we would need another space to the left of it, and another, and another…). Solid lines do not cross space boundaries. Again, -&gt; is an exception. Solid lines are not allowed in the rightmost space. These objects are too concrete to be subclassed. Dashed line arrow heads are not allowed rightmost space. These objects are too concrete to be instantiated. Left two spaces contain types. Rightmost space contains non-types. If we created a new object by subclassing it would be in the leftmost space, and would also be both a subclass and instance of . 两个对象python中分Type对象和Non-Type对象，这个Non-Type不是一个正式的概念，只是这么称呼，这类对象，比如2，就是2，2怎么再派生？怎么再实例化，不行，所以是too concrete。怎么判断，只要type(obj)出来的是&lt;type &#39;type&#39;&gt;就是Type对象，不然就是Non-Type对象 Type objects - can create instances, can be subclassed. Non-type objects - cannot create instances, cannot be subclassed. objectname.__class__ exists for every object and points the type of the object. objectname.__bases__ exists for every type object and points the superclasses of the object. It is empty only for &lt;type &#39;object&#39;&gt;. Some non-type objects can be created using special Python syntax. For example, [1, 2, 3] creates an instance of &lt;type &#39;list&#39;&gt;. 两个动作两种关系对应两种动作可以生成两种对象。有可能是Type对象,也有可能是Non-Type对象。两个动作就是subclassing和instantiating. subclassing这个动作具体就是class语句,定义一个类，或者说定一个type， This means you can create a new object that is somewhat similar to existing type objects. To create a new object using subclassing, we use the class statement and specify the bases (and, optionally, the type) of the new object. This always creates a type object. 这段代码抽象代表的就是一个类 instantiating这个动作就是实例化，由一个type实例化出对象，type相当于一个工厂的模型，具体就是通过()操作。 To create a new object using instantiation, we use the call operator (()) on the type object we want to use. This may create a type or a non-type object, depending on which type object was used. This means you can create a new object that is an instance of the existing type object. python中的内建类型是在启动python后生成的。比如1234567&gt;&gt;&gt; type(list)&lt;type 'type'&gt;&gt;&gt;&gt; list.__bases__(&lt;type 'object'&gt;,) # list是从object派生而来了&gt;&gt;&gt; ml = [1,2,3]&gt;&gt;&gt; type(ml)&lt;type 'list'&gt; 如果问[1,2,3]是什么类型啊？列表类型啊。列表类型是什么类型啊？type类型啊。type类型是什么类型啊？type类型。。。当我们创建{‘a’:1,’b’:2},(1,2)这种，是从&lt;type &#39;list&#39;&gt;,&lt;type &#39;dict&#39;&gt;实例化出来的，也就是相应的type，包括自定义。 metaclass很重要的一点就是，当我class语句定义了一个类，我就自动的有了一个type，其实也就是说__class__（新式类）12class C(object): pass type(C)就已经定了。它是根据所继承的父类的type延续下来的，因为object的类型是type所以12&gt;&gt;&gt;type(C)&lt;type 'type'&gt; 那其实这样追溯下去，因为object类型是type类，所以所有的类都是type类。除了Non-Type对象的类型是相对应的类。所以那幅图的前面两列的虚线都指到type。这里有一个问题就是它是由继承关系决定的，那如果是多重继承呢？是继承哪个？1234567891011121314151617181920212223&gt;&gt;&gt; class M1(type):... pass...&gt;&gt;&gt; class M2(type):... pass...&gt;&gt;&gt; class A(object):... __metaclass__ = M1...&gt;&gt;&gt; class B(object):... __metaclass__ = M2...&gt;&gt;&gt; type(A)&lt;class '__main__.M1'&gt;&gt;&gt;&gt; type(B)&lt;class '__main__.M2'&gt;&gt;&gt;&gt; class C(A,B):... pass...Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; TypeError: Error when calling the metaclass bases metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases 如果大家的metaclass都一样，那就没得说了，如果不一样，那么就会混乱，这时候要指定。什么时候会不一样呢？一般情况下都是type，除非自己定义specialType然后派生。但建议是不要用这个特性。 另一个问题就是，到底怎么自定义specialType？上面例子已经给出答案了。12class C(object): __metaclass__ = specialType 隐式关系图片来自文章顶部链接文章中的： issubclass问的是一个class是不是subclass of 另一个class。class和class之间的关系isinstance问的是一个object是不是instance of 另一个class。object和class之间的关系 12345678910111213141516&gt;&gt;&gt; isinstance(type,type) #虚线，type指向自己 True&gt;&gt;&gt; isinstance(type,object) #因为type是自身的实例，type又是object的子类，所以type是object的实例True&gt;&gt;&gt; isinstance(object,object) #因为object是type的实例，type又是object的子类，所以object是object的实例True&gt;&gt;&gt; isinstance(object,type) # 虚线True&gt;&gt;&gt; issubclass(type,type) # A class is considered a subclass of itselfTrue&gt;&gt;&gt; issubclass(type,object) # 实线True&gt;&gt;&gt; issubclass(object,object) # 任何类都是object的子类True&gt;&gt;&gt; issubclass(object,type) # object在类的金字塔顶端，它上面就没人啦False A class is considered a subclass of itself Q&amp;A class,object,instance的关系 An object is an instance of a class, and may be called a class instance or class object; instantiation is then also known as construction. Not all classes can be instantiated – abstract classes cannot be instantiated, while classes that can be instantiated are called concrete classes. How does python really create a new object? Internally, when python creates a new object, it always uses a type and creates an instance of that object. Specifically it uses the new() and init() methods of the type. In a sense, the type serves as a factory that can churn out new objects, the type of these manufactured objects will be the type object used to create them. This is why every object has a type.]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Interesting experience -- challenge school master swimming]]></title>
      <url>%2F2016%2F11%2F11%2Fswimming-with-master%2F</url>
      <content type="text"><![CDATA[–update–其实现在想想，可能当初会有更成熟的做法。 其实真的，在决定要去雷励的时候，众筹这个任务就已经压在我的肩上了，虽然后来真的校长答应我的挑战促使了我的任务圆满完成，但这其中的历程更值得细嚼慢咽 公开信的问题发邮件给学校办公室，给校长邮箱，我是不知道会不会有人看到，或者能有多大的反响，站在我自己的角度上，我肯定是希望校长本人能看见，然后我还想像着趁校长吃饭的空隙，上演5分钟演讲感动全世界的戏码。其实就在我点发送的一瞬间，多米诺效应就开始了。首先指出我的几个问题，我把事情想象的太简单了。 道德绑架我是出于一种目的来挑战校长的比赛，虽然说以公益的名义，但是糊里糊涂的校长就被我拉上船了，在与管理学校社交平台的学长的沟通上，也是这个问题阻碍了帮我转发。 我没写输了怎么办我只写了赢了，好，校长你施舍点我吧。但是我真想不出来，我输了能怎么办，我还卖身不成么？简直胡闹么，这样影响更不好。 这两点是最致命的。我是接到了辅导员的电话，才知道我的信已经被学校宣传部拦下来了，在老师中间已经传开了，但是校长在意大利调研，所以还没回国。辅导员对我说基于这个目的是好的，但是不保证能不能行。其实我知道基于那两个致命的缺陷，校长能有一百个理由拒绝。然后又出现了一个更要命的，更“政治化”的问题。那就是学校和公益组织之间的关系，他们想知道为什么做公益还要众筹（这是雷励的传统，因此也更有挑战，基金拿来项目地的建材费用等）。他们考虑到是不是行骗组织，因为前几年清华大学就出了一件乌龙事件，自称罗斯柴尔德家族的人来访，清华大学以最高的规格接待，结果发现是骗子。基于对学生的保护，也基于对学校名誉的保护，任何情况下，校长做决定都是谨慎的。因为即使现在没有组织的任何负面新闻，不代表将来没有，所以这一点，只要校长应战了，学校和组织之间就捆绑了。 但是想不到的是，校长答应了。听说还很爽快。 关于推动这个挑战中的问题这里面的问题更多的设计营销推广文案的问题。最主要的就是我没能很好的把那么大量的阅读者人引流到众筹平台。最重要的原因就是没有做好链接。其实我重写了公开信，但是转发的都是第一版的，所以那部分上千人的受众群体其实是流失了的。想想每个人捐我1元，任务也都完成了。后来我还特地的关于众筹的写了另一个版本的面向大学生的公开信，希望能引流一部分。我还增加了很多众筹回报。在微博平台上的长微博中发布中不是还有文字描述么，这里可以增加好几个链接，我一开始增加了好几个链接到众筹回报，会长告诉我说，不要，什么都不要，直入主题，就只放一个众筹平台的链接。后来想想这才是我推文的主要目的。这无疑的正确的。 大道至简，直奔主题，细节决定成败 备战其实之前我是不抱有任何希望的，对于这件事能不能行，但是后来接到记者的电话，再得到辅导员的证实，我心情异常的激动。连我最好的一个朋友原来也说亮瞎了的想法，变成惊呆了。也是。我要是变成那么忙的人，我也会避轻就重。纵观这件事情，最要紧的点就是校长金口开了，答应了，才有了故事的后续。我并不觉得我做了多么了不起的事，我没有想象中的很努力的去争取这个机会，整天堵在校长办公室门口或怎样，寻找一个能面对面交流然后获得机会这样一个场景。我只不是在电脑前打了几行字而已。但既然要比赛了，我就努力吧。我之前基本上游泳因为场地，时间问题就没怎么游了。但还是要练，时间也挺紧张的，我当时在转塘凤凰创意园学影视后期制作，最近的游泳场所，我要去定安游泳馆，来回要三个多小时，但还是在有限的时间去了几次，在那里我遇到美院游泳队的漂亮姐姐，然后我就上去请她们指导，还有一个很有经验的老头，也请他指导我的动作，基本上一些技术性的小细节事临时改过来的。直到比赛当天上午，我还去游了1000米，但是我始终没有测试过800米到底多少成绩，然后有多大的底气。这里非常感谢陪伴我的一个朋友，赖志鹏，帮我记录了练习跳水的镜头。 梦想还是要有的，万一实现了呢？-马云最重要的是，要时刻准备着 -me火花 跟外界沟通没有和记者朋友打过交道，但毕竟看过新闻，也知道一些舆论力量，所以在接到采访电话的时候，我几乎是不敢乱说话的，就怕好事被搅浑了，没见过大场面，hold不住这架势，没打过着交道，不知道里边是怎样的。一开始我还天真的什么都说，把自己知道的都说出来，但关键就在这，你不知道你自己知道的到底是不是真的，但媒体会信以为真。后来雷励CEO 陆丰老师还打电话过来，跟我聊了。之后我尽量只谈我自己的东西，关于组织的，学校的，我就告诉他们找官方。然后陆丰老师还要求我在记者发稿的时候要看一下最终稿有没有问题。 毕竟我还承担着两方的某些利益，小心驶得万年船。还好这一环节没出什么大问题。不知道怎么放链接，我就不把新闻整理出来了。 对所说的话负责。保证知道的都是权威的。 赛后这又是我没想到的一个点。涉世未深。不过在我看来，这应该不是什么大问题，只是这种现象已经根深在人们印象中了。就是我到底该不该赢。这个问题是马后炮。因为，我事先也不知道校长的实力，校长也不知道我的实力，大家更不知道，体军部的老师也不知道。我只是一股脑的想赢，这样挑战也名正言顺。但是后来某些人说你不应该赢，我就方了，我不会做错事了吧，想想也是，我算哪根葱，校长给你面子了，你不给校长面子？我没想到这个问题，但其实在我比赛环节之前有一个老师对学生的接力友谊赛，算是热身赛，然后有队员说，老师让我们游慢一点，故意输。但我没想到我身上。想想赛后一个记者过来和我握手说，我没想到你会赢。这是看不起我还是？不过后来校领导开过会讨论过了，党组织部的老师说这样的结果是最好的，青出于蓝而胜于蓝，而且学校游泳队取得了不俗的成绩，比不过老师说不过去。各位，你们想想，我是个年轻人，体力上本来就占有一定的优势，校长58岁，还能保持这样的竞技状态，这样的生活态度，这才是重点。况且我赢的不多，才十几秒，我一点都没放水，要不是途中多次咬牙坚持，我还很又可能输。就凭这一点，我真的很佩服我们校长。 不过我真是感受了一把受网络键盘侠攻击的滋味。 辅导员也说，这些人很多的啊，不要管。但我想想，很大的原因，还是因为信息的不对称，媒体没有很好的做好中介，把事情原本的样子展现出来。 但愿我不被规矩世俗束缚，追求本真 最后谢谢钱江晚报的一个朋友，帮我做的一个简短的视频，记录这美妙的时刻。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[编码总结]]></title>
      <url>%2F2016%2F10%2F04%2Fencoding%2F</url>
      <content type="text"><![CDATA[这篇很长！！！先看一下目录。 更新： python脚本文件的编码 添加vim编码的链接 问题的根源因为计算机是二进制的，为了能在计算机上显示字符，又因为是电脑是美国人发明的，他们定义了字符表（ascii码表），也就是字符和数字的对应，比如在ascii码表中65表示A，这样就有一对一的映射关系，字符就能用数字表示了，那样计算机也就算懂得“文字”了。而ascii码表是用到了0~127这样一个范围，0*** **** 7位二进制，但是电脑普及之后，其他国家也想在电脑上显示自己的文字，因为一个字节是8位么，有些可以把8位中的最高位利用起来，定义一些其他字符，然后兼容ascii码，但是有些国家像中国，8位是远远不够的，所以就有了像gbk,gb2312这样的自己定义的一组字符编码表。后来国际上统一制定了一个叫unicode的字符编码表，能够包含所有国家的文字 那unicode到底是什么？这里其实有好几个不同的概念 不要混淆概念 字符集(Abstract character repertoire) 编码字符集(Coded character set) 字符编码方式 (Character encoding form) 字符编码方案 (Character encoding scheme) 字符集第一层，可以看作是抽象层，我就是我们人类的视角，看到的我们的语言的文字集合 不同文字系统在记录信息上的能力是等价的。进一步讲，文字只是信息的载体，而非信息本身。不用文字，用其他的载体（数字）也可以存储同样意义的信息。吴军《数学之美》 编码字符集就是给抽象的字符编上数字，可以看作逻辑层。 如gb2312中的定义的字符，每个字符都有个整数和它对应。一个整数只对应-着一个字符。反过来，则不一定是这个说法有点模糊，反过来不一定是，是说在这个gb2312定义的字符中，一个字符能有多个整数对应，一个整数只对应一个字符的意思吗？一对多的关系？如果是这样，那没有意义啊，如果是因为在不同编码方式下，比如,这里只是假设打比方啊，在a编码表中，&quot;中&quot;对应52,在b编码中&quot;中&quot;对应77,这样说一个字符对应不同的整数还说的通，但是这样77在a中就能对应其他字符了，与一个整数只对应着一个字符在这个条件下也就矛盾了。所以我不知道这句话说的到底是什么意思 但只需要知道这里所说的映射关系，是数学意义上的映射关系，编码字符集是与计算机无关的,unicode就在这一层 字符编码方式记得组原里面的逻辑结构和存储结构的概念，这里的字符编码方式就对应着存储结构的这个概念，它是与计算机有关的 通俗的说，意思就是怎么样才能将字符所对应的整数的放进计算机内存，或文件、或网络中。于是，不同人有不同的实现方式，所谓的万码奔腾，就是指这个。gb2312，utf-8,utf-16,utf-32等都在这一层。 这里就有问题了，既然像unicode已经定义了文字对数字的对应了，那直接就那样存就行了？too young, too simple， 不是那么简单。要考虑到存储空间，提一下，因为会有很多零，考虑到这些，所以逻辑形式和存储形式会不一样。下面详解 字符编码方案 这个更加与计算机密切相关。具体是与操作系统密切相关。主要是解决大小字节序的问题。对于UTF-16和UTF-32编码，Unicode都支持big-endian 和 little-endian两种编码方案。一般来说，我们所说的编码，都在第三层完成（字符编码方式）。具体到一个软件系统中，则很复杂。浏览器－apache－tomcat（包括tomcat内部的jsp编码、编译，文件读取）－数据库之间，只要存在数据交互，就有可能发生编码不一致，如果在读取数据时，没有正确的decode和encode，出现乱码就是家常便饭了。 我理解就是这一层就是考虑大端还是小端存储，这是和不同计算机具体设计所不同的。 unicode刚说了unicode是在第二层，只是理论上的，什么叫只是理论上的，它是理想的，他定义了字符与一个数字的关系，仅仅而此。他没有定义编码在电脑中的具体存储形式。比如 中 对应是4E2D 0100 1110 0010 1101 它不就这样存着就好了么？ 不是这样的。看A 是41,0000 0000 0100 0001 如果都按照这样直接存着，有一个问题就是太浪费资源了，8位还好，16位的话，有那么多个0，存储空间都浪费了，而且传输的时候也浪费不必要的带宽，所以这是理论上编码和具体实现的差别。在实际存储到计算机上要考虑其他因素，正是有这些因素，导致了utf-8，utf-16,utf-32等，基于unicode的编码方式。 但有些编码不只是定义了影射关系，除了有字符集同时也包含了字符编码的含义，也就是这样定义的也是这样存的。如ASCII,GBK,GB2312等， unicode 只是定义了编码。没有定义怎么具体实现。 unicode 作为字符集(usc)是唯一的，编码方案(utf)才是有很多种。 也就是怎么存储，比如中，用的最多的是utf-8 utf-8 具体utf-8是怎么和unicode对应不是这里的讨论重点，终点是unicode和utf-8的关系，unicode是理想的，虚浮的，utf-8才是真实的显示的。unicode是一个code point，他还是需要被表示成一个一个binary,这就需要encode. In Unicode, a letter maps to something called a code point which is still just a theoretical concept. How that code point is represented in memory or on disk is a whole nuther story. 例子1234567891011&gt;&gt;&gt; import sys&gt;&gt;&gt; sys.stdin.encoding'UTF-8'&gt;&gt;&gt; c = '中文'&gt;&gt;&gt; c'\xe4\xb8\xad\xe6\x96\x87'&gt;&gt;&gt; cu = c.decode('utf-8')&gt;&gt;&gt; cuu'\u4e2d\u6587'&gt;&gt;&gt; cu.encode('gbk')'\xd6\xd0\xce\xc4' It does not make sense to have a string without knowing what encoding it uses. 这句话很重要。这里就先知道c这个字符串是由utf-8编码的。也就是计算机里面存的就是\xe4\xb8\xad\xe6\x96\x87对应的二进制。其实编码可以看作一个给unicode加密的过程,解码就是从字符串到unicode解密的过程。其实最终在计算机里只是一些010101010这样的数字，关键就是看你怎么看待它，怎么去翻译它的问题，翻译不正确就没有意义。 c 是由utf-8来编码的，解码之后unicode code point 是4e2d 6587, 代表&#39;中文&#39;，再对它进行gbk编码，它则变成了&#39;\xd6\xd0\xce\xc4&#39;, 所以字符集在不同编码方式下可能对应的实际存储形式是不一样的。 但反过来。给你一串这个数字 ， 不知道它的编码方式是毫无意义的。因为unicode定义了这个地球所有的字符和数字的映射关系，看作是一个“上层建筑”，一个蓝图，各个编码就是具体的施工，因为地形的原因，气候关系，各个国家根据这个蓝图都会有有些变动（这个例子不够好）。 同一个unicode在不同编码下肯定是不一样的,但是不同的unicode在不同的编码下有可能是一样的。这个很容易验证，只要随便找个字符字节，decode一下，只要能decode出来，这个字节符合编码的格式，然后还原出来的unicode就是在那个编码下对应的unicode但是两者是相同的字节。下面有一个例子，看下面。所以，像\xe9这种给出不一定就是utf-8编码方式，有些只是刚好符合编码格式，但是不一定有意义。 1234&gt;&gt;&gt; c.decode('ascii')Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; UnicodeDecodeError: 'ascii' codec can't decode byte 0xe4 in position 0: ordinal not in range(128) 因为c不是utf-8来编码的所以用ascii来“解密”这个逆过程是行不通的当得到了unicode又可以用不同的“加密方式”加密了。 python中的编码深入（python2）首先明确0x41和\x41的区别123456789&gt;&gt;&gt; 0x4165&gt;&gt;&gt; \x41 File "&lt;stdin&gt;", line 1 \x41 ^SyntaxError: unexpected character after line continuation character&gt;&gt;&gt; '\x41''A' 0x41是numeric ，\x41是 character，它只有在字符串中才有意义。 两者虽然在电脑中都是存着01000001,但是看待它的角度不一样。 str类和unicode类str和unicode是两个不同的类在python的REPL中，类似w = &#39;{whatever}&#39;，这样给出的，代表w是一个str， str hold bytes ! str hold bytes ! str hold bytes !str 存储的是已经编码后的字节序列，输出是看到每个字节用16进制表示，以\x开头，每个汉字会占用3个字节的长度。 str is string of bytesunicode is string of unicode character 1234567891011121314&gt;&gt;&gt; c='中文'&gt;&gt;&gt; c'\xe4\xb8\xad\xe6\x96\x87'&gt;&gt;&gt; cu=u'中文'&gt;&gt;&gt; cuu'\u4e2d\u6587'&gt;&gt;&gt; print c中文&gt;&gt;&gt; print cu中文&gt;&gt;&gt; len(c)6&gt;&gt;&gt; len(cu)2 cu=u&#39;中文&#39;表示cu的编码指定为unicode了。这个是python的内部编码。我现在有一个疑问，那这个cu在内存中保存的是什么样的？？？ [Todo] 一个以bytes 为单位，一个以unicode character 为单位 Unicode started out using 16-bit characters instead of 8-bit characters.!!! 我的理解是len(cu) == 2 表示cu里面有2个code pointlen（c) == 6 表示c有6个bytes 那这里就有两个问题了-[x] str存储已经编码后的字节序列，是用什么编码？？从键盘上按下到屏幕上显示的这一步我们先不管，我猜想是涉及到键盘的工作原理Todo和输入法的原理[Todo],改天再把这一块补上，现在先就关注再python内部的编码。123import sys&gt;&gt;&gt; sys.stdin.encoding'UTF-8' 是默认用sys.stdin.encoding来编码输入的字符。 说到这里，python中有好几个有关编码的函数或值 sys.stdin.encoding sys.stdout.encoding sys.getdefaultencoding() sys.getfilesystemencoding() 各自的用处都不一样 -[] w＝&#39;中文&#39; 是需要编码一下的 用utf-8那这样 w = &#39;\xe9&#39;也要先utf-8编码？这个我还不清楚，因为不可能一个不编码，一个编码，应该是统一的形式，但是对\xe9进行utf-8的编码是不行的因为对于但字节的，utf-8是高位是0开头的，所以这个不可能用utf-8编码成功，所以我猜测是因为\x,有这个，直接以字节码的形式传入进来了不用编码了。 print当做print c的时候，会把c的byte string， 也就是字节流传到终端，终端接受到这一组字节流要用终端的编码来解码这个字节流（毕竟不是字符集，传送过来的只是编码方式，所以找字符对应关系还得还原），这样就又回到了unicode的形式，然后接下来就是字符怎么显示到计算机屏幕上的问题了 实验12345&gt;&gt;&gt; c = '中文'&gt;&gt;&gt; c.decode('utf-8')u'\u4e2d\u6587'&gt;&gt;&gt; c.decode('utf-8').encode('gb2312')'\xd6\xd0\xce\xc4' 我在iTerm下先把Terminal的Character Encoding改为GB 2312可以看到结果是被正确打印出来但当我把编码随便改成另外国家的然后再打印的时候就不对了但是！ cg里面保存是一样的 这也就是说当你终端的编码和在python中处理字符的编码不一致的时候，打印结果可能出现问题。之所以是可能，因为如果都是英文的话，因为都兼容ascii码,所以会打印出你想要看到的样子。 12345&gt;&gt;&gt; cg = '\xd6\xd0\xce\xc4'&gt;&gt;&gt; cg.decode('iso 8859-11')u'\u0e36\u0e30\u0e2e\u0e24'&gt;&gt;&gt; cg.decode('gb2312')u'\u4e2d\u6587' 这里就是不同unicode在不同的编码下有着相同的字节的例子然后1234&gt;&gt;&gt; cg.decode('iso 2022-jp')Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; UnicodeDecodeError: 'iso2022_jp' codec can't decode byte 0xd6 in position 0: illegal multibyte sequence 上面那个能对iso 8859-11解码也只是凑巧，这个对iso 2022-jp就不行。 实验2如果是print一个unicode对象的话12345&gt;&gt;&gt; cgt = cg.decode('iso 8859-11')&gt;&gt;&gt; print cgtTraceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; UnicodeEncodeError: 'ascii' codec can't encode characters in position 0-3: ordinal not in range(128) 看着样子好像是要转化成字节流传送到终端再解码。那这样不会出现什么问题么？因为unicode的code point和字符之间是一一对应的，我编码成utf-8也好，gbk也好，其他什么的也好，只要能编成，我只是用它做个过度，我只需确保解码的时候用的是一致的编码的就行了，现在这里的问题就是ascii码不能编成，因为格式不支持。这个ascii应该是sys.getdefaultencoding()的。以下终端编码是utf-812345&gt;&gt;&gt; cgt = cg.decode('iso 8859-11')&gt;&gt;&gt; cgt.encode('utf-8')'\xe0\xb8\xb6\xe0\xb8\xb0\xe0\xb8\xae\xe0\xb8\xa4'&gt;&gt;&gt; print '\xe0\xb8\xb6\xe0\xb8\xb0\xe0\xb8\xae\xe0\xb8\xa4'ะฮฤ 这个显示的不知道是不是一致的，看着又像又不像，少了一个点貌似，到底对不对？？ 读取文件读文件，文件的编码现在我先建立一个gbk.txt的文件，在vim中:set fileencoding=gbk,有关vim中的编码看这里输入内容我叫陈烨保存。先看一下utf-8的编码长什么样，gbk编码长什么样12345&gt;&gt;&gt; c = '我叫陈烨'&gt;&gt;&gt; c'\xe6\x88\x91\xe5\x8f\xab\xe9\x99\x88\xe7\x83\xa8'&gt;&gt;&gt; c.decode('utf-8').encode('gbk')'\xce\xd2\xbd\xd0\xb3\xc2\xec\xc7' 然后读取文件1234&gt;&gt;&gt; f = open('gbk.txt')&gt;&gt;&gt; fr = f.read()&gt;&gt;&gt; fr'\xce\xd2\xbd\xd0\xb3\xc2\xec\xc7\n' 可以看出，我保存的是gbk编码格式，现在读入的也是gbk编码的格式，因为计算机他操作的就在“第三层”（这里先忽略第四层）所以，如果我不知道原来文件的编码是什么，直接操作文件内容也是没有意义的，只是现在大部分都是utf-8，一切都恰好行的通，等出现乱码的时候就应该知道是编码出现问题了。 读文件，文件内容的操作现在我建立一个文件叫做wr.TARIN , 这是里面的内容是你好 中国 Hello China 1 2 31234567&gt;&gt;&gt; import sys&gt;&gt;&gt; sys.getfilesystemencoding()'utf-8'&gt;&gt;&gt; f = open('wr.TRAIN')&gt;&gt;&gt; content=f.readline()&gt;&gt;&gt; content'\xe4\xbd\xa0\xe5\xa5\xbd \xe4\xb8\xad\xe5\x9b\xbd Hello China 1 2 3\n' 这个sys.getfilesystemencoding()是不是用来文件解码的还不清楚！！！【Todo】文件都是以字节流的方式读进来的？ 但不管怎么样，读进来的是一段字符串，重点是你怎么看，都是这样的01010的数字，关键在于怎么翻译，所以要知道它文件原来的编码方式。123456789&gt;&gt;&gt; content_list = content.split()&gt;&gt;&gt; content_list['\xe4\xbd\xa0\xe5\xa5\xbd', '\xe4\xb8\xad\xe5\x9b\xbd', 'Hello', 'China', '1', '2', '3']&gt;&gt;&gt; print content你好 中国 Hello China 1 2 3&gt;&gt;&gt; print content_list['\xe4\xbd\xa0\xe5\xa5\xbd', '\xe4\xb8\xad\xe5\x9b\xbd', 'Hello', 'China', '1', '2', '3']&gt;&gt;&gt; print content_list[0]你好 那这里就有一个问题，为什么print content_list显示的是以这样的形式，而不是[&#39;你好&#39;,&#39;中国&#39;,&#39;Hello&#39;,&#39;China&#39;,&#39;1&#39;,&#39;2&#39;,&#39;3&#39;]这样子？这其实是两个问题。content_list是list类型，它不是一个str！！！123456789&gt;&gt;&gt; l = ['中文','你好']&gt;&gt;&gt; l['\xe4\xb8\xad\xe6\x96\x87', '\xe4\xbd\xa0\xe5\xa5\xbd']&gt;&gt;&gt; print l['\xe4\xb8\xad\xe6\x96\x87', '\xe4\xbd\xa0\xe5\xa5\xbd']&gt;&gt;&gt; print str(l)['\xe4\xb8\xad\xe6\x96\x87', '\xe4\xbd\xa0\xe5\xa5\xbd']&gt;&gt;&gt; str(l)"['\\xe4\\xb8\\xad\\xe6\\x96\\x87', '\\xe4\\xbd\\xa0\\xe5\\xa5\\xbd']" 在打印list类型的时候，会先把list转为str，这样就发现\x编程了\\x，相当于\xe4原本表示编码的，被当成字符串处理了，说了一切看你怎么看的问题。但其实本来是list转为字符串格式的话，会调用repr来转化，但是效果是和str是一样的。12&gt;&gt;&gt; repr(l)"['\\xe4\\xb8\\xad\\xe6\\x96\\x87', '\\xe4\\xbd\\xa0\\xe5\\xa5\\xbd']" 12345&gt;&gt;&gt; lc = ','.join(l)&gt;&gt;&gt; print lc中文,你好&gt;&gt;&gt; lc'\xe4\xb8\xad\xe6\x96\x87,\xe4\xbd\xa0\xe5\xa5\xbd' 但是如果想要有[...]的效果怎么办12&gt;&gt;&gt; print str(l).decode('string_escape')['中文', '世界'] string_escape是转义字符123456&gt;&gt;&gt; repr(l)"['\\xe4\\xb8\\xad\\xe6\\x96\\x87', '\\xe4\\xbd\\xa0\\xe5\\xa5\\xbd']"&gt;&gt;&gt; repr(l).decode('string_escape')"['\xe4\xb8\xad\xe6\x96\x87', '\xe4\xbd\xa0\xe5\xa5\xbd']"&gt;&gt;&gt; print "['\xe4\xb8\xad\xe6\x96\x87', '\xe4\xbd\xa0\xe5\xa5\xbd']"['中文', '你好'] 也就是相当于把\\x还原回\x了的一步操作。如果已经是\x再这样弄，没什么效果。 写入文件12345&gt;&gt;&gt; ','.join(content_list)'\xe4\xbd\xa0\xe5\xa5\xbd,\xe4\xb8\xad\xe5\x9b\xbd,Hello,China,1,2,3'&gt;&gt;&gt; fw = open('out.TEST','w')&gt;&gt;&gt; fw.write(','.join(content_list))&gt;&gt;&gt; fw.close() 还可以用unicode统一来处理文本，不过在写入文件时，还是要转换为“第三层”的格式，毕竟unicode是虚浮的！！！12345678910&gt;&gt;&gt; fw=open('out.TEST','w')&gt;&gt;&gt; content_u_list_conjunction = ','.join(content_u_list)&gt;&gt;&gt; content_u_list_conjunctionu'\u4f60\u597d,\u4e2d\u56fd,Hello,China,1,2,3'&gt;&gt;&gt; fw.write(content_u_list_conjunction)Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;UnicodeEncodeError: 'ascii' codec cant encode characters in position 0-1: ordinal not in range(128)&gt;&gt;&gt; fw.write(content_u_list_conjunction.encode('utf-8')) #要指定encode编码，不然用默认的&gt;&gt;&gt; fw.close() 这个默认的应该就是sys.getdefaultencoding()指定的吧。 python 脚本文件的编码经常可以看到一些.py文件的头两行是怎么写的1234#!/usr/bin/env/python# coding=utf-8# 或# -*- coding: utf-8 -*- If a comment in the first or second line of the Python script matches the regular expression coding[=:]\s*([-\w.]+), this comment is processed as an encoding declaration; the first group of this expression names the encoding of the source code file. The encoding declaration must appear on a line of its own. If it is the second line, the first line must also be a comment-only line. The recommended forms of an encoding expression are # -*- coding: &lt;encoding-name&gt; -*-from Encoding declarations Python will default to ASCII as standard encoding if no other encoding hints are given.from PEP 263 – Defining Python Source Code Encodings 如果没有指定，脚本默认会用ascii码来解析文件内容，这时如果遇到有中文的，那就会报错 还有一些example 参考资料 The Absolute Minimum Every Software Developer Absolutely, Positively Must Know About Unicode and Character Sets (No Excuses!) python新手必碰到的问题—encode与decode，中文乱码 字符编码详解 Unicode HOWTO Meaning of 0x and \x in python hex strings? unicode-table Why does Python print unicode characters when the default encoding is ASCII? len() with unicode strings Python, len and slices on unicode strings len(unicode string) Python 2.7 解决写入文件的中文乱码问题 python write file dealing with encode Pragmatic Unicode Python编程的中文问题 Python2字符编码问题小结 1,2,4,7,13,14 推荐要看一下 一些重要的摘出来4 The Unicode standard describes how characters are represented by code points. A code point is an integer value, usually denoted in base 16. In the standard, a code point is written using the notation U+12ca to mean the character with value 0x12ca (4810 decimal). The Unicode standard contains a lot of tables listing characters and their corresponding code points:123456&gt; 0061 &apos;a&apos;; LATIN SMALL LETTER A&gt; 0062 &apos;b&apos;; LATIN SMALL LETTER B&gt; 0063 &apos;c&apos;; LATIN SMALL LETTER C&gt; ...&gt; 007B &apos;&#123;&apos;; LEFT CURLY BRACKET&gt; Strictly, these definitions imply that it’s meaningless to say ‘this is character U+12ca’. U+12ca is a code point, which represents some particular character; in this case, it represents the character ‘ETHIOPIC SYLLABLE WI’. In informal contexts, this distinction between code points and characters will sometimes be forgotten. A character is represented on a screen or on paper by a set of graphical elements that’s called a glyph. The glyph for an uppercase A, for example, is two diagonal strokes and a horizontal stroke, though the exact details will depend on the font being used. Most Python code doesn’t need to worry about glyphs; figuring out the correct glyph to display is generally the job of a GUI toolkit or a terminal’s font renderer. a Unicode string is a sequence of code points, which are numbers from 0 to 0x10ffff. This sequence needs to be represented as a set of bytes (meaning, values from 0-255) in memory. The rules for translating a Unicode string into a sequence of bytes are called an encoding. 12There are many encodings and they define 128-255 differently. For example, character 185 (0xB9) is ą in windows-1250 encoding, but it is š in iso-8859-2 encoding.So, what happens if you print \xb9? It depends on the encoding used in the console. In my case (my console uses cp852 encoding) it is:123&gt; &gt;&gt;&gt; print '\xb9'&gt; ╣&gt; Because of that ambiguity, string ‘\xb9’ will never be represented as ‘╣’ (nor ‘ą’…). That would hide the true value. (这里解释了为什么用\xb9这样字节来保存，而不打印出来实际的字符)It will be represented as the numeric value:123456&gt; &gt;&gt;&gt; '\xb9'&gt; '\xb9'&gt; #Also:&gt; &gt;&gt;&gt; '╣'&gt; '\xb9'&gt; But what happens if variable is just entered in the console?When a variable is enteren in cosole without print, its representation is printed. It is the same as the following:123&gt; &gt;&gt;&gt; print repr(content)&gt; '\xe4\xbd\xa0\xe5\xa5\xbd \xe4\xb8\xad\xe5\x9b\xbd Hello China 1 2 3\n'&gt; Unlike str objects, which are strings of bytes, unicode objects are strings of unicode characterscharacters != bytes. a utf16 character is 2 bytes, but only one character 14 内置的open()方法打开文件时，read()读取的是str，读取后需要使用正确的编码格式进行decode()。write()写入时，如果参数是unicode，则需要使用你希望写入的编码进行encode()，如果是其他编码格式的str，则需要先用该str的编码进行decode()，转成unicode后再使用写入的编码进行encode()。如果直接将unicode作为参数传入write()方法，Python将先使用源代码文件声明的字符编码进行编码然后写入。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[project of stackoverflow - python piece (一)]]></title>
      <url>%2F2016%2F02%2F12%2Fstackoverflow-python-piece-1%2F</url>
      <content type="text"><![CDATA[Why does Python print unicode characters when the default encoding is ASCII? 在python 2.6的交互式界面中：123456&gt;&gt;&gt; import sys&gt;&gt;&gt; print sys.getdefaultencoding()ascii&gt;&gt;&gt; print u'\xe9'é&gt;&gt;&gt; 我原本预想打印出来的结果是乱码或者直接报错，因为字符 “é” 并不是ASCII码所定义的范围，而且我没有指定编码。我想我是不是没有懂这个ASCII码作为默认编码的真正意思。 73票的回答： 谢谢不同回复的各方面的回答，我觉得我们可以连起来成一个解释当尝试着去打印unicode字符串的时候，u&#39;\xe9&#39;，Python会隐式的先尝试去对这个字符串用sys.stdout.encoding返回的编码方案编码。实际上，python在一开始初始化的时候就记录了这个设置。如果不能在环境中找到合适的编码，才会使用默认的ASCII码编码。 比如，我使用一个默认编码是UTF-8的bash shell。当我在它上启动python，它会使用这个设置：12345$ python&gt;&gt;&gt; import sys&gt;&gt;&gt; print sys.stdout.encodingUTF-8 让我们先暂时退出python shell然后重新用一些伪造的编码设置bash的环境12$ export LC_CTYPE=klingon# we should get some error message here, just ignore it. 然后重新启动python shell，证实一下他确实恢复到它默认的acsii编码12345$ python&gt;&gt;&gt; import sys&gt;&gt;&gt; print sys.stdout.encodingANSI_X3.4-1968 那就对了！ 如果现在你要打印一些在ascii码定义之外的unicode字符，你就会得到漂亮的错误提示123&gt;&gt;&gt; print u'\xe9'UnicodeEncodeError: 'ascii' codec can't encode character u'\xe9' in position 0: ordinal not in range(128) 让我们退出python，不要管bash shell 我们现在在python输出字符后观察会发生什么。为了能够观察，我们需要在图形界面的终端启动bash shell(我使用的是Gnome Terminal)然后我们设置终端的输出编码为ISO-8859-1 aka latin-1(图形界面的终端通常在下拉菜单里面都有可以设置字符编码的选项)注意，这个不会改变shell 真正的环境编码。他只改变终端自己对于给出输出的解码方式，有点像浏览器的行为。因此你可以改变终端的编码，那是和shell环境的编码是相互独立的。然后启动从shell中启动python，核实一下sys.stdout.encodin是被设置成shell的环境编码(我的是UTF-8)： (我：插一句，bash shell的环境编码是由LC_CTYPE决定的。然后终端改为latin-1的编码，应该先在编码正常utf-8的时候先启动，然后再改编码，否则，至少我尝试下来如果一开始用latin-1编码启动终端，注意是启动终端，sys.stdou.encoding是ascii)1234567891011121314$ python&gt;&gt;&gt; import sys&gt;&gt;&gt; print sys.stdout.encodingUTF-8&gt;&gt;&gt; print '\xe9' # (1)é&gt;&gt;&gt; print u'\xe9' # (2)Ã©&gt;&gt;&gt; print u'\xe9'.encode('latin-1') # (3)é&gt;&gt;&gt; (1) python 如实的输出二进制字节字符串，然后终端接受到这个，然后尝试着去用latin-1的字符映射来匹配它的值。在latin-1，0xe9或者233对应字符&quot;é&quot;,这也是终端的显示 (2) 不管当前设置在sys.stdou.encoding的编码方案是什么，python先隐式的用这个来编码unicode，在这个例子中是UTF-8。在UTF-8编码完了后,编成了一串二进制字符串\xc3\xa9（后面会解释）。终端接受到这个字节流后然后尝试着去用latin-1去解码0xc3a9，但是latin-1的范围是0到255，所以会一个字节一个字节的解码，0xc3a9是2个字节长，因此latin-1的解码器会解释成0xc3(195)和0xa9(169),这两个对应的字符分别是Ã和©. (3) python 会用latin-1的编码方案来编码unicode的code point u&#39;\x9&#39;(233)。事实是latin-1的code point的范围是0-255,然后刚好好unicode字符指向在那个范围内（Turns out latin-1 code points range is 0-255 and points to the exact same character as Unicode within that range. ）。因此，在那个范围内的unicode code point 用latin-1编码会产生相同的值。所以u&#39;\xe9&#39;(233)在用latin-1编码后，会产生二进制字符串\xe9。终端接受这个值后，尝试这种latin-1的字符映射来匹配这个值，就像第（1）中情况一样，它对应&quot;é&quot;，在屏幕上也是这么显示的。 (我：在二进制的时候，是直接去找对应关系，不用用这个编码去解码到unicode再去找对应，我理解错了) 现在我们在下拉菜单下面将终端的编码设置为UTF-8（就像你改变浏览器编码一样）。不需要中断python或重启shell。现在终端的编码和python的一致了，我们来重新尝试打印：1234567&gt;&gt;&gt; print '\xe9' # (4)&gt;&gt;&gt; print u'\xe9' # (5)é&gt;&gt;&gt; print u'\xe9'.encode('latin-1') # (6)&gt;&gt;&gt;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[how character display on screen]]></title>
      <url>%2F2015%2F11%2F12%2Fhow-character-display-on-screen%2F</url>
      <content type="text"><![CDATA[我知道ascii码2c 是“，”逗号，但是计算机是怎么知道它是“逗号”的？ 简答：有时候不是会安装字体font么，里面就有对应的字型。要显卡渲染形成的。大体过程是：字符编码（Unicode）→字体的形索引（Glyph ID）→字形轮廓→点阵图字形 计算机是如何显示文字的呢？计算机要对文字进行存储后就需要显示出来，而我们的液晶屏都是一个个的像素点组成的，这就必须要对文字进行渲染绘制，发送到显卡中进行栅格化和显示等操作。Dos下最简单，利用主板BIOS就能对ascii码进行点阵化输出。 字符显示器，显示字符的方法以点阵为基础，点阵是指由m*n个点组成的阵列，点阵的多少取决于显示字符的质量和字符窗口的大小。 字符窗口是指每个字符在屏幕是那个所占的点数。它包括字符显示点阵和字符间隔。 将点阵存入由rom构成的字符发生其中，在CRT进行光栅扫描的过程中，从字符发生器中一次读出某个字符的点阵，按照点阵中0和1的代码不同控制电子束的开或关，从而在屏幕上显示出字符，对应每个字符窗口，所需显示字符的ACSII代码被存放在视频存储器VRAM中，以备刷新 参考 假如说这个程序是 xterm ，它会通过 X core font API ，将这个字符直接送给 Xorg ，由 Xorg 来完成字体渲染（当然现在 xterm 也支持 libXft 了，不过先不管这个）。Xorg 拿到应用程序送来的请求之后，会在字体中检索每个字对应的字形，然后渲染出来。这个检索过程中用到的索引，就是我们之前给字符编上的号。如果要指定字体，需要向Xorg提供一个长得像这样：“-adobe-times-medium-r-normal–12-120-75-75-p-64-iso8859-1” 的字符串来指定字体。 作者：乌鸦链接：https://www.zhihu.com/question/24340504/answer/28902204来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 在UNIX终端上和DOS里 ， 字符是终端或显卡（使用内置字库）绘制的，不但跟unicode和freetype什么的没有任何关系，而且跟操作系统都没有关系。打印机也是如此：当你把一个文本文件直接发送给打印机，打印机使用内置的字库绘制每个文字和符号著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。作者：姜维链接：http://www.zhihu.com/question/24340504/answer/27969692来源：知乎 介绍到这里，大家应该对整个字体的绘制过程有个整体的认识了，首先是经过字符编解码，将硬盘中存储的有对应编码的文本文件进行加载，例如Java的文件IO，变成内存中的字符串对象，也就是符合本语言字符串存储特性的数据，（当然如果你愿意，也可以当做二进制读入，然后再手段转换编码，也是可以的），绘制时则首先调用对应的CodePage进行编码的索引查找，找到对应的字体字形索引，然后根据字形索引获取到字库中的数据，根据系统提供的绘制曲线绘制样条线的方法进行图形渲染，这样就能得到显示器上的图像了。而更高级的就是对字体进行反走样，锐化，等更为细节的操作了。著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。作者：孙笑凡链接：http://www.zhihu.com/question/24340504/answer/29927340来源：知乎]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[【转】如何从菜鸟程序员成长为高手]]></title>
      <url>%2F2015%2F04%2F07%2Frookie-to-master%2F</url>
      <content type="text"><![CDATA[原文链接 下面这篇优秀的文章来自Axb的自我修养，写得很直白、很真实，很有营养，分享在这里与君共勉！口头禅 这其实是两个问题 （不要混淆概念）还有没有更好的方案 （不要思维局限）能不能举个例子 （理论实际相结合）能不能给个一句话总结 （说明自己掌握了重点） 摘要最近有一些毕业不久的同事问我：“你工作的时候有没有什么窍门？怎么才能快速成为高手？” 想起当初刚入职，新人培训的时候，也跟其他同事讨论过这个问题：如何才能成为业界大牛？当时自己只是觉得兴趣是最好的老师，思路方法什么的没有多想。 加入微博平台架构部的时间也不短了，趁着快过春节总结了一下自己入职微博以来的工作情况，从互联网开发的半个门外汉，到如今能设计一些架构、排查一些问题、分享一些经验，收获颇多，感想颇多,也逐渐意识到思路和方法的重要性，在此跟大家分享一下。主要分为学、做、想三方面。 学会学习学习无疑是程序员最为重要的素质之一，尤其是互联网这种日新月异的行业，把学习当做工作的一大半也不为过。 自主学习最近发现身边的人并不是不想学习，只是每天都在纠结自己到底学什么好：简单的没挑战，复杂的看不懂；旧技术怕过时，新技术没方向…… 讲讲自己毕业后的经历，毕业之后去了个不大不小的公司，工作主要是做一些XX管理系统之类的东西，没什么挑战，也用不上什么技术，基本上前端用个extjs后面套个sql server就解决了。工作稳定了几年，业余时间除了wow没别的事情做，觉得这么闲下去不是办法，于是之后一年的时间里，用上班摸鱼和下班休息的时间学了这些东西： 闲着无聊想做个小游戏，发现游戏相关的书大多是英文的，看不懂，一咬牙翻译了《Real-time rending 3rd》的前几章，刚开始前言都看不懂，只能一个词一个词的翻字典，一句话要琢磨几个钟头到底作者说的到底是什么意思。翻译了几百页英文书之后，发现自己看英文书没什么障碍了，于是开始每天用休息和摸鱼的时间看书。 看完游戏引擎的书之后，把irrlicht引擎的代码看了一遍，然后自己山寨了一个3d渲染的场景管理器，还有个朴素的渲染引擎。 给自己的游戏引擎写了个基于脚本语言的解释器，为此看了不少编译原理和虚拟机的书，了解了程序究竟是什么东西，这是我觉得收益很大的一件事情。 看编译原理的书的时候发现操作系统的知识有些欠缺，又去看了linux内核相关的书。之后买了个开发板天天修改内核玩，毕业以后又一次了解了内核的cpu调度、内存管理和文件系统，了解了应用是怎么跑在操作系统上，操作系统又是怎么运行在硬件上的，这也是收益很大的一件事情。 看完操作系统又顺着看网络相关的书，之后把lighthttpd的代码看了一遍，用c写了个linux下的http服务器，把几种网络编程模型挨个实现了一遍。 实现http服务器的过程中觉得自己编码能力还是有欠缺，把代码大全翻了一遍，顺着又去看了设计模式的书，并且用自己的理解把每个模式用文字重新描述了一遍。 中间还看了很多语言和框架相关的书，就不一一列举了。 我把学习的方向分为三类： 为了工作，满足当前工作所必备的知识 为了提升，与当前工作相关的知识（深度） 拓展视野，与当前工作无关的知识（广度） 学习（1）之后只是个熟练工，2和3才是提升自己的途径，伴随着知识储备的提升，接触新事物时更容易找到相似的知识加以类比，加快理解，也更容易掌握本质。如果每天都在纠结“到底学什么”，那么只能说明还是学的太少了。（真正没什么可学的大牛们应该不会读到这里吧……） 所以，如果觉着没什么东西可以学的时候，那么可以考虑一下学一下更有深度的知识（比如虚拟机或编译器），或者完全不同的知识（新的语言或当前比较火的方向），甚至完全不相干的知识（单纯练习英文阅读，学习ppt排版之类）吧。随着知识储备增加，自己的不足和未来的学习的方向也会更加明确起来。 向历史学习以微博为例，在微博发展的过程中经历了不少波折，并逐渐衍生出了目前的系统架构。很多新人最喜欢问的问题便是“现在线上是怎么做的？” 这个问题不错，但是还不够好。在程序员的世界里罕有能解决所有问题的“银弹”，当前的做法用不了多久也会被替换掉，如果想了解一件事情，那么就多关注一下“它是怎么变成今天这样的”吧。学会用发展的眼光看问题，了解一些经历过的经验教训，收获会比单纯学会一件什么事情多的多。 那么，如何向历史学习？ 公司内部的资料库、wiki等大都会有旧时的资料，刚入职时大多不会太忙，这些资料库简直是挖不完的宝藏 部门内部分享，比如我当初入职时经常去听“微博XXXX架构演化历程”之类的内部分享 多问一下自己”它为什么不那么设计 老员工忆苦思甜吹牛逼的时候多奉承几句 向他人学习这里有两个极端， 有的人喜欢自己闷头捣鼓，什么也不问，这必然是不利于自己提高的； 也有人碰到问题就问，这也有问题，浪费他人时间不说，更关键的是说明这人向他人学习的思路错了，要学习他人的并不是具体某个知识（要学知识看书就能解决了），而是学习别人的思维方式。 但是思维方式这种东西很难通过交流的方式学到，后来我发现有个很简单的学习方式：口头禅。举几个例子，大家体会一下： “这个其实是两个问题” “有没有更好的方案” “能不能举个例子” “能不能给个一句话总结”除了口头禅，很多牛人都会有非常鲜明的思维方式和处事原则，如果有幸与业界的大牛共事，那么恭喜你，只要多交流、多观察、多思考，那么提升速度会提升好几个数量级。 多做有意义的事情有的人每天时间浪费在跟问题本身无关的事情上，比如我要设计架构的时候还要考虑架构图怎么画，写完代码还要反复部署测试好几轮才pass，查bug的时候把时间浪费在扫日志上。人的精力总是有限的，把时间浪费在这些事情上面，让自己提高的时间就变得少了。 练习，更多的练习这里有个误区：“做有意义的事情”不等于“只做自己没做过的事情”。 对于程序员来说，写代码是基本功中的基本功，编码的规范、设计的权衡、甚至顺手的IDE快捷键都要靠平日的试错和积累，很难通过几本书或者几天培训领悟到。 曾经目睹一些人写代码一年之后开始做一些小项目的设计，然后就迫不及待的把重心全都转移到设计甚至架构上，这种没有基础能力支撑做出的设计和架构最多只能算是高级意淫，大多没等落地就荒废了，意义不大。究其原因，大多是设计出来的东西“不好做”或者“不好用”，就像是只看过一遍课本就去参加高数考试，现实吗？（学霸们我错了……） 举个例子，几年前在看设计模式的过程中，用qt做了个看漫画的应用，把能用的模式都试了一遍，当然有很多用的不合适的地方，正是这些不合适的地方让我对面向对象编程和设计模式的思考深入了很多，如何权衡灵活性和复杂性也有了新的认识。之后在设计很多系统的时候少走了很多弯路，既保证了时间点又保证了质量。如果当时指望着“用的时候再说”，大概已经被项目坑的不能自理了。 善用工具工具能解决的事情就用工具去解决，好的工具能节约大把的时间用在更有意义的事情上。 工具的范畴很广，比如linux的各种命令、比如团队内部的各种系统、比如顺手的应用、甚至包括上下班骑的自行车。只要能节约时间、提高效率，那就值得一试。 在这里我列举几个大幅度提升了我的效率的东西： 双屏显示器 顺手的键盘 google（不是baidu！不是bing！） mac mac上的应用：idea、alfread、omnifocus、甚至synergy和istats menus之类跟开发本身关系不大的应用。 我更倾向于把“使用工具”作为一种生活态度：是否希望让自己的生活专注于有意义的事情。如果你认同这个观点，那么想一想投入和回报比例，还是很可观的。 （当然，为了不花钱而自己破解应用的大神也是极叼的……） 提高时间的利用率时间是所有期待提升自己的人最宝贵的资源，效率再高，没时间做也没意义。 网上有个流传挺广的图：打扰程序员的成本。事实上我每天的工作时间非常碎片化，来到公司之后可能不断的接电话、被问问题、被拉去开会、回复邮件等等；也经常会有时间不够用或者没事做的困惑，这里分享一下心得： GTD可以整合很多碎片时间。除了把事做完之外，把上下文相关的事情集中在一起完成也很有帮助。比如把几件想去其他办公室做的事情整合成一趟完成。 减少无意义的时间浪费，比如家住在公司边上可以每天节省几个小时的时间用来学习或者做别的事情。（但如果节省下来的时间用来刷微博，那就没有必要了。） 另外一个很有趣的现象：一个软件的注册费就10几刀，贵些的几百刀，把日常用到的所有工具的费用全加起来都顶不上一个肾6贵，但是很多人还是坚持着没有破解不用的观念，为了几百块钱浪费了大把时间。 加班可以创造很多时间，并且能有效减少被打扰的几率，但是也会给身体和精神带来很大负担。因此加班做的事情必须能对个人进步产生足够多的收益。如果加班只是用来处理无意义的工作的话，那应该是日常工作出了什么问题。 事情可以分成紧急重要、紧急不重要、重要不紧急、不重要不紧急四类，在todo列表里随时要有重要不紧急的事情。 学会思考深究当有什么问题解决不了的时候，很多人会有畏难或者拖延的情绪，典型口头禅就是“就这么凑合着用吧”或者“先这样吧，以后有时间再研究”，说这些话的人大多并不是真的那么忙，甚至有人一边刷着微博一边跟我说没时间研究……(你tm在逗我？) 要克服畏难情绪其实很简单，找一个具体的似懂非懂的问题，想尽办法把问题研究清楚，体会几次解决问题时的愉悦感，建立自信。 大部分问题其实没有什么高深的科学原理，甚至只要翻几页书就解决了，但是遇到问题不深究，久而久之会形成自我暗示：这些问题是我懂的，那些是我不懂的，自己反而把自己进步的路给堵上了。 说到如何深究，也有几条心得： 遇事多想为什么，并且要反复问为什么。很多貌似理解了的问题过一阵再重新想想，往往会发现之前还有没考虑到的地方 问题要有明确答案，哲学之类的就别纠结了 查找资料时选权威的书籍或者网站，避免被误导 找人讨论，或者直接拉小伙伴入伙，既可以互相交流，又可以互相监督 分享你的成果 不要所有事情全都深究，会给自己太多压力 多说，多写，多交流平常工作中有一个感受，有交流和写作习惯的人思路会更清晰一些，能接触到的观点也会多一些。这方面其实属于我的弱项，大概总结几个观点。 隔一段时间最好能书面形式总结一下最近的工作，比如说写个心得感悟，或者持续更新自己的简历 写作的时候有两个难点：对要说明的事情做总结和抽象，形成观点统一、调理清晰的主线；从对方的视角考虑，把事情说明白，避免自言自语。 找人讨论之前自己先要有个基本完整的思路，否则大部分的时间都要耗在解释原理之类的上网查反而更快的事情上。 讨论之后要有一句话就能说明白的结论和描述清晰的时间点。 有些人喜欢纠结于“这个不是我的问题，为什么要我处理”之类的事情。在我看来这是很好的机会。既能增长见识，又能展示水平，还能留个认真负责的好名声，何乐而不为呢。 最后最后分享一下关于我理解的程序员的自我修养，在我看来，可以总结为：负责任，重名声。 负责任，说的更具体些：写的代码自己有没有测过、做的框架自己有没有用过、设计的架构自己有没有认真权衡过。 重名声，说的直接些：没有测过的代码、没有用过的框架、没有权衡过的方案有没有脸交付给别人。 与各位共勉。]]></content>
    </entry>

    
  
  
</search>
