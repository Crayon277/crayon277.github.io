<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[能不能一笔连成线]]></title>
    <url>%2F2018%2F03%2F05%2Fgame-shoot%2F</url>
    <content type="text"><![CDATA[最终如果能一笔连成线，说明是都遍历到了。那从一个点开始，遍历就是找邻近的点，看看这个邻近的点合不合法 有没有越过边界 有没有被之前遍历过 是不是绿点 都合法在从这个邻近的点找它的邻近的点。伪代码 12345678next(点): if 找满了24个点: 打印路径，退出 for 该点的邻近点们: 如果该点合法: 保存轨迹 next(邻近点) 删除轨迹 代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394/************************************************************************* &gt; File Name: solve.c &gt; Author: Crayon Chaney &gt; Mail:mmmmmcclxxvii@gmail.com &gt; Created Time: Mon Mar 5 20:45:25 2018 ************************************************************************/#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;#include&lt;unistd.h&gt;typedef struct route&#123; int stack[24][2]; int top;&#125;ROUTE;int total = 24;ROUTE path;int flag = 0;void print_path()&#123; int top = path.top; //有可能还有其他解法，要保留这个path.top flag = 1; while(top &gt;= 0)&#123; printf("(%d,%d) --&gt; ", path.stack[top][0],path.stack[top][1]); top --; &#125; printf("\n\n\n");&#125;int Already_exist(x,y)&#123; for(int i = 0; i &lt;= path.top;i++)&#123; if(x == path.stack[i][0] &amp;&amp; y == path.stack[i][1])&#123; return 1; &#125; &#125; return 0;&#125;int valid(x,y)&#123; if(x&lt;0 || y&lt;0 || x&gt;4 || y &gt; 4 || (x == 0 &amp;&amp; y == 1))&#123; return 0; &#125; if(Already_exist(x,y))&#123; return 0; &#125; return 1;&#125;void save_route(x,y)&#123; path.top ++; path.stack[path.top][0] = x; path.stack[path.top][1] = y;&#125;void clean_route(x,y)&#123; path.top --; //退栈&#125;void next(int x, int y,int count)&#123; //先把框架搭好 /* printf("pass,%d,(%d,%d),%d\n",count,x,y,path.top); */ /* getchar(); */ if( 24 == count &amp;&amp; 23 == path.top)&#123; //最后bug出现在这里 24 == path.top ，从0 开始 print_path(); return; &#125; for(int i = -1;i&lt;=1;i+=2)&#123; if(valid(x+i,y))&#123; save_route(x+i,y); next(x+i,y,count+1); clean_route(x+i,y); &#125; &#125; for(int i = -1;i&lt;=1;i+=2)&#123; if(valid(x,y+i))&#123; save_route(x,y+i); next(x,y+i,count+1); clean_route(x,y+i); &#125; &#125; //这里的遍历邻近点还有没有更好的写法呢？？？&#125;int main()&#123; path.top = 0; int start_x=0,start_y = 0; path.stack[0][0] = start_x; path.stack[0][1] = start_y; next(start_x,start_y,1); if(!flag)&#123; printf("no solution!\n"); &#125; return 0;&#125; 有些语法忘了，全局变量结构体，一开始path.top=0放在主函数外面报错，可能python写多了，总觉得会执行到。但这个赋值一定要在函数体内，全局变量int total = 24这个是初始化！！！]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[比特币-自问自答（一）]]></title>
    <url>%2F2018%2F02%2F25%2Fbitcoin-troubleshoot%2F</url>
    <content type="text"><![CDATA[发给一个不合法的地址会怎么样？我第一反应想到的是能发出去吗？之所以想到这个问题是，因为我们现实生活中转账的时候，如果对方账号不存在是转不过去的。而且在比特币系统中没有存在银行这么一个中心机构给我们干这个事情，在《精通比特币2》第四章中的Introduction部分说到 “The digital keys in a user’s wallet are completely independent of the bitcoin protocol and can be generated and managed by the user’s wallet software without reference to the blockchain or access to the internet. 存储在用户钱包中的数字密钥是完全独立余比特币协议，可由用户钱包软件生成并管理，无需参照区块链或访问网络，这其实就说明一件事，我转账的时候，并不需要对方账户存在，因为本身地址生成的时候，网络事先也是不知道的。 那如果可以发送的话，是给了谁？为了搞懂这个问题，必须要先知道地址到底是什么和整个交易是怎么样的这两个关键的问题。 我很久之前看过有关比特币的资料，印象中是把公钥当作地址 展开 – 公钥私钥 公钥是密码学里面非对称加密里面的概念，一个密钥对包含一个私钥和一个公钥。有非对称就有对称，这个就有点类似门锁，有些门锁是不会自动上锁，撞上门还可以开进去，锁门是需要钥匙锁的。然后像球性锁，或者酒店里面的锁，一旦撞上门，那就只能通过钥匙打开，没有钥匙是打不开的。在《趣味数学》这本书里面举了一个例子，你想一个3位数，比如123，然后乘以91，告诉我结果（11193）末尾三位，193在我只知道193的情况下，我能知道你原来想的是什么，只要19311=2123，取末三位，123。原理是9111=1001，任何一个三位数乘以1001末尾三位不变。这里91就是公钥，11就是私钥。我把公钥告诉大伙，但私钥保密，这样在被人传送消息给我的时候就能保证只有我能够阅读到原来的信息。当然真实加密中不会用这么简单的算法。但原理类似。那同样，我怎么知道发送给我的信息的就来自与那个人，而没有被调包。比如A-&gt;B,A可以先用B的公钥加密，在用自己的私钥加密。那么B就收到的就是SKA(PKB(msg)),然后用A的公钥解密，就可以确定是A发过来的，然后在用自己的私钥解密就得到了信息。 关闭 – 公钥私钥 但比特币系统中不能完全把公钥和地址对等起来。当产生了一个钥匙对之后，公钥经过两次哈希运算,分别是SHA256和RIPEMD160,得到公钥哈希，pubKeyHash,然后再用base58格式编码得到了我们常见的比特币地址。这里base58只是编码而已，不是加密，更不是非对称加密。所以是可以还原到公钥哈希的。 来自《精通比特币2》上的图 为什么还要经过两次哈希运算呢？我的理解是进一步的保证了不可逆计算。那为什么要用base58编码呢，其实是为了简便的表示和压缩字节数据。 搞懂了地址是什么，再来看交易，一笔交易的本质是什么，**我的理解是交易就是自己拿一把钥匙打开一把对应的门，拿出里面的钱从另一个有上述酒店锁的门缝里塞进去，然后只有这个拥有这个门的钥匙的人才能进去打开。**这里暂时不考虑coinbase交易，也就是挖矿奖励。当然会涉及到找零机制，酒店工作人员会把多余的钱塞到另一间房，而转账者有这间房的钥匙。那么这个酒店的房间总共有(那其实 “The size of bitcoin’s private key space, (2^256) is an unfathomably large number. It is approximately 10^77 in decimal. For comparison, the visible universe is estimated to contain 10^80 atoms.” 可以当作无限个了，也就是你随便想一个地址字符串，转钱到这里，相当于你随便塞了一笔钱到一个陌生的房间，那么如果这个世界上恰好有人拥有这个房间的钥匙，那么就相当于送了他一笔钱，或者等以后有人恰好钱包给他生成了这个地址（地址冲突的概率是存在的），那么他会发现，他刚买了一个新钱包，而这个钱包里面有一笔钱。如果是不合法的地址呢，因为现在很多钱包软件出来，所以我是钱包软件制作者的话，我会在前段检查地址的合法性，不然这笔钱就永远遗失了，因为谁也没有钥匙，相当于就被放进了一个黑洞。 来自《精通比特币2》上的图 常见的比特币地址是由1开头的。 展开 – 交易解锁脚本 转账，无非就是从一个地址到另一个地址，为了搞懂这个流程首先要明确这个和银行账户的区别，那这里这个地址的概念和银行里的账户的概念其实本质上是不一样的。银行里的账户，资产的变动，会显示+10,000 -9,000 等等，然后个人所拥有的资产就是加加减减得到的。比特币系统中，一个人所拥有的资产就看最新的状态就行了，不用加加减减了，这是得益于比特币所使用的UTXO账户模型， 意思是我转账，要把所有的钱都花掉，这不是意味着我有20个btc，要转1个btc给小明，就得转20个给小明，它是有找零机制的，也就是剩下的19个（暂时先不讨论手续费的问题）会返回到一个新的地址（为了匿名性的考虑，当然也可以返回到原来的地址），但总的来说，一笔交易的输入，他不是说像银行里，我有200，要转150给其他人，然后我的账户减掉150，剩下50，其他人账户上加150，不是这样的，因为没有一个中心机构做这件事，在比特币系统中，是200都得参与交易，那这笔交易的输出就是UTXO,中文叫未花费过的交易输出，对比银行基于账户模型，一个重过程，一个重结果。这就很直白了，那是谁控制这这些UTXO呢，就是掌握其地址相对应的私钥的人，可以花费这笔币。总的来说，我要转1个btc给A，那么这个输入一定是之前某个交易的输出，或者好几笔输出的组合（总之输入值要大于交易额），而且我拥有这些之前交易输出的地址的所有权。 那之前别人转给我的地址，是怎么让我拥有这个地址的所有权的呢？或者我转给其他人，是怎么保证只能这个人能用这笔钱的呢？这就涉及到另一个概念了，比特币脚本。其实我感觉比特币系统中做的最多的操作就是证明，证明我拥有转账地址所对应唯一的私钥，证明签名是正确的，(最主要的原因是加密算法都是单向的，所以只能做验证结果是不是一样的，而不是做验证起点是不是一样的操作)我就可以花别人转给我这个地址上的币了。一个比特币交易的数据结构是这样婶儿的 12345678910111213141516171819202122&#123; "version": 1, "locktime": 0, "vin": [ &#123; "txid":"7957a35fe64f80d234d76d83a2a8f1a0d8149a41d81de548f0a65a8a999f6f18", "vout": 0, "scriptSig": "3045022100884d142d86652a3f47ba4746ec719bbfbd040a570b1deccbb6498c75c4ae24cb02204b9f039ff08df09cbe9f6addac960298cad530a863ea8f53982c09db8f6e3813[ALL] 0484ecc0d46f1918b30928fa0e4ed99f16a0fb4fde0735e7ade8416ab9fe423cc5412336376789d172787ec3457eee41c04f4938de5cc17b4a10fa336a8d752adf", "sequence": 4294967295 &#125; ], "vout": [ &#123; "value": 0.01500000, "scriptPubKey": "OP_DUP OP_HASH160 ab68025513c3dbd2f7b92a94e0581f5d50f654e7 OP_EQUALVERIFY OP_CHECKSIG" &#125;, &#123; "value": 0.08450000, "scriptPubKey": "OP_DUP OP_HASH160 7f9b1a7fb68d60c536c2fd8aeaa53a8f3cc025a8 OP_EQUALVERIFY OP_CHECKSIG", &#125; ]&#125; 一笔交易能够用多少，就是通过输出的value值体现的。 辣个scriptPubKey就是比特币的堆栈脚本，上面把输出比作一把锁，那么要用这把锁锁住的币的人要用钥匙，验证的方式就是他要提供签名和公钥，最终要执行的脚本是这样的 图片来自《精通比特币2》 前面部分叫解锁脚本，由要解锁的人提供，后面是锁定脚本，是要引用那笔交易的输出（UTXO），然后依次脚本执行堆栈。 （上面图解释的很清楚了） 在上面说地址是由公钥哈希经过base58编码而成的，那么其实这个过程是可逆的，编码不是加密，虽然我们转账是给到地址，但是我们是可以由比特币地址得到公钥哈希，所以锁定脚本里&lt;PubKHash&gt;就是这么来的 那么怎么才算拥有这个地址，就是我有钥匙，有独一无二的钥匙，怎么才算是一个独一无二的钥匙，首先地址是怎么来的， 私钥-&gt;公钥-&gt;地址，这里每一步都是单向的。所以在脚本中EQUALVERIFY其实做的就是是否你拥有正确能生成这个地址的公钥，其实这部分是将公钥给隐藏起来了的。CHECKSIG做的是验证签名是不是有效的。 展开 – 椭圆曲线加密 在比特币系统中，用的非对称加密算法是椭圆曲线加密算法，ECC指的是椭圆曲线密码学，公钥是通过椭圆曲线乘法从私钥计算得到的，而ECDSA是椭圆曲线数字签名，是在这个密码体系下的签名算法， 这里的dA就是私钥,公钥则是用来验证私钥的签名的正确性 这里的Qa就是公钥，具体的可以看《精通比特币2》的第六章 关闭 – 椭圆曲线加密 因为私钥，公钥，地址，三者关系是密不可分的，EQUALVERIFY的意义其实就是验证我这把钥匙是对着这把锁的，公钥和地址的联系通过验证体现出来的，CHECKSIG的意义是这把锁同时还有声控，必须主人同意才能开锁,私钥和公钥的联系通过签名体现出来的，同时也意味着是我同意了这笔交易，出现问题了就是呈堂证物。签名也另一方面杜绝了，万一公钥被伪造风险或者恰好有另一个公钥经过hash160运算后得到相同的公钥哈希（这是存在的，但如果要同时也对应着私钥，那基本上是不可能的），第一步验证成功，但还需要破解私钥，才能验证签名成功，这样就增加了攻击者的难度 公钥是由私钥生成的，通过椭圆曲线(ECPoint)生成，一个私钥经过椭圆曲线变换之后会生成一个65个byte的数组，一般我们会看到这样的一个公钥：04a34b99f22c790c4e36b2b3c2c35a36db06226e41c692fc82b8b56ac1c540c5bd5b8dec5235a0fa8722476c7709c02559e3aa73aa03918ba2d492eea75abea235，公钥一般是把byte数组是经过hex(16进制)的处理之后显示出来的，不同于私钥的Base58,公钥是用来解开私钥签名的数据，使用私钥签名交易之后，会把自己的公钥一起发送，私钥签名的数据可以使用公钥解密，发送公钥之后旷工才能验证私钥的签名的正确性(能不能解开)，私钥和公钥是成对出现的，一个私钥签名的数据，只有对应的公钥才能解开，而地址也是从公钥生成的，这样就可以验证花费的交易是不是属于这个地址的。 关闭 – 交易解锁脚本 之所以底层叫区块链，链就体现在我要交易，手上就要有东西，东西来源就当作输入吧，把输入看作一个环扣，输入就是要扣在之前交易的输出上，每个人扣属于自己的，不能乱扣。扣这个动作就是解锁脚本的过程，也就是将解锁脚本和锁定脚本连在一起执行验证的过程，在这个过程中，转账者要用私钥进行签名交易，同时也会将自己的公钥一起发送，这样矿工就能验证私钥签名的有效性，同时这个公钥也必须对应着UTXO的地址（公钥哈希）。]]></content>
      <categories>
        <category>blockchain</category>
      </categories>
      <tags>
        <tag>bitcoin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[P2P 网络]]></title>
    <url>%2F2017%2F10%2F12%2Fp2p%2F</url>
    <content type="text"><![CDATA[P2P or Peer-to-Peer is a very hard type of program to create, mostly because of its very structure. Most internet applications are Client-Server this is because a lot of headaches are solved just by having a fixed server you know you can connect to. At the end of the day, that’s more or less all Napster did, it just indexed files and said who is currently hosting them. The other problem with creating P2P software, is that developing it on your own, you will have very few peers to test with, even if you do create a bunch of virtual computers. You will find it hard to test it scaled to 00’s of users. First steps though, you will need to learn to program in a suitable language, something like C++ or C# maybe just make it as a console application to learn the technology. Next, learn how to work with files. Not much use if you can’t save stuff is it. Networking next. Start with a client-server set up just to get to grips with transferring files. Make a server app that gives the files and a client app that downloads it. Then start to scale it to one server giving files to lots of clients. Final step is to merge the client and server so that as the peer downloads more of the file, it can start to be a server and let other clients download from it. If you want, now you can think about a GUI. 资源： Building P2p network]]></content>
  </entry>
  <entry>
    <title><![CDATA[python里面yield和send]]></title>
    <url>%2F2017%2F10%2F12%2Fpython-yield-send%2F</url>
    <content type="text"><![CDATA[前序资料链接： python生成器详解 python yield实现 python generator 下面是自己的理解和补充&lt;! –more –&gt; 一个函数里面有申明yield关键字的时候，这个函数就是生成器generator. 比如 1234def g(): value = (yield 1) print 'continue' value = (yield value) 测试： 123456&gt;&gt;&gt; f = g()&gt;&gt;&gt; f.next()1&gt;&gt;&gt; f.send(2)continue2 yield其实类似做了一个中断跳到其他地方的操作。send方法就是返回中断处继续执行 value = (yield 1)要分开来看,yield 1和value = yield前面是yield出去，后面是send进来的值赋给了value send方法其实是有返回值的！！！ 返回值就是生成器从下一个yield值。但是send其实也是“中断”跳到原来yield的生成器，直到生成一个返回到它这里，它才继续操作。这里说的是两个函数分别包括send和yield，就是两个函数跳来跳去。 这个特性来解决生产者消费者问题，就是协程的概念 1234567891011121314151617181920212223242526272829303132#!/usr/bin/python#-*- coding: utf-8 -*-# File Name: test_yield.py# Created Time: Wed Oct 11 22:24:20 2017__author__ = 'Crayon Chaney &lt;mmmmmcclxxvii@gmail.com&gt;'# value = 0def consumer(): value = 0 while 1: value = (yield value) if value: print "consuming ",value value = 'return here' else: breakdef process(c): now = c.next() while now &lt; 5: now = now + 1 print "processing ",now msg = c.send(now) print msg c.close()if __name__ == '__main__': c = consumer() process(c) 呈现的结果就是生产一个，消费一个123456789101112131415processing 1consuming 1return hereprocessing 2consuming 2return hereprocessing 3consuming 3return hereprocessing 4consuming 4return hereprocessing 5consuming 5return here 状态机图没有体现send返回值的，再完善一下。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>python-piece</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微信小程序-snake案例解析]]></title>
    <url>%2F2017%2F07%2F12%2Fminiprogram%2F</url>
    <content type="text"><![CDATA[snake.wxmlwx:for1234567&lt;view class="ground"&gt; &lt;view wx:for="&#123;&#123;ground&#125;&#125;" class="rows" wx:for-item="cols"&gt; &lt;view wx:for="&#123;&#123;cols&#125;&#125;" class="block block_&#123;&#123;item&#125;&#125;" &gt; &lt;/view&gt; &lt;/view&gt;&lt;/view&gt; 最外层的view想成一个大容器，这个容器的大小是由相对应的ground的wxss规定的，然后内层第一个view是放在这个大容器的一个抽屉，然后最里层是放在这个抽屉里面的东西， 想象建立一个操场，先是规划好操场的大小，划好地块，然后在每一排的植被土壤弄好，然后再一块一块的假草放上去。 注意的就是，默认数组的当前项的下标变量名默认为index，数组当前项的变量名默认为item 123&lt;view wx:for="&#123;&#123;array&#125;&#125;"&gt; &#123;&#123;index&#125;&#125;: &#123;&#123;item&#125;&#125;&lt;/view&gt; 这个index就是下标索引，从零开始，而item是数组里面具体的东西比如这个array在js里赋值[&#39;a&#39;,&#39;b&#39;,&#39;c&#39;,&#39;d&#39;]那么打印出来的是：12340:&apos;a&apos;1:&apos;b&apos;3:&apos;c&apos;4:&apos;d&apos; 如果是[[1,2],[2,3],[3,4]]那么打印出来是：1230:[1,2]1:[2,3]2:[3,4] 所以item表示的就是第index下标对应的值wx:for-index=&quot;idx&quot;,wx:for-item=&quot;itm&quot;只是名字不叫item,index而已，自己命名罢了。 参考： 列表渲染 modal弹出框组件参考： 微信小程序之弹框modal 微信小程序把玩（二十三）modal组件 snake.wxss 中flex属性首先看标签结构1234567891011&lt;view class="score"&gt; &lt;view class="title"&gt;snake&lt;/view&gt; &lt;view class="scoredetail"&gt; &lt;view class="scoredesc"&gt;得分&lt;/view&gt; &lt;view class="scorenumber"&gt;&#123;&#123;score&#125;&#125;&lt;/view&gt; &lt;/view&gt; &lt;view class="scoredetail"&gt; &lt;view class="scoredesc"&gt;历史最高&lt;/view&gt; &lt;view class="scorenumber"&gt;&#123;&#123;maxscore&#125;&#125;&lt;/view&gt; &lt;/view&gt;&lt;/view&gt; 上面的布局用图示就是 12345678910111213.score &#123; display:flex;&#125;.scoretitle&#123; flex:1; ...&#125;.scoredetail&#123; flex:1; ...&#125; 如果用了flex就是这样的展现形式 如果.score中设置的display设置为block,效果为而且其他inline,grid等都是上面这个效果。 其实flex还隐藏了一个设置，就是flex-flow应该默认是row，所以在一列上展开。flex是flexiable的缩写，注意在scoretitle和scoredetail中都有设置flex值，这个值表示的意义就是比重，我是这么理解的。比如，如果将scoretitle中的flex值改为4 可以看到title的视图占的地盘越来越大，而因为另外两个视图都是由同样的scoredetail控制，flex都为1，所以占比相同。 而且因为是flex，所以只要是关于距离的属性值，都会影响到它，比如scoretitle中的margin值的左侧改为200rpx12345.title&#123; ... margin: 40rpx 20rpx 40rpx 200rpx; ...&#125; 可以看到因为title这个视图被要求离左侧200rpx，导致另外两个视图被等比例的压缩了。 参考: display:flex多栏多列布局 操场宽度 rpx参考：-微信小程序尺寸单位rpx以及样式相关介绍 123456789101112.ground&#123; width: 660rpx; height:840rpx; margin-left: 40rpx; background-color: #eee4da;&#125;.block&#123; width:30rpx; height:30rpx; float: left; background: #ccc;&#125; rpx单位是微信小程序中css的尺寸单位，rpx可以根据屏幕宽度进行自适应。规定屏幕宽为750rpx。如在 iPhone6 上，屏幕宽度为375px，共有750个物理像素，则750rpx = 375px = 750物理像素，1rpx = 0.5px = 1物理像素。 因为一个块设定30rpx,然后每一行有22个（22列），所以操场宽度是2230=660rpx, 有28行，高度就是2830=840rpx。 snake.js逻辑层！！ setData参考： 关于微信小程序里面this.setData到底怎样或运行的？ setData 函数用于将数据从逻辑层发送到视图层，同时改变对应的 this.data 的值。注意1.直接修改 this.data 而不调用 this.setData 是无法改变页面的状态的，还会造成数据不一致2.单次设置的数据不能超过1024kB，请尽量避免一次设置过多的数据。 1.页面最终绑定的是data对象上的属性（键）2.setData(obj)方法中要求对象作为参数，他做了两件事 1)他会将obj参数上的属性浅拷贝到data对象上，该功能建议你参考Object.assign()方法的功效 2)obj参数上的属性浅拷贝到data对象的同时，会对页面绑定该属性的地方重新渲染，起到了脏值检查的作用 为什么在initGround和initSnake方法中没有用this.setData，而是直接设置data中的值先直接给结论，那是因为在createFood方法中setData了ground等值，不然在屏幕上显示不出操场。 12345678910111213onLoad: function (options) &#123; var maxscore = wx.getStorageSync('maxscore'); if(!maxscore) maxscore=0 this.setData(&#123; maxscore:maxscore &#125;); this.initGround(this.data.rows,this.data.cols); //操场渲染 //this.initSnake(3); //贪吃蛇渲染 this.createFood(); //this.move();&#125;, 123456789101112131415161718192021222324252627282930313233initGround:function(rows,cols)&#123; //初始化操场 //console.log([rows,cols]); for(var i=0;i&lt;rows;i++)&#123; var arr = []; this.data.ground.push(arr); for(var j=0;j&lt;cols;j++)&#123; this.data.ground[i].push(0); &#125; &#125; // console.log(this.data.ground); &#125;, initSnake:function(len)&#123; for(var i= 0;i&lt;len;i++)&#123; this.data.ground[0][i] = 1; this.data.snake.push([0,i]); //???Todo //这里没有用this.setData方法来设置snake可以吗？ //还是用对象方法是可以的？ &#125; &#125;,createFood:function()&#123; var x=Math.floor(Math.random()*this.data.rows); var y=Math.floor(Math.random()*this.data.cols); var ground = this.data.ground; ground[x][y] = 2; this.setData(&#123; ground:ground, food:[x,y] &#125;) &#125;, initGround和initSnake里面是对data数据中的ground和snake进行改变，如果把onLoad中的createFood注释掉，可以看到渲染的效果是 注意这里的棕色底是ground的css属性，是容纳操场的“大抽屉”123456.ground&#123; width: 660rpx; height:840rpx; margin-left: 40rpx; background-color: #eee4da;&#125; 而贪吃蛇的活动场地是由block属性控制的，背景应该为灰色。可以在视图层打印出每个操场的数组值（操场由数组控制，值是0的为灰色，值是1的是蛇体部分，值是2的是食物）12345678 &lt;view class="ground"&gt; &lt;view wx:for="&#123;&#123;ground&#125;&#125;" class="rows" wx:for-item="cols" &gt; &lt;view wx:for="&#123;&#123;cols&#125;&#125;" class="block block_&#123;&#123;item&#125;&#125;"&gt; &#123;&#123;cols&#125;&#125; &lt;/view&gt; &lt;/view&gt; &lt;/view&gt;&lt;/view&gt; 因为有理应在操场这个视图中打印出数字，但是没有，还是和上面一样。 然后再把createFood注释删掉，看到效果 由此得知，并不是initGround和initSnake不用this.setData来设置ground值，而是统一在createFood中做了，并可以验证，this.setData是逻辑层和视图层的实时交互的途径，要想在视图层中显示由逻辑层控制的一些参数，必须通过this.setData，不然没有效果。因为蛇体其实就是ground的某几个值为1，而snake不是用来渲染视图层的，是用来后面的判断生死以及移动的，可以想成是后台的数据，所以可以不用this.setData来设置，而ground是要显示在前端的，所以必须用this.setData来设置 触壁后蛇头位移？详细见下面的debug部分。 原因是因为在checkGame中的this.setData函数设置后，没有即使反应在视图层，我想的是，这个函数是及时生效 调用流程是： Move –&gt; changeDirection –&gt; changeRight –&gt; checkGame 在checkGame中this.setData做完后不是马上视图层生效，而是回到changeRight继续做剩下的，而剩下的因为没经过逻辑判断，这里可能会后bug，因为触壁后，已经到头了，理应弹出结束框，但是因为视图层没有马上生效，所以导致changeRight中在checkGame后的ground[x][y]=1继续执行，这个则是超出了边界。 可以做一个实验 12&lt;view&gt;&#123;&#123;newfield.text&#125;&#125;&lt;/view&gt;&lt;button bindtap="addnewfield"&gt; add new field&lt;/button&gt; 123456789101112addnewfield:function()&#123; this.outersetData(); this.setData(&#123; "newfield.text":"here is after outersetData" &#125;); &#125;, outersetData:function()&#123; this.setData(&#123; "newfield.text":"can this message display???" &#125;) &#125;&#125;) 最后结果： outersetData中设置的，在单步调试中也没有显示过，说明，在函数调用过程中，应该是要所有调用结束后才会触发setData的作用，然后视图层重新渲染 初始化操场我写的是:12345678910111213...initGround:function(rows,cols)&#123; //console.log([rows,cols]); var arr=[]; for(var i=0;i&lt;rows;i++)&#123; this.data.ground.push(arr); for(var j=0;j&lt;cols;j++)&#123; this.data.ground[i].push(0); &#125; &#125; console.log(this.data.ground); &#125;,... 注意var arr = []写在for循环外面，然后在调试中看到 这是一个异常的情况，不可能有那么多数据。 然后测试了一下从上面的测试可以看出，虽然g.push(arr)是导入了4个[]，但当g[0].push(1)，做这个的时候，实际上，这4个[]都是引用同一个arr,也就是arr是“全局的”，它变，全都变。 事件参考：-event 视图层的代码&lt;view class=&quot;control&quot; bindtouchstart=&quot;tapStart&quot; bindtouchmove=&quot;tapMove&quot; bindtouchend=&quot;tapEnd&quot;&gt;当在这个视图里面发生触屏事件，这个视图的大小可能是control控制的，然后在里面的每一次点击滑动，都会触发相应的tapStart,tapMove,tapEnd函数。 与视图层的逻辑层，以tapStart为例，123456tapStart:function(event)&#123; this.setData(&#123; startx:event.touches[0].pageX, starty:event.touches[0].pageY &#125;)&#125;, 我一开始怀疑为什么要event,以为是关键字，看到文档中写 在相应的Page定义中写上相应的事件处理函数，参数是event。 它是参数，并不是关键字。然后试了一些，把上面的event改为其他的名字也可以，其实就是一个命名参数function(event=**)这种。这个event是个对象。 如无特殊说明，当组件触发事件时，逻辑层绑定该事件的处理函数会收到一个事件对象。 然后是event.touches[0]，好奇[1]是什么，这个touches是什么东西。 touches 是一个数组，每个元素为一个 Touch 对象（canvas 触摸事件中携带的 touches 是 CanvasTouch 数组）。 表示当前停留在屏幕上的触摸点。 然后打印出来，touches数组就一个元素，长度就为1，没有touches[1]。 tapEndthat和this参考： js中this和that 微信小程序开发日记：重要的var that=this 深入理解JavaScript中的this关键字 onLoad12345678910 changeLeft:function()&#123; ... this.checkGame(snakeTAIL);...this.setData(&#123; ground:ground, snake:arr &#125;);... &#125;, 123456789101112131415161718192021222324252627checkGame:function(snakeTAIL)&#123; var arr=this.data.snake; var len=this.data.snake.length; var snakeHEAD=arr[len-1]; if(snakeHEAD[0]&lt;0||snakeHEAD[0]&gt;=this.data.rows||snakeHEAD[1]&gt;=this.data.cols||snakeHEAD[1]&lt;0)&#123; clearInterval(this.data.timer); this.setData(&#123; modalHidden: false, &#125;) &#125; for(var i=0;i&lt;len-1;i++)&#123; if(arr[i][0]==snakeHEAD[0]&amp;&amp;arr[i][1]==snakeHEAD[1])&#123; clearInterval(this.data.timer); this.setData(&#123; modalHidden: false, &#125;) &#125; &#125; if(snakeHEAD[0]==this.data.food[0]&amp;&amp;snakeHEAD[1]==this.data.food[1])&#123; arr.unshift(snakeTAIL); this.setData(&#123; score:this.data.score+10 &#125;); this.storeScore(); this.creatFood(); &#125; &#125;, 1234567891011modalChange:function()&#123; this.setData(&#123; score: 0, ground:[], snake:[], food:[], modalHidden: true, direction:'' &#125;) this.onLoad(); &#125;, 我发现一个问题，就是在changeLeft中（或者其他change direction），会checkGame，如果贪吃蛇触壁或者碰到自己的身体，那就会设置modalHidden值为false然后，因为每个this.setData发送都会重新渲染视图层，然后将会触发弹出框，这个弹出框的确认也会触发一个事件，modalchange重置。这里就有一个问题了，这一些列都是从changeleft的checkGame步骤分叉出来的，那如果重置了之后，changeleft中的this.setData还执不执行了，因为重置这一步也会执行this.setData，那到底是设置了哪个数据？ 从结果来看，如果贪吃蛇死了，触发重置，那么changeleft里面的this.setData就不会执行了，不然，ground和snake就不是初始值了。 然后我看到了modalchange中有this.onLoad()，猜测原因应该在这里，就是重新开始服务线程。这时候一切都被销毁，重新开始，自然changeleft中的this.setData也不会再执行了。 其他 期间调试一个changebottom的bug，发现怎么也没有进去这个函数，结果发现在这个定义的下面还定义了同名的函数，那个里面什么还没写，估计是之前放在哪里搭的框架。结论：如果有同名函数，则默认是选择最新的那个，也就是最下面的那个。 debug##移动轨迹渲染 changeleft中发现贪吃蛇在往左移动的时候，把移动轨迹都当作身体渲染出来了。 原因： 123for(var i=1;i&lt;len-1;i++)&#123; arr[i] = arr[i+1];&#125; for循环里面把i从1开始了，应该从0开始。从1开始导致arr[0]没有被覆盖 死了的时候，蛇头“位移” 可以看到背后蛇头触到最右边的时候应该死了，但是蛇头却在下一行的最左边显示了一块，然后第1列整体往下挪了。最后一行由独立的一块。 单步调试后发现，在changeleft等这些函数中 1234567891011121314... var x = snakeHead[0]; var y = snakeHead[1]+1; arr[len-1] = [x,y]; //var check = this.checkGame(arr); this.checkGame(arr); //if(check)&#123; ground[x][y] = 1; //&#125; this.setData(&#123; snake:arr, ground:ground &#125;)... 当this.checkGame(arr)做了之后，在checkGame函数中，当贪吃蛇死了之后，只是把modalHidden设为false了，但是这个this.setData没有让视图层重新渲染，不知道为什么？？？应该这里就弹出游戏结束的框了，但是没有，而是返回到change*函数内，继续做ground[x][y]=1，然后往下继续，因为已经触到最右边，此时y=22，是22，不是21，21是这一行的最后一块，还没出界，22出界。但是因为在checkGame中没有弹出结束框，所以ground中有第22列了，然后在snake.wxml中，是根据，然后两个嵌套循环来打印出这个操场，然后这个操场的每一个块又是由snake.wxss来控制，因为规定了每行就是22个，这是因为660/30 = 22，决定的，也是cols=22，定义的，然后上面的y=22，其实是第23块，从0开始。那这时候,一行放不下，就放到下一行去了，那本来第二行还换不换行？ 做了一个实验，数据量小一点。 可以看到没有换行 源代码：]]></content>
      <categories>
        <category>wechat</category>
      </categories>
      <tags>
        <tag>javascript</tag>
        <tag>html</tag>
        <tag>css</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Javascript detail record]]></title>
    <url>%2F2017%2F07%2F09%2Fjs-piece%2F</url>
    <content type="text"><![CDATA[#Web的集成开发环境: jsfiddle Thimble jsbin BugFix &lt;script&gt;元素要放所有的标签的后面，也就是最后。今天的一个bug问题就出现在这里12345678910111213141516171819var myButton = document.querySelector(&apos;button&apos;);var myHeading = document.querySelector(&apos;h1&apos;);function setUserName() &#123; var myName = prompt(&apos;Please enter your name.&apos;); localStorage.setItem(&apos;name&apos;, myName); myHeading.innerHTML = &apos;Mozilla is cool, &apos; + myName;&#125;if(!localStorage.getItem(&apos;name&apos;)) &#123; setUserName();&#125; else &#123; var storedName = localStorage.getItem(&apos;name&apos;); myHeading.innerHTML = &apos;Mozilla is cool, &apos; + storedName;&#125;myButton.onclick = function() &#123; setUserName();&#125; html里面是1234... &lt;script src=&quot;scripts/main.js&quot;&gt;&lt;/script&gt; &lt;button&gt;Change user&lt;/button&gt;... 在页面中点击change user的按钮一直没有反应，打开console看到报错原因是12Uncaught TypeError: Cannot set property &apos;onclick&apos; of null at main.js:45 null说明myButton是空的，没有读取到，然后在html中将&lt;button&gt;``&lt;scirpt&gt;标签调换一下就可以了。 &lt;script&gt;元素放在 HTML 文件底部的原因是，浏览器解析 HTML 似乎按照代码出现的顺序来的。如果 JavaScript被首先读取，它也应该影响下面的 HTML，但有时会出现问题，因为 JavaScript 会在 HTML 之前被加载，如果 JavaScript 代码出现问题则 HTML 不会被加载。所以将 JavaScript 代码放在底部是最好的选择。]]></content>
      <categories>
        <category>javascript</category>
      </categories>
      <tags>
        <tag>javascript-piece，html</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[比特币- 资料整理（2）]]></title>
    <url>%2F2017%2F06%2F21%2Finside-money-2%2F</url>
    <content type="text"><![CDATA[BITUSD（BTU）是如何取代美元的？ -[] 由于美元占据全球交易规模的一半以上，美元的弱势资本开始流向新兴市场导致了新兴市场经济的繁荣，新兴市场的繁荣意味着贸易顺差，贸易顺差意味着赚取更多美元。? 贸易顺差是指在特定年度一国出口贸易总额大于进口贸易总额，又称“ 出超 ”。贸易顺差就是在一定的单位时间里(通常按年度计算)，贸易的双方互相买卖各种货物，互相进口与出口，甲方的出口金额大过乙方的出口金额，或甲方的进口金额少于乙方的进口金额，其中的差额，对甲方来说，就叫作贸易顺差，反之，对乙方来说，就叫作贸易逆差。贸易顺差越多并不一定好，过高的贸易顺差是一件危险的事情，意味着经济的增长对外依存度过高。 经常项目贸易顺差主要源于净出口的增加，是中国对外贸易、特别是出口迅速增加的结果，净出口增加使得国内总需求扩张，国内总需求扩张促进了国民经济增长。 -[] 从77年牙买加货币体系创立起，80年拉美金融危机，94年墨西哥金融危机，97亚洲金融危机，08年全球金融危机，都伴随着美元的升值。金融危机和美元的升值有什么关系 什么是BTU呢，BTU是一个概念，其内涵是1美元等于多少BTS。 BTS /USD BTU/ BTS 10 0.1 (0.1BTS等于1美元) 假如1BTS在市场上涨到10美元 ，这时候BTU的标价就是0.1BTS.有人也许会问如下这种情况 BTS/USD BTU/BTS 10 0.2 当然在初期这种偏离是存在的，但随着市场深度的加深这种偏离就被纠正了。否则市场深度也不可能上升。假设BTS价格持续上涨到100美元，BTU的价格就跌到0.01BTS, 我作为多头在0.1买进，结果跌到了0.01，损失了99%这不是要跳楼吗?不用担心，0.01BTS 还是等于1美元啊， BTS /USD BTU/ BTS 100 0.01 (0.01BTS还是等于1美元) 作为多头的我放弃BTS的汇率变化而持有BTU, 不管BTU的价格如何变化，我如果把他当做美元来交换的话是没有变化的。 损失了BTS的收益，获得了BTU的稳定性。从而开展正常的贸易。作为空头的小马虽然把BTS质押出去了，但随着BTS的飙升，BTU的暴跌，他可以换回更多的BTS, 因此小马可以看做一名投机客而非贸易商。这时候还会出现一种线下的交易BTU和美元之间的兑换业务。基于BITUSD模式我们还可以展开更多遐想，例如BITUSD彻底取代USD的可能性，莫非第三次货币体系变革就要开始了吗? 浅显易懂看锚定的充要条件与承兑商风险-]]></content>
      <categories>
        <category>blockchain</category>
      </categories>
      <tags>
        <tag>bitcoin</tag>
        <tag>money</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PBFT算法理解]]></title>
    <url>%2F2017%2F06%2F18%2Fpbft%2F</url>
    <content type="text"><![CDATA[参考资料： 超级账本PBFT（拜占庭容错）算法详解 Q: 为什么是f+1A：一方面，一个极端，因为拜占庭错误节点最多f个，当我有f+1个一致的结果，这f+1个没有一个是错误的节点，那么不管总数多少，即使我还有f个错误的，因为最多f个，但我已经有f+1个一致的结果了，f+1&gt;f，所以作恶失败。另一个极端，f+1中有f个错误的节点。因为结果都一样！！，而最多是有f个replicas出现问题，所以至少有一个replicas是正确的，就是这个+1,而结果一致，说明这些结果都是正确的。f+1就是能保证了收到的结果是正确的。 紧接着prepare阶段，当一个replica节点发现有一个quorum同意编号分配时，它就会广播一条COMMIT信息给其它所有节点告诉他们它有一个prepared certificate了。与此同时它也会陆续收到来自其它节点的COMMIT信息，如果它收到了2f+1条COMMIT（包括自身的一条，这些来自不同节点的COMMIT携带相同的编号n和view v） Q: 这里为什么是2f+1条commitA: 最多容错n-1/3个(令等于f)，n=3f+1,然后减掉f个错误的，2f+1]]></content>
      <categories>
        <category>blockchain</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
        <tag>blockchain</tag>
        <tag>fabric</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hadoop 相关数据的规约mapreduce程序 in python]]></title>
    <url>%2F2017%2F06%2F09%2Fmtjoin%2F</url>
    <content type="text"><![CDATA[生成数据123456789101112131415161718192021222324252627282930import syschans = ['ABC','DEF','CNO','NOX','YES','CAB','BAT','MAN','ZOO','XYZ','BOB']sh1 =['Hot','Almost','Hourly','PostModern','Baked','Dumb','Cold','Surreal','Loud']sh2 =['News','Show','Cooking','Sports','Games','Talking','Talking']vwr =range(17,1053)chvnm=sys.argv[1] #get number argument, if its n, do numbers not channels,lch=len(chans)lsh1=len(sh1)lsh2=len(sh2)lvwr=len(vwr)ci=1s1=2s2=3vwi=4ri=int(sys.argv[3])for i in range(0,int(sys.argv[2])): #arg 2 is the number of lines to output if chvnm=='n': #no numuber print('&#123;0&#125;_&#123;1&#125;,&#123;2&#125;'.format(sh1[s1],sh2[s2],chans[ci])) else: print('&#123;0&#125;_&#123;1&#125;,&#123;2&#125;'.format(sh1[s1],sh2[s2],vwr[vwi])) ci=(5*ci+ri) % lch s1=(4*s1+ri) % lsh1 s2=(3*s1+ri+i) % lsh2 vwi=(2*vwi+ri+i) % lvwr if (vwi==4): vwi=5 然后执行：123456python make_join2data.py y 1000 13 &gt; num1.txtpython make_join2data.py y 2000 17 &gt; num2.txtpython make_join2data.py y 3000 19 &gt; num3.txtpython make_join2data.py n 100 23 &gt; chan1.txtpython make_join2data.py n 200 19 &gt; chan2.txtpython make_join2data.py n 300 37 &gt; chan3.txt 可以查看数据： 问题然后在上面比如Hourly_Talking,922这些表明是有922个观众在观看Hourly_Takling这个节目。Almost_Show,ABC表明是ABC电视台下有Almost_Show这个节目，然后现在要计算ABC电视台的收视情况 map这里主要就是要筛选出ABC电视台 12345678import sysimport repat = re.compile(r'\d+')for line in sys.stdin: if 'ABC' in line or len(pat.findall(line)): print '&#123;&#125;\t&#123;&#125;'.format(*(line.strip().split(','))) 因为观众数的那些还不知道和那些电视台相关，所以这些数据要保留 reduce123456789101112131415161718192021222324252627282930import sysline_count = 0 old_key = None viewer_count = 0 abc_found = False for line in sys.stdin: line = line.strip() key_value = line.split('\t') key = key_value[0] value = key_value[1] line_count = line_count + 1 if key == old_key or line_count == 1: if value == "ABC": abc_found = True else: viewer_count = viewer_count + int(value) if key != old_key and line_count: #这是进入下一组了 if abc_found == True: #只有在是ABC的才打印出来 print( '%s %s' % (old_key, viewer_count) ) old_key = key #下一个 if value.isdigit(): viewer_count = int(value) abc_found = Falseprint '%s %s' % (key, viewer_count) 在reduce阶段的时候，shuffle已sort了，&lt;key,value&gt;的value要么是’ABC’，要么是数字，如果是数字的话累加，而且，因为是sort过的，然后一定是这样的形式：123d,12d,23d,abc 所以相关的点就在key都是d的value累加完后，势必会读到d的value是哪个电视台的，如果是’ABC’的话，就可以输出了。 本地测试 hadoop 集群测试 与本地测试的结果一样]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
        <tag>mapreduce</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hadoop mapreduce -- 数据去重(python)]]></title>
    <url>%2F2017%2F06%2F09%2Fdedup%2F</url>
    <content type="text"><![CDATA[问题描述就用mapreduce的思想来将重复的数据剔除 测试数据自己随便弄 map123456import sysfor line in sys.stdin: line = line.strip() print "&#123;0&#125;\t&#123;1&#125;".format(line,1) 这个比wordcount程序简单多了。其实在这个例子中，&lt;key,value&gt;的value没有什么用，最后不用输出。 reduce1234567891011121314import syslast_key = Nonefor line in sys.stdin: this_key = line.split('\t')[0].strip() if this_key == last_key: pass else: if last_key: #print this_key #错误！！！ print last_key #this_key每一轮都更新，当不一样了的时候，要将上一轮的key输出 last_key = this_keyprint this_key 在this_key == last_key条件满足的时候，跟wordcount不一样的是，这里什么都不用做，比较wordcount程序这里是要累加的。但其实reduce这一步只要将相同的输出一个就行了。 本地测试命令: python mapper.py &lt; testfile* | sort | python reducer.py hadoop测试 看到结果也是一样的。 combine上面结果中12Combine input records=0Combine output records=0 了解了一下combine的过程，我一开始疑惑combine到底在哪个阶段，他的输入是什么（输入的是sort前还是sort后），是在哪个节点运行的。 参考： Which runs first, Combiner or Partitioner in a MapReduce Job -[] combine阶段在shuffle阶段之前，因为shuffle阶段做的是copy和sort，那么表示的就是combine阶段的时候是没有sort过的数据输入。这很重要。如果是sort过的话的，那么combine的程序就跟reducer的程序一样。只是在单个节点上，可以看作预处理的reduce。那在旧的mapreduce架构shuflle在jobtracker上运行，combine在tasktracker上执行。那在YARN架构下，combine应该在nodemanager，shuffle在resourcemanager。[Todo] 不确定 combine只是处理一个节点中的输出，而不能享受像reduce一样的输入（经过了shuffle阶段的数据）,这个非常关键 实验combine带来的优化能力先用wordcount测试，词频统计是一个可以展示combine用处的例子。词频统计程序为每一个它看到的词生成了一个（word，1）键值对。所以如果在同一个文档内“cat”出现了3次，（”cat”，1）键值对会被生成3次，这些键值对会被送到Reducer那里。通过使用Combiner，这些键值对可以被压缩为一个送往Reducer的键值对（”cat”，3）。现在每一个节点针对每一个词只会发送一个值到reducer，大大减少了shuffle过程所需要的带宽并加速了作业的执行。 测试数据网上下载了两个英文小说 一个是165k，另一个是446k 不使用 combine ： 命令: hadoop jar ../../hadoop-2.8.0/share/hadoop/tools/lib/hadoop-streaming-2.8.0.jar -input file:///Users/Crayon_277/Develop/Project/hadoop/mapreduce-program/wordcount/f*.txt -output file:///Users/Crayon_277/Develop/Project/hadoop/mapreduce-program/wordcount/output -mapper mapper.py -reducer reducer.py 结果： 可以看到12GC time elapsed (ms)=4Total committed heap usage (bytes)=1160773632 使用了combine: 命令：hadoop jar ../../hadoop-2.8.0/share/hadoop/tools/lib/hadoop-streaming-2.8.0.jar -input file:///Users/Crayon_277/Develop/Project/hadoop/mapreduce-program/wordcount/f*.txt -output file:///Users/Crayon_277/Develop/Project/hadoop/mapreduce-program/wordcount/output -mapper mapper.py -reducer reducer.py -combiner reducer.py combine的程序用回reducer.py的程序 12GC time elapsed (ms)=3Total committed heap usage (bytes)=1159200768 可以对比出12345GC time elapsed (ms)=4Total committed heap usage (bytes)=1160773632 GC time elapsed (ms)=3Total committed heap usage (bytes)=1159200768 是有优化的。时间上效率也有提升。 combine不是所有的情景都适合combiner操作是有风险的，使用它的原则是combiner的输入不会影响到reduce计算的最终输入，例如：如果计算只是求总数，最大值，最小值可以使用combiner，但是做平均值计算使用combiner的话，最终的reduce计算结果就会出错。 数据去重的例子中使用combine123456789import syss = set() #集合for line in sys.stdin: s.add(line.strip().split('\t')[0]) #取&lt;key,value&gt;中的valuefor item in s: print "&#123;0&#125;\t&#123;1&#125;".format(item,0) # 0其实没有什么意义 我预想的是这个在每个节点上将map输出的东西，先筛选一遍，就是用集合的方法，然后再输出，但是！！ 结果有点问题，用的时间也多了 [Todo]不知道为啥？combine的输出格式也和map阶段的一样，但错误。 从结果上看，还有重复的数据，反推，说明有数据没有被sort到一起，因为从打印结果看到，相同的中间隔着一些，但是在reduce的程序，可以看出，如果是收集在一起的数据是只会打印一个的，说明shuffle没有起作用？？]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
        <tag>mapreduce</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hadoop wordcount in python]]></title>
    <url>%2F2017%2F06%2F08%2Fwordcount%2F</url>
    <content type="text"><![CDATA[因为不会java，暂时用自己熟悉的python来写mapreduce程序放在hadoop上跑。mapreduce只是一个编程思想，不局限于语言。 hadoop streaming both the mapper and the reducer are executables that read the input from stdin (line by line) and emit the output to stdout. The utility will create a Map/Reduce job, submit the job to an appropriate cluster, and monitor the progress of the job until it completes. 官网的解释，也就是说，这个可执行文件或脚本里面，只要从stdin标准输入读入数据，然后进行内部的分词处理，输出到stdout，就行了，streaming会创建mapreduce的作业，发送给各个tasktracker，同时监控整个作业的执行过程。 用法12345hadoop jar hadoop-streaming-2.8.0.jar \ -input myInputDirs \ -output myOutputDir \ -mapper /bin/cat \ -reducer /usr/bin/wc 官网给出的，但在机子上首先需要找到hadoop-streaming的jar文件，路径跟官网的不一样。 我的路径是：./share/hadoop/tools/lib/hadoop-streaming-2.8.0.jar 测试数据 map阶段：12345678import sysfor line in sys.stdin: line = line.strip() keys = line.split() for key in keys: value = 1 print('&#123;0&#125;\t&#123;1&#125;'.format(key,value)) python从stdin标准输入中读取每行数据, 然后将词切分，然后输入格式为&lt;key,value&gt;的形式，因为在map阶段，value都是1 本地测试结果： reduce阶段：12345678910111213141516171819202122import syslast_key = Nonerunning_total = 0for input_line in sys.stdin: input_line = input_line.strip() this_key, value = input_line.split("\t",1) value = int(value) if last_key == this_key: running_total += value else: if last_key: #进入新的一组会进入这条语句，last_key初始是None，一开始不会打印 print("&#123;0&#125;\t&#123;1&#125;".format(last_key,running_total)) running_total = value last_key = this_keyif last_key == this_key: #最后一组输出 print("&#123;0&#125;\t&#123;1&#125;".format(last_key,running_total)) 本地测试： 有问题！怎么没有把相同的归在一起，其实这个程序如果按照map的输出当作输入执行结果就是这样的。因为last_key和this_key不停在变，因为map的输出哪怕没有两行是相同的key。那其实这里就涉及mapreduce的机制了，map阶段完成由输入数据到单词切分的工作，还有shuffle阶段，这个阶段完成相同的单词的聚集和分发工作，这个过程是mapreduce的默认过程，不用具体配置,也就是map和reduce的中间环节会把相同的给收集起来再进行reduce，如果在本地测试应该是这样的： 用sort命令将相同的放在了一起，就模拟了把相同单词的聚集工作。 [] ？有个疑问就是：相同的单词聚集在一起是分发给一个节点么，也就是不同节点计算着不同的单词，可能有节点计算好几个不同的单词，但问题是，是不是一个相同的所有单词都是在一个节点上reduce，如果不是，因为相同的单词被分了几份reduce了，那岂不是还要再reduce，总归要合并的，那这步在哪个节点上，由谁控制？ hadoop 上测试用file:///放在本地看 hadoop jar ../hadoop-2.8.0/share/hadoop/tools/lib/hadoop-streaming-2.8.0.jar -input file:///Users/Crayon_277/Develop/Project/hadoop/wordcount/testfile* -output file:///Users/Crayon_277/Develop/Project/hadoop/wordcount/output2 -mapper mapper.py -reducer reducer.py 注：以上在伪分布集群下测试的。 mapreduce framework运行hadoop程序给出的INFO，可以看到123456789101112131415161718Map-Reduce Framework Map input records=2 Map output records=16 Map output bytes=109 Map output materialized bytes=153 Input split bytes=234 Combine input records=0 Combine output records=0 Reduce input groups=12 Reduce shuffle bytes=153 Reduce input records=16 Reduce output records=12 Spilled Records=32 Shuffled Maps =2 Failed Shuffles=0 Merged Map outputs=2 GC time elapsed (ms)=0 Total committed heap usage (bytes)=1160773632 Map input records=2 这是说明有两个文件输入Map output records=16数了一下mapper.py程序的输出，就是16个然后可以看到Reduce input groups=12应该就是说明了shuffle的工作收集相同的单词，但Reduce input records=16这个16应该指的的总的还是16个，不是按单词组来看。Shuffled Maps=2 我本来觉得是代表了有2种单词是有相同的，收集在一起了。但不是，因为其实在这个案例上是有4种是单词是有重复的。[Todo] 贴个流程图： 总结其实应该有5个阶段： map phase The map phase is done by mappers. Mappers run on unsorted input key/values pairs. Each mapper emits zero, one, or multiple output key/value pairs for each input key/value pairs. combine phase The combine phase is done by combiners. The combiner should combine key/value pairs with the same key. Each combiner may run zero, once, or multiple times. shuffle and sort phase The shuffle and sort phase is done by the framework. Data from all mappers are grouped by the key, split among reducers and sorted by the key. Each reducer obtains all values associated with the same key. The programmer may supply custom compare functions for sorting and a partitioner for data split. partitioner The partitioner decides which reducer will get a particular key value pair. reducer The reducer obtains sorted key/[values list] pairs, sorted by the key. The value list contains all values with the same key produced by mappers. Each reducer emits zero, one or multiple output key/value pairs for each input key/value pair.参考：What is the purpose of shuffling and sorting phase in the reducer in Map Reduce Programming? 因为combiner操作是有风险的，使用它的原则是combiner的输入不会影响到reduce计算的最终输入，例如：如果计算只是求总数，最大值，最小值可以使用combiner，但是做平均值计算使用combiner的话，最终的reduce计算结果就会出错。这个例子统计词频，同样也不能combine，因为会遗失数据了。]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
        <tag>mapreduce</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell （一）]]></title>
    <url>%2F2017%2F06%2F05%2Fshell%2F</url>
    <content type="text"><![CDATA[参考： Linux的环境变量.bash_profile .bashrc profile文件 What’s the difference between .bashrc, .bash_profile, and .environment?’]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>shell</tag>
        <tag>bash</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重新编译hadoop过程终于到的问题]]></title>
    <url>%2F2017%2F06%2F02%2Frecompile-hadoop%2F</url>
    <content type="text"><![CDATA[在macOS上直接执行命令brew install hadoop 然后执行hadoop命令的时候会出现WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable的警报。这是因为apcche hadoop 官网上下载的源文件是在32为的机器上编译的。所以当64位的机子在加载.so文件的时候会出错。基本上不影响使用hadoop(如果使用mahout做一些机器学习的任务时有可能会遇到麻烦，加载不成功，任务直接退出，所以还是有必要解决掉这个warn的)。 从网上下载的源文件中的BUILDING.txt看到如下的信息 123456789101112Requirements:* Unix System* * JDK 1.7+* * Maven 3.0 or later* * Findbugs 1.3.9 (if running findbugs)* * ProtocolBuffer 2.5.0* * CMake 2.6 or newer (if compiling native code), must be 3.0 or newer on Mac* * Zlib devel (if compiling native code)* * openssl devel (if compiling native hadoop-pipes and to get the best HDFS encryption performance)* * Linux FUSE (Filesystem in Userspace) version 2.6 or above (if compiling fuse_dfs)* * Internet connection for first build (to fetch all Maven and Hadoop dependencies) java 路径问题mac 下安装的路径见 Mac下jdk的安装路径 protobuf的问题因为用brew insatll protobuf命令来安装protobuf版本是最新的，而这里是要求2.5.0，所以要自己手动下载protobuf2.5 解压tar xfvj tar xfvj protobuf-2.5.0.tar.bz2 配置进入目录后 ./configure CC=clang CXX=clang++ CXXFLAGS=&#39;-std=c++11 -stdlib=libc++ -O3 -g&#39; LDFLAGS=&#39;-stdlib=libc++&#39; LIBS=&quot;-lc++ -lc++abi&quot; makemake -j 4sudo make install 完成！ 关于zlib的在Linux机子上的话就用各自的包管理工具安装。 12yum -y install svn ncurses-devel gcc*yum -y install lzo-devel zlib-devel autoconf automake libtool cmake openssl-devel mac下执行xcode-select --install就行了 maven修改安装目录下conf/settings.xml（因为maven使用的国外的reposity，国内有时无法访问，修改为国内镜像即可）修改如下：在里添加123456&lt;mirror&gt; &lt;id&gt;nexus-osc&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;name&gt;Nexusosc&lt;/name&gt; &lt;url&gt;http://maven.oschina.net/content/groups/public/&lt;/url&gt;&lt;/mirror&gt; 上面最终是12345&lt;mirrors&gt; &lt;mirror&gt; ... &lt;/mirror&gt;&lt;/mirrors&gt; 同样在内新添加 1234567891011121314151617181920212223242526272829303132&lt;profile&gt; &lt;id&gt;jdk-1.8&lt;/id&gt; &lt;activation&gt; &lt;jdk&gt;1.8&lt;/jdk&gt; &lt;/activation&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;name&gt;local private nexus&lt;/name&gt; &lt;url&gt;http://maven.oschina.net/content/groups/public/&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;name&gt;local private nexus&lt;/name&gt; &lt;url&gt;http://maven.oschina.net/content/groups/public/&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; &lt;/profile&gt; But！！！在我的机子上有问题，还是保持原样就行了。因为后面出现了一个问题，所以以为这里是一个症状，排除法么。但如果有谁是因为镜像下载问题的话，估计是这个的问题。还有这里的国内镜像，maven.oschian.net，【todo】再去找找其他镜像的地址。 出现的问题1234567....[INFO] Apache Hadoop Auth ................................. SUCCESS [ 3.375 s][INFO] Apache Hadoop Auth Examples ........................ SUCCESS [ 2.518 s][INFO] Apache Hadoop Common ............................... FAILURE [ 4.272 s][INFO] Apache Hadoop NFS .................................. SKIPPED[INFO] Apache Hadoop KMS .................................. SKIPPED.... 可以看到 hadoop common 编译失败 报错： 123456789101112131415161718[INFO] BUILD FAILURE[INFO] ------------------------------------------------------------------------[INFO] Total time: 21.337 s[INFO] Finished at: 2017-06-03T11:20:12+08:00[INFO] Final Memory: 73M/725M[INFO] ------------------------------------------------------------------------[ERROR] Failed to execute goal org.apache.maven.plugins:maven-antrun-plugin:1.7:run (make) on project hadoop-common: An Ant BuildException has occured: exec returned: 2[ERROR] around Ant part ...&lt;exec failonerror="true" dir="/Users/Crayon_277/Develop/Project/hadoop/hadoop-2.8.0-src/hadoop-common-project/hadoop-common/target/native" executable="make"&gt;... @ 7:160 in /Users/Crayon_277/Develop/Project/hadoop/hadoop-2.8.0-src/hadoop-common-project/hadoop-common/target/antrun/build-main.xml[ERROR] -&gt; [Help 1][ERROR][ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.[ERROR] Re-run Maven using the -X switch to enable full debug logging.[ERROR][ERROR] For more information about the errors and possible solutions, please read the following articles:[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException[ERROR][ERROR] After correcting the problems, you can resume the build with the command[ERROR] mvn &lt;goals&gt; -rf :hadoop-common 链接文章： Hadoop “Unable to load native-hadoop library for your platform” warning Compile Apache Hadoop on Linux (fix warning: Unable to load native-hadoop library)-]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[stackoverflow-bitcoin-1]]></title>
    <url>%2F2017%2F05%2F29%2Fstackoverflow-bitcoin-1%2F</url>
    <content type="text"><![CDATA[工作量证明机制和权益证明机制有什么区别What’s the difference between PoW and PoS?’我正在寻找能够说明工作量证明机制算法和权益证明机制算法的解释，还有他们是如何和比特币还有区块链有联系的。 也希望有一个非常简单明了没有包含过多技术的回答。可以有一点技术方面的东东，但我不是开发者，我并不知道怎么去编程。 （）（） 下面几点简要的概括： 一个加密货币有它自己的区块链来储存所有出现的交易 工作量证明机制和权益证明机制是两种不同的算法来获取 哪个区块将会链接到区块链后面 的共识。 工作量证明（PoW）需要某种类型的工作发生的证明。就比特币矿工来说，他们需要在区块被其他接受之前做这个工作。 权益证明(PoS) 要求用户拥有相当量的货币（比如拥有许多coins）来决定下一个区块。这有某一方垄断货币的高风险。但是有几种方法可以阻止（通过随机分配利益相关者来共识新区块，其他） 最主要的区别可以归结于，工作量证明机制需要额外的资源（挖矿设备）但权益证明不需要。如果比特币家里减少，越来越少的人被激励去挖矿，因此会导致整个系统的安全性减少，工作量机制会被苛责（criticized) 。而权益证明机制，因为它是免费来增加新区块到区块链后面的，你可以用它来同事做几个相似的币的权益证明（详见PoS链接中的“nothing at stake”问题） 例子： 比特币，莱特币还有其他许多币种使用PoW方法。 NXT，BitShares还有其他使用PoS方法。 以太坊使用PoW但是它计划要转到PoS. PeerCoin使用PoW和PoS的结合机制。]]></content>
      <categories>
        <category>stackoverflow</category>
      </categories>
      <tags>
        <tag>bitcoin</tag>
        <tag>blockchain</tag>
        <tag>stackoverflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[project of stackoverflow - C Piece (一)]]></title>
    <url>%2F2017%2F05%2F27%2Fstackoverflow-c-piece-1%2F</url>
    <content type="text"><![CDATA[C中的操作符优先级 precedence of operator in c我是一个变成新手，现在我正在学有关C操作符优先级的部分。我尝试着想要分析下面给出的代码 12345678#include&lt;stdio.h&gt;int main()&#123; int x, y, z; x = y = z= -1; z = ++x&amp;&amp;++y&amp;&amp;++z; printf("x = %d y = %d z = %d", x, y ,z);&#125; 在学了操作符的优先级后，我知道一元操作符(unary operator)有更高的优先级，所以在上面的代码中：z = ++0&amp;&amp;++0&amp;&amp;++0;所以x,y,z的值是0，对吧？但是编译执行后，结果是x = 0 y = -1 z = 0有人能帮我解决这个问题么？ 得票2: 这个表达式：z = ++x&amp;&amp;++y&amp;&amp;++z; 其实和下面这个表达式是等价的： z = ( ++x &amp;&amp; ++y ) &amp;&amp; ++z; 根据标准C： 和二进制位操作&amp;不一样，&amp;&amp;操作是从左向右结合计算。如果第二个操作数北极算了，那就说明在第一个操作数和第二个操作数之间存在一个sequence point。如果第一个操作数比较等于0，那么第二个操作数不会被计算。 所以首先++x被计算。它等于0。所以++y不会被计算。表达式：(++x &amp;&amp; ++y)结果是0。因为它等于0，所以表达式(++x &amp;&amp; ++y) &amp;&amp; ++z中的子表达式++z不会被计算。所以z会被赋值整个表达式的值，那就是0。 这里至少没有任何未定义的行为(undefined behaviour) 因为表达式++z不会被计算。 所以你会得到 x == 0, y == -1, 和 z == 0 （这是因为赋值语句） Undefined behavior and sequence pointstag: c++ , undefined-behavior, c++.fag, sequence-points 什么是“序列点”(sequence points)? (不知道这么翻译对不对)未定义行为和序列点的关系是什么？ 我经常使用像a[++i] = i这种有趣却复杂的表达式，我也感觉不错，为什么要停止使用这些呢？ 如果你已经阅读到这里了，确保访问下面的问题Undefined behavior and sequence points reloaded. 556票的回答： C++98 和 C++03 这个回答是准备给C++旧标准的。C++11和C++14标准版本没有正式的包含”[sequence points]”这个说法；运算反而是(sequence before) 或 (unsequenced) 或 (indeterminately sequenced) 。网络效应（net effect)？基本上一致，但是术语不一样而已。 不承诺： 好吧，这个回答有点长，所以在阅读的时候需要一点耐心，如果你已经知道这些东西了，再次阅读不会让你疯狂的。 前提： 需要C++ standard的一点基础知识 什么是sequence points? 标准中说到： At certain specified points in the execution sequence called sequence points, all side effects of previous evaluations shall be complete and no side effects of subsequent evaluations shall have taken place. (§1.9/7) [TODO]]]></content>
      <categories>
        <category>stackoverflow</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>c-piece</tag>
        <tag>stackoverflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[愚见比特币（一）--货币的本质]]></title>
    <url>%2F2017%2F05%2F18%2Finside-money%2F</url>
    <content type="text"><![CDATA[对货币的研究不是很深入，但毕竟是每天都用的东西，然后结合了一些看的资料，下面给出我的理解，不对的地方非常欢迎指点。 要想了解比特币，还得从猴子变人开始说起… 古时候，人们交易，实际上就是交换，比如我有鸡蛋，你有牛奶，我刚好需要牛奶，然后你刚好需要鸡蛋，然后商量着，我用30个鸡蛋换你一桶牛奶。 但是社会体系越来越庞大后，需求也越来越多后，可能我要牛奶，但牛奶拥有者不要鸡蛋，所以我还得先换到他想要的那样东西，这让我想起了我小时候听的磁带里面的一则故事，故事名字还有里面具体的那个物品名字我给忘了，大概意思就是小兔他妈妈让小兔子拿着自家缝的一块布去换家里需要的白菜（我指的具体的物品是指这些，但这不是终点，忽略这些细节），然后小兔子找到白菜主人，他不要布，他要地瓜，然后找到地瓜主人，问要不要交换，然后也不要，他要香蕉，然后又去找香蕉的主人，反反复复，找到最终能交换到需要布的，然后再一步步回朔换到白菜。就是一个递归的过程。这样换，就很麻烦 （图片中的尖头表示拥有者手中持有物的更替） 然后慢慢大家达成某种共识，就是抽取出一种特殊商品，所有其他东西都可以由它等价交换（一般等价物）。现在我鸡蛋换牛奶是，先用30个鸡蛋换100个海贝，这里海贝就是这种“中介商品”，然后100个海贝再去换1桶牛奶 这个海贝其实就是货币的雏形，然后慢慢的发展到金属货币，经历银本位，复本位，金本位，blabla的，这里我也不是很了解，但不影响。比如我国古代的铜币，银子，金子。但是金属有个弊端就是太重了，后来就有钱庄，发行银票，但银票本质还是以金子做货币基础的，银票只是起到了符号的作用。我国南宋的交子是最早政府发行的纸币（银票），而且这些交子（银票）都是由商人自由发行的。 到了二战结束后，全球形成了以美元为中心的布雷顿森林体系，取代了站前的金本位制度，后来美国取消兑换黄金后，全球真正进入了信贷程序发行货币的时代。 以前是用黄金作为中介，这些都是实物，看得见摸得着的。现在的纸币本位，其实是由国家信用作为“抵押”的 基础货币相当于政府向全国国民的借债，但至于借债是否能被偿还，乃至政府资产是否价值，只取决于人们对政府的信心和政府自身的信用 我是这么理解的。如果A欠B十块钱，B欠C十块钱，是不是通过商量协定后A欠C十块钱一样的。那现在其实就是把人民币看作一种权利义务的关系，我们是债权人，国家是债务人，我们有100元，先把这个单元去掉，相当于就是（我们有对国家的100债券），然后我们交易，我给你10元，就是我把对国家的10个债权转让给你。现在是把这个关系抽象出来放在原来黄金的位置上。 其实上面的这个债券债务关系比喻还是有点不太恰当，毕竟国家发行货币就是不断印钞，印多了通货膨胀。之前商业银行还可以发行自己的货币，但后来中央将这个权利回收，只有中央可以发行货币。 总结来说，很久以前的海贝变成了现在的纸币。货币用来买卖的，为什么我接受这个货币，其实就是大家都认可么，就像海贝，从商品中分离出来固定充当一般等价物，因为海贝是实物，摸得着看得见，后面是大自然“撑腰”。现在只是后面是国家的信用“撑腰” 那我们的财富是什么，是我们手上的100元吗？不是，财富是我们资产负债表的加加减减。可以说货币就是记账方式，钱只是账本上面的一串数字，那每个人其实有一本账本（在银行里）。 那比特币本质其实就是一个所有人的账本，所有人交易放在一个账本上，所有人都可以看，所有人都可以维护。它是去中心化的，没有中央银行。记载在我们现在生活中的账本的那些数字，我们给它一个单位叫元，叫美元，日元等等。然后在比特币这个系统，我们给它一个单位叫比特币。这个系统中发行货币的方式就是“矿工挖矿“（我不太喜欢这个称号，久而久之就不知道本质是啥了，其实就是全网的记账人），给记账人记账的奖励就是产生新的比特币，以及交易产生的手续费。 那我们现实生活中的货币是基于国家信用的，而比特币是基于密码学，基于数学原理。只要大家都认可（共识机制），就可以交易了。 那国家货币还有一些防伪手段等来解决现实生活中出现的问题。下面会说明比特币是怎么利用数学来解决这个问题的。 我的理解不是很深，欢迎指正。也请阅读的过的人留下邮箱，万一有错，不想误人子弟，等错误更正会通过邮箱来提醒你。]]></content>
      <categories>
        <category>blockchain</category>
      </categories>
      <tags>
        <tag>bitcoin</tag>
        <tag>monetary</tag>
        <tag>currency</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[平静和沉淀]]></title>
    <url>%2F2017%2F05%2F17%2Fcalm-down%2F</url>
    <content type="text"><![CDATA[焦虑。 其实我觉得我有毅力做一件事，但是太急功近利了，没有耐心。而且，懒。这个是人的天性啊，但是为了要达到你想追求的目标，就必须要和天性斗争。不能老是拿顺其自然的话语来安慰自己，目前在自己身上这两者是竞品。 在这个追求快速制胜的时代，连NBA联盟都流行小球，快准狠的风格了，做一只马刺队一样的清流还是很难的啊。 毕竟人家波波老爷子用了20年打造的文化基奠。 浮躁。 受大环境影响，往往迷失了自己。我感觉现在虚活着，什么都想干，但不知道干嘛。 静。]]></content>
      <categories>
        <category>life</category>
      </categories>
      <tags>
        <tag>life</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[install hadoop]]></title>
    <url>%2F2017%2F04%2F14%2Finstall-hadoop%2F</url>
    <content type="text"><![CDATA[因为hadoop版本的问题，有些命令可能不一样。网上搜到的一些资料都会过时或与我现在安装的版本不兼容。所以直接看官方文档 那安装其实涉及的就是单机和集群。特地在知乎上逛了一圈，得到的答案是，看目的吧，如果主要想学习mapreduce编程的，不要搭集群，不要搭集群，不要搭集群！！！因为目的是修炼内功，就没必要磨练工具了吧。但至少我觉得安装个工具如果都搞不定的话，那就不用混了。还是把重心放在mapreduce编程上吧 这里记录一个安装single-node hadoop的历程。 我mac上用的是homebrew包管理工具，所以我就直接brew install hadoop。好了，安装完成。 接下来的文档里面都有。 主要记录一下几个点： java的路径 因为是从官网下载的dmg直接安装的。java home的路径是/Library/Java/JavaVirtualMachines/jdk1.8.0_60.jdk/Contents/Home如果是其他途径，比如brew cask install java的话，那应该会在/usr/local/Cellar/java中吧（我猜的），还有其他的肯定会有提示的。 官网文档中的etc/hadoop？？在哪？ 因为是通过brew安装的hadoop，所以hadoop都在/usr/local/Cellar/hadoop里面。文档直接说是etc/hadop，对应我机子上完整的路径是/usr/local/Cellar/hadoop/2.8.0/libexec/etc 同理bin/hadoop 中间什么配置core-site.xml等文件看文档就好了。因为不同版本可能配置会不一样！！！所以还是看官方文档 出来这个页面就可以了 hadoop fs -ls 在官网文档里面的命令是hdfs dfs，但其实是一样的 但执行结果：12WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicablels: `.': No such file or directory 上面那个是因为编译的问题。hadoop官方是32位编译的好像。然后我机子是64位的。这个暂时不管。下面这个报错其实是正常的。 hadoop fs -ls命令的语法完整其实是hadoop fs -ls [path]而默认情况下，不用详细指定[path],hadoop会认为是在hdfs中的/home/[username]，这个[username]就是用bash shell当前的用户替换。 比如在我机子上，hadoop回去找/home/MMMMMCCLXXVII，但这个路径不存在hdfs中。那这样，其实就是指定一个路径就可以了。 hadoop fs -ls / 它会自动获取计算出hdfs的根目录，然后显示 其实根据core-site.xml的配置 123456&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://localhost:9000&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 预想hadoop fs -ls hdfs://localhost:9000/ 应该可以的。但是好像有问题。[TOdo] 然后用hadoop命令显示本地的文件。hadoop fs -ls file:/// 借鉴的文档： 【hadoop】ssh localhost 免密码登陆（图解）主要就是先要有sudo权限，如果没有用root账户的时候。How To Create a Sudo User on CentOS 这个usermod命令后，要重启终端。 Have you logged in again after the usermod? IIRC, groups are only looked up when you log in (e.g. opened a new terminal window). 然后就是那两个命令，创建isa-pub.主要就是要有权限。 关闭SElinux CentOS7中关闭selinux这个设置后重启没用，还是开着的]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vim的字符编码]]></title>
    <url>%2F2017%2F04%2F10%2Fvim-encoding%2F</url>
    <content type="text"><![CDATA[vim中的编码vim 有四个跟字符编码方式有关的选项，encoding、fileencoding、fileencodings、termencoding (这些选项可能的取值请参考 Vim 在线帮助 :help encoding-names) encoding: Vim 内部使用的字符编码方式，包括 Vim 的 buffer (缓冲区)、菜单文本、消息文本等。默认是根据你的locale选择.用户手册上建议只在 .vimrc 中改变它的值，事实上似乎也只有在.vimrc 中改变它的值才有意义。你可以用另外一种编码来编辑和保存文件，如你的vim的encoding为utf-8,所编辑的文件采用cp936编码,vim会自动将读入的文件转成utf-8(vim的能读懂的方式），而当你写入文件时,又会自动转回成cp936（文件的保存编码). fileencoding: Vim 中当前编辑的文件的字符编码方式，Vim 保存文件时也会将文件保存为这种字符编码方式 (不管是否新文件都如此)。 fileencodings: Vim自动探测fileencoding的顺序列表， 启动时会按照它所列出的字符编码方式逐一探测即将打开的文件的字符编码方式，并且将 fileencoding 设置为最终探测到的字符编码方式。因此最好将Unicode 编码方式放到这个列表的最前面，将拉丁语系编码方式 latin1 放到最后面。 termencoding: Vim 所工作的终端 (或者 Windows 的 Console 窗口) 的字符编码方式。如果vim所在的term与vim编码相同，则无需设置。如其不然，你可以用vim的termencoding选项将自动转换成term的编码.这个选项在 Windows 下对我们常用的 GUI 模式的 gVim 无效，而对 Console 模式的Vim 而言就是 Windows 控制台的代码页，并且通常我们不需要改变它。 最主要的就是关注一下encoding和fileencoding，总结就是前者是vim内部处理字符的用的。vim中可能会处理不一样的编码的字符，然后都化为统一的格式进行处理是最明智的。后者是文件的编码格式。 上面也说的很清楚了，文件读入时，若是fileencoding和encoding不一致，会先转化成encoding，统一处理，最后保存的时候再转化回fileencoding。转化的过程就是通过unicode这个第二层过渡。看编码总结 vim的多字符编码方式支持工作流程 Vim 启动，根据 .vimrc 中设置的encoding 的值来设置 buffer、菜单文本、消息文的字符编码方式。 读取需要编辑的文件，根据fileencodings 中列出的字符编码方式逐一探测该文件编码方式。并设置fileencoding为探测到的，看起来是正确的 字符编码方式。 对比fileencoding和encoding的值，若不同则调用iconv将文件内容转换为encoding所描述的字符编码方式，并且把转换后的内容放到为此文件开辟的buffer里，此时我们就可以开始编辑这个文件了。注意，完成这一步动作需要调用外部的iconv.dll，你需要保证这个文件存在于$VIMRUNTIME或者其他列在PATH环境变量中的目录里。 编辑完成后保存文件时，再次对比fileencoding和encoding的值。若不同，再次调用iconv将即将保存的 buffer 中的文本转换为fileencoding所描述的字符编码方式，并保存到指定的文件中。同样，这需要调用iconv.dll由于Unicode能够包含几乎所有的语言的字符，而且Unicode的UTF-8编码方式又是非常具有性价比的编码方式 (空间消耗比UCS-2小)，因此建议encoding的值设置为utf-8。这么做的另一个理由是encoding设置为utf-8时，Vim 自动探测文件的编码方式会更准确 (或许这个理由才是主要的 ;)。我们在中文 Windows 里编辑的文件，为了兼顾与其他软件的兼容性，文件编码还是设置为GB2312/GBK 比较合适，因此fileencoding建议设置为 chinese (chinese 是个别名，在 Unix 里表示 gb2312，在 Windows 里表示cp936，也就是 GBK 的代码页)。]]></content>
      <categories>
        <category>砍树人</category>
      </categories>
      <tags>
        <tag>encode</tag>
        <tag>utf-8</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用r做一个简单的统计词频的程序]]></title>
    <url>%2F2017%2F04%2F08%2Fr-text-mining-word-frequency%2F</url>
    <content type="text"><![CDATA[要求：假设文件1中有内容a b c c,文件2中有a b d现在要统计成如下的样子： a b c d 文件1 1 1 2 0 文件2 1 1 0 1 用到R中的table函数 预备table table uses the cross-classifying factors to build a contingency table of the counts at each combination of factor levels. 123456&gt; f1[1] "a" "b" "c" "c"&gt; table(f1)f1a b c 1 1 2 文档中说了table使用facter中的level来生成统计项，然后记录各项出现的次数。 factor123set.seed(102) # This yields a good illustration.x &lt;- sample(1:3, 15, replace=TRUE)education &lt;- factor(x, labels=c("None", "School", "College")) 123456&gt; x[1] 2 2 3 2 1 2 3 1 3 2 3 3 3 2 2&gt;education[1] School School College School None School College None College[10] School College College College School School Levels: None School College 上面可以看出labels就是实现一种转化么。默认是lables = levels(x) 解题思路因为文件1中没有d，但统计的时候还是要有它的项，当然值是0。所以我们要有一个level是包含所有的项的1234&gt; table(factor(f1,levels=c('a','b','c','d')))a b c d 1 1 2 0 这里有另一个话题就是读取文件还可以用readLines函数，不过12&gt; readLines(file.choose())[1] "a b c c" 可以看到，这是一个向量，scan读进来直接是分开的。所以如果用readLines的话，还要用strsplit函数进行分割，就和python中的split函数一样还有我这里用file.choose()来手动选择文件，因为在mac上不知道为什么绝对路径传进去都有问题。[Todo] 简单情况现在将情况简单化一点，现在假设只有一个文件，现在统计的文件1等就是第1行，依次类推。 先得到所有的词，每个词是一个元素，像scan那样12345678dat &lt;- readLines(file.choose())rownum &lt;- length(dat)word &lt;- NULLfor(i in 1:rownum)&#123; di &lt;- dat[i] di &lt;- strsplit(di,split=' ')[[1]] word &lt;- c(word,di)&#125; 得到所有的项其实也就是数学里面的集合么。估计Levels就是集合实现的123&gt; factor(word)[1] a b c c a b dLevels: a b c d 这样就得到了所需要的所有项a,b,c,d 那其实因子a b c c a b d它是按顺序来的，那其实对第一行的统计就可以table(factor(word[1:len_row_1]))那len_row_1怎么得来，就可以在原来的for循环中直接用length计算出12345678910dat &lt;- readLines(file.choose())rownum &lt;- length(dat)len &lt;- rep(0,rownum) #word &lt;- NULLfor(i in 1:rownum)&#123; di &lt;- dat[i] di &lt;- strsplit(di,split = ' ')[[1]] word &lt;- c(word,di) len[i] &lt;- length(di) #&#125; 多了有#号标记的这两行 统计事先先生成rownum行然后length(levels(factor(word)))列的矩阵，之后往里面塞就行了123f &lt;- factor(word)l &lt;- levels(f)m &lt;- matrix(0,nrow = rownum,ncol = length(l)) 1234&gt; m [,1] [,2] [,3] [,4][1,] 0 0 0 0[2,] 0 0 0 0 因为我们现在有了len12&gt; len[1] 4 3 4意思是文件第一行的元素个数，3就是第二行的然后我们可以用数组的知识，也就是类似c语言中的两个指针来移动了123456start &lt;- 1for(i in 1:rownum)&#123; # 这里我一开始忘了写1:，只是rownum，导致一直bug end &lt;- start+len[i] - 1 m[i,]&lt;-table(factor(word[start:end],levels = l)) start &lt;- end+1&#125; 1234&gt; m [,1] [,2] [,3] [,4][1,] 1 1 2 0[2,] 1 1 0 1 弄的好看一点12345&gt; colnames(m)&lt;-c('a','b','c','d')&gt; m a b c d[1,] 1 1 2 0[2,] 1 1 0 1 复杂情况就是要前面的步骤，要读取多个文件。其实后面步骤都是一样的。只是一个是将多文件的内容放在一个文件的每一行，同样我们需要知道所有的项，也就是levels。多出来的工作也就是我们要读多个文件，然后进行拼接而已。没什么难度，只是代码的优雅程度不一样而已。 R下的文件目录操作 dir.create(&#39;newdir&#39;)：创建文件夹 unlink(&#39;directory&#39;,recursive=TRUE):删除文件夹，若有文件一并删除 file.create(&#39;newfile&#39;): 创建一个新文件，若存在则会覆盖原文件 cat(&#39;hello world&#39;,file=&#39;newfile&#39;,append=TRUE): 文件加入一行内容 file.append(&#39;file1&#39;,&#39;file2&#39;): 将file2的内容添加到file1的后面 file.copy(&#39;source&#39;,&#39;des&#39;):拷贝文件source到文件des file.show(&#39;filename&#39;)： 显示文件内容 file.remove(&#39;filea&#39;,&#39;fileb&#39;): 删除文件 list.files()：显示当前工作目录下的文件列表 这里可以借助list.files()来搭桥。知道了目录下的文件列表，我们就可以用循环了 合并数据123456789f &lt;- function(x)&#123; data &lt;- readLines(x) return(strsplit(data,split=' '))&#125; dir_path &lt;- '/Users/Crayon_277/Develop/Project/R/homework/3'files &lt;- list.files(dir_path,pattern = '[0-9]+.txt$',full.names = T) result &lt;- lapply(files,f) list.files中的full.names参数为false的时候12&gt; files[1] "1.txt" "2.txt" 当为T的时候123&gt; files[1] "/Users/Crayon_277/Develop/Project/R/homework/3/1.txt"[2] "/Users/Crayon_277/Develop/Project/R/homework/3/2.txt" 区别就一目了然了 123456789&gt; result[[1]][[1]][[1]][1] "a" "b" "c" "c"[[2]][[2]][[1]][1] "a" "b" "d" 然后可以在用for语句拼接，或者一开始直接用for遍历 lapply returns a list of the same length as X, each element of which is the result of applying FUN to the corresponding element of X.lapply就类似python中的map]]></content>
      <categories>
        <category>R</category>
      </categories>
      <tags>
        <tag>R</tag>
        <tag>R-piece</tag>
        <tag>text-mining</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用R画出下面这样子的形式的图]]></title>
    <url>%2F2017%2F04%2F07%2Fr-lines%2F</url>
    <content type="text"><![CDATA[用到什么学什么 plot的使用官方的description Generic function for plotting of R objects. For more details about the graphical parameter arguments, see par. For simple scatter plots, plot.default will be used. However, there are plot methods for many R objects, including functions, data.frames, density objects, etc. Use methods(plot) and the documentation for these. plot(x, y, …) 这里先用到plot的一个type参数 what type of plot should be drawn. Possible types are “p” for points, “l” for lines, “b” for both, “c” for the lines part alone of “b”, “o” for both ‘overplotted’, “h” for ‘histogram’ like (or ‘high-density’) vertical lines, “s” for stair steps, “S” for other steps, see ‘Details’ below, “n” for no plotting. 这里有个&quot;n&quot;的参数值可以选择，也就是什么都不会打印，先看个例子1234x &lt;- seq(-pi,pi,length = 100)plot(x,sin(x),type='p')plot(x,sin(x),type='l')plot(x,sin(x),type='n') 分别是这样色儿的看最后一个，也就是什么都没画。什么都没有有什么用！？存在即合理，它可以用来弄一个画布，然后再在上面画其他图形 比如：1&gt; plot(c(0,10),c(0,10)) 这里plot的x,y参数是用向量指定的，x坐标的放一起，y坐标的放一起，其实坐标点是(0,0),和(10,10)，在这两个坐标上，默认是画了两个小圆圈。但是如果我想要一个有坐标系的这样的一个画布，我就可以 1&gt; plot(c(0,10),c(0,10),type='n') 而这里x,y的作用就是撑开画布坐标系的大小，我如果plot(c(0,50),c(0,50),type=&#39;n&#39;)，那坐标系就变大了。 lines A generic function taking coordinates given in various ways and joining the corresponding points with line segments.lines(x, …) Default S3 method:lines(x, y = NULL, type = “l”, …) 就是根据像plot那样x,y解释的意思，将两点连起来，同时用type指定的样式画出这点线这个说法有点不正确，好像是说type指定的是线的样式，比如实线，虚线，不是的。lty这个参数才是指定“线样式的” 我这里看到了lines(x,...)说明可以不用指定y，那画出来是什么？？123456&gt; plot(c(0,10),c(0,10),type='n')&gt; lines(c(0,1))&gt; lines(c(5,9))&gt; lines(c(2,4))&gt; lines(c(10,1))&gt; lines(c(4,7)) 可以看出来给出的c(a,b)，a,b都是表示纵坐标，默认好像横坐标是1到2，那这样就是画(1,a)到(2,b)的线？至少实验出来是这样的1&gt; lines(c(4,7,6)) 三个向量元素，那上面的猜测是对的，现在是画(1,a),(2,b),(3,c)的线段，估计向量元素增多，就是横坐标到4，5，6了吧 lines 的type lines(x, y, type = “l”, …)typecharacter indicating the type of plotting; actually any of the types as in plot.default. 说是根据plot的type来，一开始我觉得这不跟lty参数重复了么，其实两个是不一样的1234&gt; plot(c(0,10),c(0,10),type='n')&gt; lines(c(2,4),c(3,8),type = "s")&gt; lines(c(6,7),c(3,8),type = "s",lty=2)&gt; lines(c(6,7),c(3,8),type = "l",lty=3) 当type=&quot;s&quot;是，画的是折线！！！，s解释为step，相当于画的是曼哈顿路径。lty才是线是什么样子的形式的。而type应该是画的什么什么形状吧，不知道怎么描述 lty的实验1234plot(c(1,6),c(1,1),type='l',lty=1,ylim=c(0,8))for(i in 2:6)&#123; lines(c(1,6),c(i,i),type = 'l',lty=i)&#125; text在画布上写文本吧直接看实验123&gt; plot(c(0,10),c(0,10),type='n')&gt; text(c(5,1),c(3,3),1)&gt; text(c(5,8),c(2,3),c("A","B")) points画点。主要是pch,cex这两个参数有点意思 pchplotting ‘character’, i.e., symbol to use. This can either be a single character or an integer code for one of a set of graphics symbols. The full set of S symbols is available with pch = 0:18, see the examples below. (NB: R uses circles instead of the octagons used in S.) Value pch = “.” (equivalently pch = 46) is handled specially. It is a rectangle of side 0.01 inch (scaled by cex). In addition, if cex = 1 (the default), each side is at least one pixel (1/72 inch on the pdf, postscript and xfig devices). For other text symbols, cex = 1 corresponds to the default fontsize of the device, often specified by an argument pointsize. For pch in 0:25 the default size is about 75% of the character height (see par(“cin”)). cexcharacter (or symbol) expansion: a numerical vector. This works as a multiple of par(“cex”). 目前我的理解就是pch就是点的样式，cex就是指定大小 pch 实验12345678plot(c(0,10),c(0,10),type='n')line.draw = 9for(i in 1:25)&#123; if((i-1) %% 5==0)&#123; line.draw = line.draw - 1 &#125; points((i-1)%%5,line.draw,pch=i)&#125; 回到题目画这样的一个三角形。思路就是用points画大一点的圆圈，text来写A这中标签，然后lines来画线，没什么难度12345678910plot(c(0,10),c(0,10),type = 'n')lines(c(3,5),c(4,9),type = 'l',lty=1)lines(c(5,7),c(9,4),type = 'l',lty=1)lines(c(3,7),c(4,4),type = 'l',lty=1,xlim=c(2.5,6.7))points(5,9,pch=1,cex = 5)text(5,9,'A')points(3,4,pch=1,cex = 5)text(3,4,'B')points(7,4,pch=1,cex = 5)text(7,4,'C') 不过我这样，太啰嗦了啊 R中的最常用的对象就是向量，很多运算都支持向量操作。可以用向量123456plot(c(0,10),c(0,10),type = 'n')x &lt;- c(3,5,7)y &lt;- c(4,9,4)points(x,y,cex=5)text(x,y,c("A","B","C"))lines(x,y,type='l') lines(x,y) , 这个x，y的坐标，相当于这里，两个坐标的x都提取出来到x，两个坐标的y都提取出来到y，相当于起始点终点的x坐标放一起，起始点终点的y坐标放一起.感觉python中的map(None,x,y) 后就是[(3,4),(5,9),(7,4)] 其实就是各点的坐标 但是是不闭合的，为什么，其实两个组合确定一条线，可能lines中的向量，x先是(3,5),在是(5,7),y对应，但后面没有回去(7，3)。要手动添加1lints(c(x,3),c(y,4),type='l') 这样就和开篇的fancybox的图片里面一样了。]]></content>
      <categories>
        <category>R</category>
      </categories>
      <tags>
        <tag>R</tag>
        <tag>R-piece</tag>
        <tag>plot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自我约束-开会]]></title>
    <url>%2F2017%2F04%2F06%2Fself-discipline-meeting%2F</url>
    <content type="text"><![CDATA[如果不能做到以下，那么你就把你的屁股老老实实的坐到那该死的团会上，体验如坐针毡的感觉。 自己真的做的惜时如金的时候，真的做到压榨每一分每一秒的时候，真的做到push self的时候，当感觉到跑在计划前面的时候。 不能不趁三十之前，立志猛进也 野蛮生长]]></content>
      <categories>
        <category>life</category>
      </categories>
      <tags>
        <tag>life</tag>
        <tag>namaste</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Intro to hadoop and MapReduce -- hdfs & mapreduce (二)]]></title>
    <url>%2F2017%2F04%2F06%2Fhdfs-mapreduce%2F</url>
    <content type="text"><![CDATA[Quiz： Is there a problem [x] network failure [x] disk failure on datanode [] not all datanode used (Why do you think that all nodes have to be used. What if you have hundreds of Data Nodes?) [] block sizes differ (If block sizes would have to be the same, what would happen if the file could not be divided in same size blocks?) [x] disk failure on namenode what if namenode had hardware problem Quiz: any problems now [x] data inaccessible (when network failure) [x] data lost forever (when disk failure) [] no problem so, depends.]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
        <tag>mapreduce</tag>
        <tag>udacity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Intro to hadoop and MapReduce -- Big Data(一)]]></title>
    <url>%2F2017%2F04%2F04%2Fbig-data%2F</url>
    <content type="text"><![CDATA[Definition of Big Data可能有些人认为几个terebytes的数据量是大数据，但这个量不是标准的，所以一个合理的定义是 It’s data that’s too big to be processed on a single machine. Quiz: Chanllenges with Big Data- most data is worthless data is created fast data from different sources in various formats most data is not worthless, but actually does have a lot of value. The 3 V’s of big dataVolume总结：量大。需要考虑那些能提供有用信息 But in order to store it, you’ll need a way to scale your storage capacity up to massive volume. Hadoop, which stores data in a distributed way across multiple machines, does that Variety就是说我们如果用像MySQL,Oracle这种数据库，数据必须要适合他们的格式，但是现在我们处理的数据很大部分都是unstructured或者是semi-structured.比方说现在打客服热线不都有一个提示说是会录音，一种存储是语音识别成文字保存起来，另一种是直接存储成mp3格式然后让相应的软件解码如果后面要用的话。那hadoop不管你的数据是什么样的格式， you can just store the data in its raw format, and manipulate and reformat it later. example Sometimes the most unlikely data can be extremely useful and lead to savings due to better planning. 比方说现在要通知附近的货车到中心取货，基于位置的系统就会通知最近的车辆过来。但往往，这个最近，不是最佳的选择。也许那里有交通堵塞，也许最近的车辆过来需要过羊肠小道，那里的路比较难走，也许是要绕一大圈才能到中心。更需要考虑的是，这辆车上也许没有足够的空间了，这辆车没有油了。所以以下都是需要考虑的 Current GPS location fromi all trucks Current itineraries for all trucks Current traffic speed in related areas as reported by services such as waze Current load of trucks by volume and weight Fuel efficiency of the different vehicles The world we live in is extremely complex, and there are a lot of variables to consider that you can tweak to get large benefits. Velocity实时更新？？If we can’t store it as it arrives, we’ll end up discarding some of it, and that’s what we absolutely want to avoid. history of hadoop来自hadoop 之父 Doug Cutting So, let me tell you how Hadoop came to be. About ten years ago in around 2003, I was working on an Open Source web search engine called Nutch, and we knew it needed to be something very scalable, because the Web was you know, billions of pages. terabytes, petabytes, of data, that we needed to be able to process, and we set about doing the best job we could and it was tough. We got things up and running on four or five machines, not very well, and around that time Google published some papers about how they were doing things internally. Published a paper about their distributed file system, TFS. and about their processing, framework, MapReduce. So my partner and I, at the time, in this project, Mike Cafarella. said about trying to reimplement these in Open Source. So that more people could use them than just folks at Google. Took us a couple of years, and we had Nutch up and running on, instead of four or five machines, on, 20 to 40 machines. It wasn’t perfect, it wasn’t totally reliable, but it worked. And we realize that to get it to the point where it was scaled to thousands of machines, and be as bullet proof as it needed to be, would take more than just the two of us, working part time. Around that time, Yahoo approached me and said they were interested in investing in this. So I went to work for Yahoo in January of 2006. First thing I did there, was, we took the parts of Nutch that were a distributed computing platform, and put them into a separate project. A new project christened Hadoop. Over the next couple years, with, Yahoo’s help, and the help of others, we took Hadoop, and really got it to the point where it did scale to petabytes, and running on thousands of processors. And doing so quite reliably. It spread to lots of companies, and mostly in the Internet sector, and became quite a success. after that, we, we started to see a bunch of other projects grow up around it. And Hadoop’s grown to be the kernel of a, which, pretty much an operating system for big data. We’ve got tools that, allow you to, more easily do, MapReduce programming, so, you can develop using SQL or a data flow language called Pig. And we’ve also got the beginnings of higher­level tools. We’ve got interactive SQL with Impala. We’ve got Search. and so we’re really seeing this develop to being a general purpose platform for data processing. that scale’s much better and that it is much more flexible than anything that’s, that’s, else is out there. hadoop clusterhadoop存储数据的方法是一个分布式的文件系统叫做HDFS。处理数据是通过MapReduce。核心思想就是将数据分块，然后在集群中存储，也就是各个计算机搭建的一个网络吧。那这样的好处就是我们不用从中心取数据然后再操作，我们直接在集群中就地处理数据，后续还可以继续扩大集群的规模 hadoop Ecosystem Core hadoop consists of HDFS and MapReducehadoop的生态系统。以hadoop为核心的，打造的周边产品，主要的目的就是降低使用hadoop的难度和门槛。比如编写MapReduce的程序不是一件容易的事，有些没有编程经验的就可以用Pig，Hive，这种类似SQL语句来操作数据，但这两个都是将语句翻译为MapReduce然后再到集群上执行。因为Hive和Pig它们本质上还是MapReduce的工作量，所以花费的时间可能更多。所以另一个开源项目Impala，它是允许直接用SQL语句来操作数据，不用经过MapReduce（具体现在我也不懂），所以这样就很快了其他的也就类似了。 Cloudera hadoop版的其实就是把这些都给你打包好了，你不用在一个一个去弄了。 核心还是hadoop的HDFS和MapReduce]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
        <tag>mapreduce</tag>
        <tag>udacity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[seven-principle]]></title>
    <url>%2F2017%2F04%2F04%2Fseven-principle%2F</url>
    <content type="text"><![CDATA[自带鸡血，能源源不断地给自己充电，遇到打击能迅速恢复，哪怕这种打击沉重而有力，也就是，抗压能力强。 不能给自己设限，既没有上限，也没有下限，凡事能想到的事，都敢做，给联合国秘书长写信也没啥不敢的 格局大，顺势而为.胸怀达到全宇宙，又能找到把猪吹上天的风口，从来站在更大的地位上思考问题，绝不想同事蹭吃了一盒酸奶之类的小时； 对自己高标准，永不满足，一旦自己陷入舒适圈，马上调整自己，给自己提更高的要求，让自己不舒适，让自己不高心，让自己不痛快，给自己找别扭，上升到更高的level 做不可替代的角色 极度自律，执行力超强（强调）。别跟我说自律，其实就是一个人呆着的时候，不放纵自己，做应当做的是，不玩游戏，不看电视剧，不在低附加值的事情上浪费时间。同时，你不能想着，我要有时间就好了，然后每天还能睡到中午12点，然后慵懒的发发朋友圈，谈谈诗和远方。 具备逆向思维，善于创新，说白了，就不跟大家一样思考，常人怎么想，总是反着想，具备创新精神。剑走偏锋]]></content>
      <categories>
        <category>life</category>
      </categories>
      <tags>
        <tag>life</tag>
        <tag>principle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自我约束-你好]]></title>
    <url>%2F2017%2F03%2F30%2Fself-discipline%2F</url>
    <content type="text"><![CDATA[坐公交好几次都碰见她，一位穿着比较啰哩啰嗦的，时尚的。我想认识她 今天，我在看nba勇士队的比赛，她突然过来，没有一丝丝准备，都不知道我发型有没有乱的，问我能不能帮她刷下公交卡，她转支付宝给我，我下意识的说不用，现在老后悔了。 不过，从我过往的经验看，大多是我自己自作多情，人家也只是想寻求帮助，不要想太多了，今天不是你也是其他人。 但还是挺开心的，借此聊了一会，得知是大三外语系的。哈哈哈 这次的自我约束：如果你能静下心来，不要胡思乱想。进入自己的zone, 认认真真做自己的事情，专注！！看缘分，如果能做到专注，那么下次遇见的时候就厚着脸皮要个联系方式吧，不然就永远当个路人]]></content>
      <categories>
        <category>life</category>
      </categories>
      <tags>
        <tag>life</tag>
        <tag>namaste</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python name and values]]></title>
    <url>%2F2017%2F03%2F29%2Fpython-name-and-values%2F</url>
    <content type="text"><![CDATA[阅读 Facts and myths about Python names and values 做的摘记内容不是很深，只是这里面提到了一些需要注意的点。最主要还是name和value的区别 Fact: Names have no type, values have no scope. Just as names have no type, values have no scope. When we say that a function has a local variable, we mean that the name is scoped to the function: you can’t use the name outside the function, and when the function returns, the name is destroyed. But as we’ve seen, if the name’s value has other references, it will live on beyond the function call. It is a local name, not a local value. 翻译： 就跟名字没有类型一样，数值是没有作用范围的。当我们说一个函数有局部变量的时候，我们只是说的是名字只在函数作用域中起作用而已，你不能在函数外使用这个名字，当函数返回的时候，这个名字也就摧毁了。但是，如果这个名字指向的数值还有其他引用，它就会继续生存下去，不管这个函数了。局部变量，而不是局部数值。 Fact: Values can’t be deleted, only names can. Python’s memory management is so central to its behavior, not only do you not have to delete values, but there is no way to delete values. You may have seen the del statement: 12nums = [1, 2, 3]del nums This does not delete the value nums, it deletes the name nums. The name is removed from its scope, and then the usual reference counting kicks in: if nums’ value had only that one reference, then the value will be reclaimed. But if it had other references, then it will not. Fact: Assignment never copies data. Mutable means that the value has methods that can change the value in-place. Immutable means that the value can never change, instead when you think you are changing the value, you are really making new values from old ones. 比如：12x = 3y = x x和y只是一起指向了3而已，并没有给y再来一个3。这里x,y是name，3是value上面说到的Mutable是什么意思，也就是因为这个赋值不拷贝数据的特性，当y变了的时候，比如y+=1，那x还变不变？这里就要考虑到可变类型和不可变类型了 Immutable values: numbers strings tuples Mutable values: lists dicts user-defined objects 那在上面y+=1之后，其实是给y重新reference到了4 关于mutable的直接截图： Fact: Python passes function arguments by assigning to them.123def my_func(x,y) return x+yprint(my_func(8,9)) The names x and y are local to the function, so when the function returns, those names go away. But if the values they refer to are still referenced by other names, the values live on. 注意，这里就出现name和value的区别了，可以这样理解，value就是一个实物，name只是这个实物的标签，我可以贴很多标签，而看到这个标签，我就联想到这个实物，实物可以有多个标签，一个标签只能对应一个实物。 1234567def augment_twice(a_list,val): a_list.append(val) a_list.append(val)nums = [1,2,3]augment_twice(nums, 4)print(nums) #[1,2,3,4,4] 虚线框表示本地name在一个新的frame里面，而参数传递只是一种赋值操作，a_list “指向” nums指向的value,而list类型是可变数据类型，所以任何name对它的改变都是就地的，可以通过id()操作来查看是否改变了地址 另外一个程序 12345def augment_twice_bad(a_list,val): a_list = a_list + [val,val]nums = [1,2,3]augment_twice_bad(nums,4)print(nums) #[1,2,3] 这个跟上面的程序就不同在函数里面一个是用.append()来增加元素，一个则用加法然后赋值，赋值，赋值，重要的事情说三遍，这是个赋值操作，一旦出现赋值，就相当于等式左边的namerebind出现在等式右边的value It’s really important to keep in mind the difference between mutating a value in place, and rebinding a name. augment_twice worked because it mutated the value passed in, so that mutation was available after the function returned. augment_twice_bad used an assignment to rebind a local name, so the changes weren’t visible outside the function. 其他的 facts, myths都知道了，上面的需要注意一下就可以了。过]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用R来找最大连通子图]]></title>
    <url>%2F2017%2F03%2F25%2Fr-maximal-connected-subgraph%2F</url>
    <content type="text"><![CDATA[求上图的最大连通子图，其实就是图的遍历，图的遍历有深度优先和广度优先图有很多种对应的存储结构，在R里面最简单的就是邻接矩阵了。 -update- 用深度优先搜索做 在深度优先里面涉及到的R中的全局，局部变量 构造邻接矩阵1234567m &lt;- matrix(0,5,5)m[1,2] &lt;- 1m[1,3] &lt;- 1m[2,3] &lt;- 1m[4,5] &lt;- 1m &lt;- m + t(m) 1234567&gt; m [,1] [,2] [,3] [,4] [,5][1,] 0 1 1 0 0[2,] 1 0 1 0 0[3,] 1 1 0 0 0[4,] 0 0 0 0 1[5,] 0 0 0 1 0 主要也就是m&lt;-m+t(m)这一步，因为是无向图，是对称矩阵，可以先构造一半然后与转置相加。这是对称矩阵的性质的应用！！ 在线性代数中，实对称矩阵是一个方形矩阵，其元素都为实数，且转置矩阵和自身相等实对称矩阵 广度优先遍历主要思想就是它分两个部分，一个部分保存已经访问过的，一个部分是未访问的，未访问部分是用一个队列来存储，每次从队头出一个元素i，然后将这个元素的能够够到的节点依次加到队尾去。这一步其实就是邻接表中的第i行中为1的元素加进来 先考虑简单的情况，从第1个节点出发，寻找包含1的最大联通子图，其实就是1能够直接或间接够到的所有节点，在图中我们可以直观的看到是1，2，3，三个节点。 错误的代码12345678910111213visited &lt;- c(1)unvisited &lt;- m[1,]while(length(unvisited)&gt;0)&#123; now &lt;- unvisited[1] unvisited &lt;- unvisited[-1] candidate &lt;- m[now,] candidate &lt;- setdiff(candidate,visited) unvisited &lt;- union(candidate,unvisited) visited &lt;- c(visited,now)&#125;print(visited) 这里我犯了一个错误，unvisited &lt;- m[1,],这是unvisited里面保存的是什么？？12&gt; unvisited[1] 0 1 1 0 0 那我想要的是什么？应该是visisted中一开始是1,unvisisted中将1的邻接节点加进来是2,3,然后后面每次循环体内做的是队头元素出队列。但是加进来的元素应该是代表这个节点的符号,反应在矩阵中的应该是下标。矩阵里面存的其实是边信息，1代表有边,0代表无边，其实要的是0 1 1 0 0对应的下标！！！需要的是节点信息，这其实是两个概念 初始化我欠缺的也就是我知道我想要的是什么，但是不熟悉R语法，或者说不知道怎么用R语言来实现，虽然我熟悉python语法，但我也不能保证我能写出很优雅的代码，因为跟别人差就差在，他们不仅精通语法，还知道他们的性能，能有很多组合。 这里我需要的是读进来第1行矩阵元素有1的下标，取下标怎么取 有关下标的函数,目前只注意到下面的三个 which:Give the TRUE indices of a logical object, allowing for array indices. which.min:最小值的下标 which.max:最大值的下标 按照条条大路通罗马的理论，只要这个函数跟目标有点沾边的肯定能实现，只是看你的想象力，是否能突破天际因为which是需要一组逻辑向量，在R中逻辑值只有TRUE和FALSE,然后它会返回TRUE的下标只要把0 1 1 0 0转换为逻辑值就行了。查了一下12&gt; as.logical(c(-1,0,1,2))[1] TRUE FALSE TRUE TRUE 可以看到as.logical认为只有0是FALSE，其它为TRUE,这样路就通了12visited &lt;- c(1)unvisited &lt;- which(as.logical(m[1,])) 因为只要得到逻辑向量就可以了，那逻辑操作还可以用m[1,] == 1来得到逻辑向量值。这也可以还有没有其他方案？ 因为我注意到这里要么是0,要么是1,可以用向量1 2 3 4 5去乘，就得到了0 2 3 0 0,然后只要大于0的就行了123index &lt;- c(1:5)edge2node &lt;- index*m[1,]unvisited &lt;- edge2node[edge2node &gt; 0] edge2node[edge2node &gt; 0] 中的edge2node&gt;0计算完之后是逻辑值，然后用[]下标操作取逻辑值只为TRUE的元素 上面两种得到的12&gt; unvisited[1] 2 3 就是我想要的 遍历上面一开始写的错误的代码中也就是和上面一样的问题。只要改了这一部分就行了。12345678910while(length(unvisited)&gt;0)&#123; now &lt;- unvisited[1] unvisited &lt;- unvisited[-1] # 队头元素出队列 #candidate &lt;- m[now,] candidate &lt;- which(as.logical(m[now,])) candidate &lt;- setdiff(candidate,visited) unvisited &lt;- union(candidate,unvisited) # 将队头元素的邻接节点加入队列 visited &lt;- c(visited,now) # 将队头元素加入已访问的&#125;print(visited) 这里setdiff和union是集合运算，因为可以在图上直观的看到，1这个节点可以找到2,3。到2这个节点，可以找到1,3,但此时，1这个节点是已经访问了的，如果不处理，还是加进队列里面的话，那就不断在循环了！！！ setdiff是取差值，注意参数的位置，是将visited里面有的元素从candidate中消掉union是取并集，没什么好说的了还有一个intersect(x, y)就是取交集 最后的结果12&gt; print(visited)[1] 1 2 3 全图对每个节点进行同样的操作图的最大连通子图，那就对每个节点都进行上面的操作，然后图包含节点最多的就是这个图的最大联通子图了 12345678910111213141516171819202122max_node_num &lt;- 0maximal_connected_subgraph &lt;- NULLfor(i in 1:5)&#123; visited &lt;- c(i) unvisited &lt;- which(as.logical(m[i,])) while(length(unvisited)&gt;0)&#123; now &lt;- unvisited[1] unvisited &lt;- unvisited[-1] candidate &lt;- which(as.logical(m[now,])) candidate &lt;- setdiff(candidate,visited) unvisited &lt;- union(candidate,unvisited) visited &lt;- c(visited,now) &#125; current_node_num &lt;- length(visited) if(current_node_num &gt; max_node_num)&#123; max_node_num &lt;- current_node_num maximal_connected_subgraph &lt;- visited &#125;&#125;sort(maximal_connected_subgraph)print(m[maximal_connected_subgraph,maximal_connected_subgraph]) result:12345&gt; print(m[maximal_connected_subgraph,maximal_connected_subgraph]) [,1] [,2] [,3][1,] 0 1 1[2,] 1 0 1[3,] 1 1 0 深度优先遍历深度优先就是一条道走到底，无路可走的时候，及时浪子回头，然后又不听教诲又去浪到底，直到玩累了，回家的过程。 思路涉及到一个回朔。这样就需要一个parent_node来保存父节点的信息。这里我想到，是不是要回去的时候要重新计算父节点的邻接节点，因为这样才能知道其他节点啊。 同样还需要一个visited来保存已经访问过的节点。然后在访问完一个节点，要将这个节点加入visited中，在要遍历下一个节点的时候，需要取一个节点。那这个时候需要看这个节点是不是已经访问了。这里我想到了两个方案： 一个一个取。意思是下标操作，取一个对比一下是不是在visited中，可以用any(visited == current_node)如果是FALSE就是还未访问过。visisted == current_node返回的是一个逻辑向量，然后用any函数如果有一个是TRUE那返回值是TRUE，返回FALSE说明没有一个是相等的。 一下子全取出来。然后用集合运算，做差，然后再取出一个。 然后我用笔在纸上模拟的时候，发现这应该是个递归的过程。那visisted需要全局来维护，那这样函数体内就用循环可以了，遍历一个节点的所有邻接节点，然后对每一个节点再进入这个函数。这样就不需要parent_node来维护了，但是需要一个边界条件来终止递归。那就是一个节点的所有邻接节点都被访问过了。 发现的问题，visited全局变量1234567891011121314151617181920212223242526m &lt;- matrix(0,5,5)m[1,2] &lt;- 1m[1,3] &lt;- 1m[2,3] &lt;- 1m[4,5] &lt;- 1m &lt;- m + t(m)visited &lt;- c(1)dfs &lt;- function(current_node)&#123; #browser() # 调试用的 candidate_node &lt;- which(as.logical(m[current_node,])) candidate_node &lt;- setdiff(candidate_node,visited) #print(candidate_node) if(length(candidate_node) == 0)&#123; return(0) #这个0返回的没有意义的，随便都可以，只是单纯的结束 &#125; for(i in candidate_node)&#123; visited &lt;- c(visited,i) #访问i节点 dfs(i) #递归 &#125;&#125;dfs(1)print(visited) 上面的结果出错了12Error: evaluation nested too deeply: infinite recursion / options(expressions=)?Error during wrapup: evaluation nested too deeply: infinite recursion / options(expressions=)? 那就是递归没返回调试了一下，发现问题出现在visited上，dfs(i)进去的时候，理想中visited应该是全局变量，在循环中我将i节点加入已访问的节点中，但是发现递归进去的时候，candidate_node &lt;- setdiff(candidate_node,visited)这时候的visited值是1,就是初始值。可是为什么呢？？？ 内部函数在它的环境中查找visited的值（查找的顺序为：首先函数体的局部变量，参数；然后是外部函数中的局域变量，参数；最后是全局变量） 所以当在函数内做赋值的时候，相当于就建立了一个局部变量，那在第一层的时候visited &lt;- c(visited,i)这个语句还没执行到的时候，此时的visited在函数体内还没有定义！那找到的就是外部的变量，所以调试的时候看到的是1，那其实相当于因为在递归的时候可以看作都是进入自己的函数，所以每一层的visited都是独立的。 方案 1 : return(visited)1234567891011121314dfs2 &lt;- function(current_node,vis=NULL)&#123; candidate_node &lt;- which(as.logical(m[current_node,])) candidate_node &lt;- setdiff(candidate_node,visited) if(length(candidate_node) == 0)&#123; return(NULL) &#125; for(i in candidate_node)&#123; if(!any(visited == i))&#123; visited &lt;- c(visited,dfs2(i)) &#125; return(visited) &#125;&#125; 这么写有两个问题！！！第一个是有闭环的时候，因为我在前面的代码计算candidate_node的时候是依赖visited的，在每一层的函数进去后，因为前面说了，每一层的visited是独立的，所以在没有赋值之前，也就是没有在下一层return之前，用的都是外部的visited &lt;- c(1)这个值，所以这时候计算的candidate_node肯定是不正确的，不是我们想要的，因为不能正确判断是否邻接节点已经访问过。这是根源，所以导致了在下面for循环的时候，在闭环的情况下，因为没有正确的将已经访问的排除掉，而无限的递归。 第二个是分叉，就最简单的情况，1连接2,3,但后两个不连接，因为到2中，visited是外部的1，所以这里是恰好，凑巧，刚刚好candidate_node计算为空，返回，但是！！！返回的是空！这样visited &lt;- c(visited,dfs2(i))这个语句就没有起作用，追其根源那就是return写的不正确。一方面是这里连return(visited)都没执行到，相当于在2层这里直接返回NULL，但是并没有把2这个节点加入visited中。而且，即使不管上面的情况，在2饭后会，后面直接return(visited)了，函数直接退出了。3根本就没做。 试错：12345678m &lt;- matrix(0,3,3)m[1,2] &lt;- 1m[1,3] &lt;- 1m + t(m) -&gt; mvisited &lt;- c(1)print(dfs2(1)) 结果12&gt; print(dfs2(1))[1] 1 [todo] 使用return 写递归应该是可以的，那就是我整体的递归应该不是按照原来的思路了。但目前还没有想到怎么写 方案 2 : 这个visited当作一个参数传递就行了但是发现，这个只是值传递参数，不是引用传递，也就是参数变了，最后visited自己没有改变没有用啊，print(visited)就没用，最后结果就只是1 &lt;&lt;-解决然后我查到里面提到了&lt;&lt;-，可能这个操作符才是将变量复制到全局变量中去，不然&lt;-就在函数体内生成了一个同名的局部变量然后我就将上面的visited &lt;- c(visited,i)改为visited &lt;&lt;- c(visited,i)得到的结果是12&gt; print(visited)[1] 1 2 3 3 多了一个3，这个是因为在第一层的时候也就是current_node为1的时候，邻接节点是2,3,在for循环中，先进入2节点，此时可以遍历的只有3,然后进入3,访问完，回朔，此时应该是在这个图下1,2,3都是遍历完了的，但是回朔到1节点的时候，for循环还有一个3没执行，所以在for循环里面还要再加一个条件，看是否已经遍历过。123456for(i in candidate_node)&#123; if(!any(visited == i))&#123; visited &lt;&lt;- c(visited,i) #访问i节点 &#125; dfs(i) #递归&#125; 结果：12&gt; print(visited)[1] 1 2 3 寻找最大连通子图那就是再用一个for循环封装一下，和上面BFS一样。 完整代码12345678910111213141516171819202122232425262728293031323334353637m &lt;- matrix(0,5,5)m[1,2] &lt;- 1m[1,3] &lt;- 1m[2,3] &lt;- 1m[4,5] &lt;- 1m &lt;- m + t(m)max_length &lt;- 0maximal_connected_subgraph &lt;- NULLnode_num &lt;- length(m[,1])dfs &lt;- function(current_node,vis=NULL)&#123; candidate_node &lt;- which(as.logical(m[current_node,])) candidate_node &lt;- setdiff(candidate_node,visited) if(length(candidate_node) == 0)&#123; return(NULL) #这个0返回的没有意义的，随便都可以，只是单纯的结束 &#125; for(i in candidate_node)&#123; if(!any(visited == i))&#123; visited &lt;&lt;- c(visited,i) #访问i节点 &#125; dfs(i) #递归 &#125;&#125;for(i in 1:node_num)&#123; visited &lt;- c(i) dfs(i) print(visited) current_length &lt;- length(visited) if(current_length &gt; max_length)&#123; max_length &lt;- current_length maximal_connected_subgraph &lt;- visited &#125;&#125;sort(maximal_connected_subgraph)print(m[maximal_connected_subgraph,maximal_connected_subgraph]) 测试复杂的用例构造一个新的图这么构造是因为多了一个闭环，以及让1,和2节点多了一个选择，测试回朔的过程12&gt; sort(maximal_connected_subgraph)[1] 1 2 3 6 7 8 9 10 结果正确，就是打印的时候有点歧义，因为打印出来的矩阵如果没指定名字，又是1,2,3..顺序来的，会误以为是那几个节点，改一下名字就可以了1234mresult &lt;- m[maximal_connected_subgraph,maximal_connected_subgraph]colnames(mresult) &lt;- maximal_connected_subgraphrownames(mresult) &lt;- maximal_connected_subgraphprint(mresult) 结果是：12345678910&gt; print(mresult) 1 2 3 6 9 7 8 101 0 1 1 0 0 1 0 12 1 0 1 1 0 0 0 03 1 1 0 0 0 0 0 06 0 1 0 0 1 0 0 09 0 0 0 1 0 1 0 07 1 0 0 0 1 0 1 08 0 0 0 0 0 1 0 010 1 0 0 0 0 0 0 0]]></content>
      <categories>
        <category>R</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
        <tag>R</tag>
        <tag>R-piece</tag>
        <tag>BFS</tag>
        <tag>DFS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[naruto]]></title>
    <url>%2F2017%2F03%2F20%2Fnaruto%2F</url>
    <content type="text"><![CDATA[迈特凯语录 唯有努力，我不想输给他 真正的胜利，不是击败强者，而是保护对你而言最重要的东西。 不相信自己的人，连努力的价值都没有。 真正重要的东西，不管痛苦也好、悲伤也好…都要努力到底，就算失去生命也要用双手来保护到底!如此一来，就算死掉的话，也会永远留下男子汉活过的证据… 努力是绝不会背叛人的 你只要相信自己所走的路，大步向前走就好，然后就那样成为一个能让别人带着笑容守望着的人吧。 天资聪颖的人并非幸福，能够为自己所信任之人去努力拼搏的人才是幸福的！ 当新叶萌发，新春到来之时，才是青春的最高潮燃烧得最火热的时刻！ 既然我已经摆出帅哥的姿势来耍帅了,就必须要彻底地遵守约定! 小李,你要休息了吗? 青春的勋章离不开『热血』 我相信木叶的莲花一定会再次定放!! 青春的操场500圈!! 这就是青春!!! 李洛克：在一个有觉悟的男人面前，任何哀愁和悲伤都是对他的侮辱 在凯开八门遁甲，这个差点一脚踢出大结局的男人，令卡卡西尊敬不已，我反复看了好几遍。凯这个集逗逼与热血气质于一身的男人。 迈特凯父亲，迈特戴的语录 不要和你的努力说对不起，那样会多对不起你的努力啊！ 祝贺你从忍者 学校毕业，但青春可不能就此毕业啊。搜索青春什么时候结束？青春不会退缩，所以永远不会结束。那爸爸死的时候也不结束吗？那才是青春的最高潮！ 迈特戴：不过你的努力也不算错，就算只跑完一半，你也确实努力了。 迈特戴：你的忍术和体术不行，这才叫爸爸高兴，知道自己的短处，才能让长处发光， 迈特戴：爸爸很高兴，能让儿子在这么小的时候就发现长处， 迈特凯：爸爸，其实你在逞强吧， 迈特戴：短处也能变成长处，唠叨代表周到，啰嗦说明热门，顽固意味着专注， 迈特戴：所谓自我约束是指在向某些困难发起挑战时，故意给自己戴上一个枷锁，把自己逼到穷途末路， 制定只属于自己的规矩，正因为有了那个枷锁，你才会认真面对挑战，而一旦失败，你就能通过实践那个规矩，让自己得到严格的锻炼，使得自己不断进步，这才叫自我约束。 迈特戴为迈特凯的父亲，他影响了迈特凯的一生，而迈特凯也将这种影响传给了自己的徒弟李洛克 青春，热血！！！ 迈特戴经常在别人嘲笑他的时候，对别人说，谢谢支持。]]></content>
      <categories>
        <category>life</category>
      </categories>
      <tags>
        <tag>life</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[project of stackoverflow - python object(一)]]></title>
    <url>%2F2017%2F03%2F14%2Fstackoverflow_object_1%2F</url>
    <content type="text"><![CDATA[what does ‘super’ do in python下面两个的区别是？ 123class Child(SomeBaseClass): def __init__(self): super(Child, self).__init__() 和123class Child(SomeBaseClass): def __init__(self): SomeBaseClass.__init__(self) 我在单个继承中已经看到super 被用的很多了。我能知道为什么要在多重继承的时候用它，但是还是不清楚在这种情况用它的好处。 180票的回答：（John Millikin) 在单一继承用super的好处很小–只是你不再需要硬编码基类名字到方法里面去了 然后，在多重继承里，不用super()几乎是不可能的。这包括常见的习语，像是mixins，interface,abstract classes等，这能让你的代码在之后延伸。如果以后有人想写一个拓展Child 和 mixin的类，他们的代码不会很好的工作。 75票的回答： 区别是什么？ SomeBaseClass.__init__(self)意思是调用SomeBaseClass的__init__方法然后，super(Child,self).__init__()意思是从Child类的MRO的父类中调用一个绑定方法__init__如果实例是Child的子类，有可能在方法解释顺序中的下一个父类是不一样的？？？ 向前兼容间接 ？？ （Indirection with Forward Compatibility) 这能给你什么？对于单重继承，问题中给出的例子几乎等同于静态分析。然而使用super 提供了具有向前兼容性的间接层向前兼容对于经验丰富的开发者来说是很重要的。你希望你的代码在做出一些细微的改动之后还能工作。当您查看修订历史记录时，您希望准确地查看何时更改了哪些内容。 你可能先从单重继承开始，但是当你增加另外的基类，你只需要改变基类的顺序（change the line with the bases）（if the bases change in a class you inherit from）如果类继承关系变了（比如增加了一个mixin)，其实你就没做什么改变。尤其在python2中，要想给super正确的方法参数是很难的。如果你知道你在单重继承下正确的使用super，这样是的调试就容易一点了 依赖注入 Dependency Injection 其他人可以使用你的代码然后插入一些父类到方法解释中(method resolution): 12345678910111213class SomeBaseClass(object): def __init__(self): print('SomeBaseClass.__init__(self) called') class UnsuperChild(SomeBaseClass): def __init__(self): print('UnsuperChild.__init__(self) called') SomeBaseClass.__init__(self) class SuperChild(SomeBaseClass): def __init__(self): print('SuperChild.__init__(self) called') super(SuperChild, self).__init__() 现在你增加其他类，然后在Foo和Bar之间插入一个类 12345678class InjectMe(SomeBaseClass): def __init__(self): print('InjectMe.__init__(self) called') super(InjectMe, self).__init__() class UnsuperInjector(UnsuperChild, InjectMe): pass class SuperInjector(SuperChild, InjectMe): pass 使用un-super子类未能注入依赖，因为你是用的子类在自己执行打印后调用的是硬编码方法 123&gt;&gt;&gt; o = UnsuperInjector()UnsuperChild.__init__(self) calledSomeBaseClass.__init__(self) called 然而使用super的子类能正确的依赖注入 1234&gt;&gt;&gt; o2 = SuperInjector()SuperChild.__init__(self) calledInjectMe.__init__(self) calledSomeBaseClass.__init__(self) called (我：因为super按照MRO来寻找next类的，不是就是去找父类SomeBaseClass,因为SuperInjector的MRO是自身&gt; UnsuperChild &gt; InjectMe &gt; SomeBaseClass &gt; object 还有就是 super 不是在SuperChild内么，为什么要按SuperInjector的MRO来？？这里应该是因为SuperInjector的init没有定义，然后是用的supserchild的，但是还是按照自身的MRO来。怎么做实验 ) 结论一直使用super来引用父类就好了 你想要引用的父类是MRO下一个类，而不是你看到的继承的关系 不使用super 回让你代码的使用者多了很多不必要的限制 我的：一个例子就是123456from collections imoprt Counter, OrderedDictclass OrderedCounter(Counter, OrderedDict): passoc = OrderedCounter("abracadabra") 之前还一直奇怪这个为什么类里面pass，什么都不用写就能结合，现在知道是因为有super相当于我先把参数传递到Counter初始化，然后因为有super找到的是下一个MRO，然后到OrderedDict初始化相当于两个工序，先count再order。 How does Python’s super() actually work, in the general case?现在有很多有关super()的资源，包括这个博客写的，还有很多stackoverflow上的问题。但是我感觉它们都没有解释它在普遍情况下是怎么工作的，也就是底层的实现。 考虑下面的这个继承层次： 123456789101112131415161718192021class A(object): def foo(self): print 'A foo' class B(A): def foo(self): print 'B foo before' super(B, self).foo() print 'B foo after' class C(A): def foo(self): print 'C foo before' super(C, self).foo() print 'C foo after' class D(B, C): def foo(self): print 'D foo before' super(D, self).foo() print 'D foo after' 如果你读过python的方法解释顺序的规则，你就知道上面的MRO是（D,B,C,A,object)。 这是被D.mro决定的(&lt;class &#39;__main__.D&#39;&gt;, &lt;class &#39;__main__.B&#39;&gt;, &lt;class &#39;__main__.C&#39;&gt;, &lt;class &#39;__main__.A&#39;&gt;, &lt;type &#39;object&#39;&gt;)) 和12d = D()d.foo() 打印出的： 1234567D foo beforeB foo beforeC foo beforeA fooC foo afterB foo afterD foo after 结果符合MRO。 但是，考虑上面的B中的super(B,self).foo() 实际调用的是C.foo，这个是在b=B()中；b.foo() 会直接到A.foo 很显然使用super(B,self).foo()不是A.foo(self)的快捷键，虽然有时是 很显然super()是有意识的在意之前的调用，然后尝试着去跟随总的MRO链。我觉得有两个方法能完成这个。第一个是做了一些类似在链中将super对象传递给下一个方法的self参数,像原来self对象那样，但是包含了这个信息，但是这样似乎会破坏很多东西(super(D,d) is d是False)，然后做了一些实验，我觉得这个方法不可行。 另外一个方法是类似全局变量来保存MRO和现在的链上的位置。我想象中的super算法是这样的： 我们当前有工作的环境吗？如果没有，创建一个队列，获取MRO，将除了第一个之外的所有元素入队列 将当前上下文的MRO队列中pop一个元素，在构建super实例的时候将它作为当前的class 当访问super实例的一个方法的时候，在当前class上寻找，然后调用它 但是，这样却没有解释类似使用不一样的基类当作第一个参数来调用super，或者调用不同方法。（这段好别扭）我想知道这个的更普遍的算法。而且，如果这样的context存在的话，我能看吗？我能破坏他么？这当然是一个糟糕的想法，但是python希望你成为一个成熟的人尽管你不是。 这同样也引入了好多设计的考量。如果我写的B只考虑了它和A的联系，然后又有其他人写了C，还有其他人写了D，我的B.foo()方法必须找到一个能兼容C.foo()的方法来调用super，尽管我在写它的时候C不存在。如果我想要我的类能很简单的扩展，那我必须要考虑这些。但是我不清楚这是不是比简单的将所有的foo的特征设置成一样来的更复杂。还有一个问题就是什么时候将代码放在super之前，什么时候之后，即使在仅考虑B的基类的时候它没有什么区别 7票的回答： super() is then obviously aware of the previous calls before it 它不是。当你做super(B,self).foo,super知道你的MRO因为它会从type(self).__mro__中得到。然后它知道应该在MRO的B后面那里开始寻找foo，一个粗略的纯 python写的应该是这样的:12345678910111213141516171819202122232425class super(object): def __init__(self, klass, obj): self.klass = klass self.obj = obj def __getattr__(self, attrname): classes = iter(type(self.obj).__mro__) # search the MRO to find self.klass for klass in classes: if klass is self.klass: break # start searching for attrname at the next class after self.klass for klass in classes: if attrname in klass.__dict__: attr = klass.__dict__[attrname] break else: raise AttributeError # handle methods and other descriptors try: return attr.__get__(self.obj, type(self.obj)) except AttributeError: return attr If I wrote B thinking only of its relation to A, then later someone else writes C and a third person writes D, my B.foo() method has to call super in a way that is compatible with C.foo() even though it didn’t exist at the time I wrote it! 并不要求你要从随机的类中多种继承。除非foo是被特意设计成在多重继承的时候将兄弟类的重写。D不应该存在。]]></content>
      <categories>
        <category>stackoverflow</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>object</tag>
        <tag>stackoverflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[understanding MRO]]></title>
    <url>%2F2017%2F03%2F13%2Fmro%2F</url>
    <content type="text"><![CDATA[其实我一直觉得遇到什么障碍再去学什么是效率比较高的，这时候是带着问题去解决问题，比起干看，没有与实际相结合，要有用多了。所以等你真正遇到这个问题了，再来看看。 这个MRO是理解super方法的前序 ,以下考虑的都是多重继承，单重继承讨论这个就没什么价值了。 Method Resolution Order In computing, the C3 superclass linearization is an algorithm used primarily to obtain the order in which methods should be inherited (the “linearization”) in the presence of multiple inheritance, and is often termed Method Resolution Order (MRO)from wikipedia – C3 linearization 这里引进这个概念。因为在继承中，会有子类继承父类当中的一些元素或方法，但是在多重继承中，到底是哪一个呢？这里就涉及到了MRO，方法解释顺序。可以想像一个列表，里面是继承关系的顺序，当调用子类的方法，或访问子类的元素的时候，就按照这个顺序依次的查找。 12345678class A(object): passclass B(object): passclass C(B): passclass D(A,B,C): pass 你可以试一下，这个D类是定义不了的，会报错12345Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;TypeError: Error when calling the metaclass bases Cannot create a consistent method resolutionorder (MRO) for bases object, B, C 这里是因为破坏了MRO的一个(monotomic)单调性规定： if C1 precedes C2 in the linearization of C, then C1 precedes C2 in the linearization of any subclass of C. 通过C3算法得出的MRO就可以满足上面的这个要求 C3 linearization先定义几个符号表示：C1C2....CN 表示一个[C1,C2,C3….CN]的解决顺序列表，在这样的一个列表中，head是C1，其余的都叫做tail。注意：是从C2到最后都算tail.C+(C1C2...CN) = CC1C2...CN 表示[C] + [C1,C2...CN]L[C]表示linearization of class C，规定L[O] = O,O表示object 算法可以描述为一个递归的过程： the linearization of C is the Sum of C plus the merge of the linearizations of the parents and the list of the parents.L[C(B1B2...BN)] = C + merge(L[B1],...L[BN],B1...BN)顺序很重要，一一对应的。 merge 算法描述为(原文)： take the head of the first list, i.e L[B1][0]; if this head is not in the tail of any of the other lists, then add it to the linearization of C and remove it from the lists in the merge, otherwise look at the head of the next list and take it. if it is a good head, then report the operation until all the class are removed or it is impossible to find good heads. If fail, python will refuse to create the class C and will raise an exception. 没看懂直接看例子。 写出各个的linearization（这个翻译成啥我也不知道）123456L[O] = OL[E] = EOL[D] = DOL[F] = FOL[B] = B + merge(L[D],L[E],DE) = B + merge(DO,EO,DE) 这里是要merge3个list，DO,EO,DE，从第一个DO开始，它的head是D，然后看D是否出现在其他list的tail中中，注意tail是指除了head其余的所有。比如有一个list是ADCBEF,那D出现在第2个位置也算是在tail中，而不是在最后一个位置才算是tail。也就是说只有D出现在其他list首位置的时候，或者就根本没有D，这个D算是一个good head，然后将D加入B的linearization中，如果D不满足上面的条件，那么顺推到下一个list EO中的E，如果再不满足，继续顺推，都不满足的话就raise an exception。 123456L[B] = B + merge(L[D],L[E],DE) = B + merge(DO,EO,DE) = B + D + merge(O,EO,E) #再从第一个list O 开始去第一个元素O，但O不满足，出现在了第二个EO的tail中，顺延 = B + D + E + merge(O,O) = B + D + E + O = BDEO 1234L[C] = C + merge(DO,FO,DF) = C + D + merge(O,FO,F) = C + D + F + merge(O,O) = CDFO 123456789L[A] = A + merge(L[B],L[C],BC) = A + merge(BDEO,CDFO,BC) = A + B + merge(DEO,CDFO,C) = A + B + C + merge(DEO,DFO) = A + B + C + D + merge(EO,FO) = A + B + C + D + E + merge(O,FO) = A + B + C + D + E + F + merge(O,O) = A + B + C + D + E + F + O = ABCDEFO 另一个例子– 不能生成mro 12345L[O] = OL[X] = XOL[Y] = YOL[A] = AXYO L[B] = BYXO #这两个其实也应该通过上面那个merge算法算出来的，只不过这里一眼就能看出来 关键看类C123L[C] = C + merge(AXYO,BYXO,AB) = C + A + merge(XYO,BYXO,B) = C + A + B + merge(XYO,YXO) 到了这里就做不下去了，这里XYO,YXO，不管第一个X还是第二个的Y，都不行！！ X is in the tail of YXO whereas Y is in the tail of XYO因此算法结束.raise an error refuese to create class C 快速判别能否生成MRO的方法以下来自 python Attributes and Methods现在要定义一个新的类class N(A,B,C)画的稍微歪了，第一排全是O，那ok，result中也生成O放在顶部，第二排，BBC，不一样，要全部一样才能放在最后的result中，所以这个是失败的。 如果将类N的定义改为class N(A,C,B) 以上深入了解以下这个机制就可以，在编程的时候可以调用__mro__属性来查看一个类的mro，了解这个更有助于你理解你写的程序，比如super，比如描述符当中也会用到这个概念 出处： The Python 2.3 Method Resolution Order python Attributes and Methods]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>mro</tag>
        <tag>python-object</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python中的对象属性查找]]></title>
    <url>%2F2017%2F03%2F08%2Fobject-attribute-look-up%2F</url>
    <content type="text"><![CDATA[原文链接 这里面已经讲的很详细了。暂时还没有自己的深刻的思考和理解，就先搬运过来。 Instance attribute look up 实例属性查找 The implementation works through a precedence chain that gives data descriptors priority over instance variables, instance variables priority over non-data descriptors, and assigns lowest priority to getattr() if provided. 现在有一个类C和一个实例c = C()，现在调用c.name，相当于在实例c中查找name属性，流程如下：1234567891011121314151617181920212223Get the Class from InstanceCall the Class&apos;s special method __getattribute__.All objects have a default __getattribute__ Get the Class&apos;s __mro__ as ClassParents For each ClassParent in ClassParents if the Attribute is in the ClassParent&apos;s __dict__ if this attribute is data descriptor return the result from calling the data descriptor&apos;s special method __get__() Breaking the for each(do not continue searching the same Attribute any further) If the Attribute is in Instance&apos;s __dict__ return the value as it is(even if the value is a data descriptor) #这个意思是即使是描述符也直接返回这个对象，不会去调用__get__(),返回值类似&lt;__main__ descriptor object at Ox..&gt; For each ClassParent in ClassParents if the Attribute is in the ClassParent&apos;s __dict__ if is a non-data descriptor return the result from calling the non-data descriptor&apos;s special method __get__() if it is Not a descriptor return the value If Class has the special method __getattr__ return the result from calling the Class&apos;s special method __getattr__ Raise an AttributeError 有几个点要记住！ descriptors are invoked by the getattribute() method overriding getattribute() prevents automatic descriptor calls getattribute() is only available with new style classes and objects object.getattribute() and type.getattribute() make different calls to get() data descriptors always override instance dictionaries. non-data descriptors may be overridden by instance dictionaries. Class attribute look up 类属性的查找一个metaclass M，和一个M的实例，类C，这时候调用C.name的流程：其实和实例访问一一对应，就是各自都升了一个level12345678910111213141516171819202122232425262728Get the MetaClass from ClassCall the Metaclass&apos;s special method __getattribute__ Get the Metaclass&apos;s __mro__ as MetaParents For each MetaParent in MetaParents if the Attribute is in the MetaParent&apos;s __dict__ if is a data descriptor return the result from calling the data descriptor&apos;s special method __get__() Get the Class&apos;s __mro__ as ClassParents For each ClassParent in ClassParents if the Attribute is in the ClassParents&apos;s __dict__ if is a(data or non-data) descriptor return the result from calling the descriptor&apos;s special method __get__() # 实例在这层上不会调用__get__() else return the value For each MetaParent in MetaParents if the Attribute is in the MetaParents&apos;s __dict__ if is a non-data descriptor return the result from calling the non-data descriptor&apos;s special method __get__() if it is NOT a descriptor return the value If MetaClass has the special method __getattr__ return the result from calling the MetaClass&apos;s special method __getattr__ Raises an AttributeError 例子123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199#!/usr/bin/env python# coding=utf-8class Desc(object): # 定一个非数据描述符 def __init__(self, msg): self.msg = msg def __get__(self, instance, owner=None): return "&#123;0&#125;: &#123;1&#125;".format(self.typ, self.msg) # self.typ是啥？？？？ class NonDesc(Desc): # non-data descriptor typ = 'NonDesc'class DataDesc(Desc): # data descriptor typ = 'DataDesc' def __set__(self, instance, value): pass def __delete__(self, instance): passclass M(type): x = 'x from M' y = NonDesc('y from cls M') z = DataDesc('z from cls M') def __getattr__(self, name): return "getattr M &#123;0&#125;".format(name)class A(object): #t = 't from A' #u = NonDesc('u from cls A') #v = DataDesc('v from cls A') x = 'x from A' y = NonDesc('y from cls A') z = DataDesc('z from cls A')class B(A): """ metaclass is M """ __metaclass__ = M """ 这个metaclass什么用？？？？ """ class C(B): """ metaclass is inherited from C """ def __getattr__(self, name): return "getattr C: &#123;0&#125;".format(name) c = C()print '******'print 'c.__class__', c.__class__ #其实就是type(c), 还有注意c是新式类，格式应该是&lt;class '__main__.C'&gt;之类的print 'c.__class__.__getattribute__', c.__class__.__getattribute__ # 因为c.__class__也是一个对象# &lt;slot wrapper '__getattribute__' of 'object' objects&gt;print 'c.__class__.__mro__', c.__class__.__mro__ # method resolution order C B A Oprint '******'print 'c.x', c.x """父类们寻找顺序是根据c.__class__.__mro__ 来的c先去寻找父类们中有没有x的描述符，没有，然后在自己的__dict__中找x，也咩有，然后再去父类们的__dict__中找有没有这个属性名的non-data 描述符，没有，不是描述符而是直接属性的呢？A中有，返回A中的x值"""print 'c.y', c.y"""同上，父类的顺序不废话了最终在第三阶段找到A中的y，它是一个non-data descriptor，NonDesc: y from cls A"""print 'c.z', c.z"""在第一个阶段中的A中找到z 是一个data descriptor，饭后 DataDesc: z from cls A"""print 'c.nope', c.nope"""当前三个阶段都找不到的时候，如果类中有定义__getattr__，就到这里去，没有报错这里所有三个阶段没有nope属性，然后到了__getattr__，返回 getattr C: nope"""c.t = 't from obj c'c.u = NonDesc('u from obj c')c.v = DataDesc('v from obj c')c.x = 'x from obj c'c.y = NonDesc('y from obj c')c.z = DataDesc('z from obj c')print '******'print 'c.t', c.t"""如上，在第二个阶段找到t, 返回 t from obj c"""print 'c.u', c.u"""在第二个阶段在c字典里面找到，不管是值还是descriptor ，这里会调用__get__() NonDesc: u from obj cupdate:更正因为在"""print 'c.v', c.v"""在第二阶段c字典里找到, 调用__get__() ，返回 DataDesc: v from obj c"""print 'c.x', c.x"""因为在第一阶段是在类父类中找描述符，虽然A中有属性x但不是描述符，因此进入第二个阶段，在实例字典中找，不管是不是描述符只要名字对了就返回. 这里在这个阶段返回x from obj c"""print 'c.y', c.y"""同上，返回的是 NonDesc: y from obj c"""print 'c.z', c.z"""同上，返回的是 DataDesc: z from obj c"""print '******' # 这里是用到 class attribute look up 。 以上是对实例进行点运算print "C.x", C.x"""因为B的metaclass是M了，C继承B，C现在的metaclass也是M现在要将上面的所有概念都升级，原来class变成metaclass，原来instance变成class先根据metaclass里的mro决定先后顺序metaparents因为这里是类属性访问，C类的metaclass是M，M.__mro__ 是 (&lt;class '__main__.M'&gt;, &lt;type 'type'&gt;, &lt;type 'object'&gt;)按顺序找x的描述符，但M中没有x的描述符，然后type，object都没有。进入第二个阶段，先计算C.__mro__,按照顺序依次访问类字典C,B,A,O ， 如果有属性重名，先要描述符，不然只要是在__dict__中就返回c中没有x,然后去B，B里面也咩有x，到A中，有x但是不是描述符，没关系直接返回,因为也没有名字为x的描述符了。返回x from A"""print "C.y", C.y"""同上，虽然在M中有y但是是非数据描述符，在第2阶段中的A类中找到y非数据描述符,返回 NonDesc: y from cls A"""print "C.z", C.z"""这是在第一个阶段中的M里找到z数据描述符， 返回 DataDesc: z from cls M"""print "C.nope", C.nope"""上面三个阶段都没有，进入第四个阶段，这个阶段不是去C中的__getattr__，因为上面说了都升了一级，现在是在M中的__getattr__，如果M里面没有__getattr__，那么就回报错，现在M有，返回 getattr M nope"""C.t = 't from obj C'C.u = NonDesc('u from obj C')C.v = DataDesc('v from obj C')C.x = 'x from obj C'C.y = NonDesc('y from obj C')C.z = DataDesc('z from obj C')"""如果是类属性访问，好像没有A，B什么事 !!!!写在流程搞错之前，之前在第二阶段没有计算类的__mro__重新看一下流程"""print '******'print "C.t", C.t"""因为metaclass以及mro中都没有t，进入下一个阶段在第二阶段中现在C类中有t这个属性了，返回 t from obj C"""print "C.u", C.u"""同上，在第二阶段中C类的__dict__中找到，返回 NonDesc: u from obj C"""print "C.v", C.v"""同上，在第二阶段中返回 DataDesc: v from obj C"""print "C.x", C.x"""和M中有重名，但是因为M中的不是数据描述符，这个的优先级高，在第二阶段返回 x from obj C虽然A中也有x，但是mro顺序C排在A前面"""print "C.y", C.y"""同上，有重名，但是M中是非数据描述符，第一阶段过，到第二阶段，返回 NonDesc: y from obj C然后A中同理"""print "C.z", C.z"""重名，但是z在M中是数据描述符，在第一阶段就返回 DataDesc: z from cls M"""print "C.nope", C.nope"""这个没有变 getattr M nope""" 结果：1234567891011121314151617181920212223242526272829******c.__class__ &lt;class '__main__.C'&gt;c.__class__.__getattribute__ &lt;slot wrapper '__getattribute__' of 'object' objects&gt;c.__class__.__mro__ (&lt;class '__main__.C'&gt;, &lt;class '__main__.B'&gt;, &lt;class '__main__.A'&gt;, &lt;type 'object'&gt;)******c.x x from Ac.y NonDesc: y from cls Ac.z DataDesc: z from cls Ac.nope getattr C: nope******c.t t from obj cc.u &lt;__main__.NonDesc object at 0x1009b8f10&gt;c.v &lt;__main__.DataDesc object at 0x1009b8f50&gt;c.x x from obj cc.y &lt;__main__.NonDesc object at 0x1009b8f90&gt;c.z DataDesc: z from cls A******C.x x from AC.y NonDesc: y from cls AC.z DataDesc: z from cls MC.nope getattr M nope******C.t t from obj CC.u NonDesc: u from obj CC.v DataDesc: v from obj CC.x x from obj CC.y NonDesc: y from obj CC.z DataDesc: z from cls MC.nope getattr M nope]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>object</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[descriptor]]></title>
    <url>%2F2017%2F03%2F08%2Fdescriptor%2F</url>
    <content type="text"><![CDATA[其实自己没有深入的研究源码，这篇也是基于阅读一些官方文档和他人的博客做的总结。我这里的思路是从描述符的渊源到为什么有这个描述符，然后怎么用这里先直接给出描述符的定义，先有个印象，如果一开始阅读感觉没什么联系，没关系，最终那些点将连成线的。官方的定义： In general, a descriptor is an object attribute with “binding behavior”, one whose attribute access has been overridden by methods in the descriptor protocol. Those methods are get(), set(), and delete(). If any of those methods are defined for an object, it is said to be a descriptor.from – Descriptor HowTo Guide 也就是只要一个类定义了__get__(),__set__(),__delete__()当中的任意一个特殊方法,这个类就有了个别名“描述符”啦 描述符的由来首先，因为python是一种动态编译的语言，他能在运行中动态添加类属性或类对象属性。那这些属性是被保存在比如a.__dict__这个里面，这里a是一个实例a=A()。其实类也有一个__dict__属性，通过A.__dict__就可以访问到. 123456789101112131415&gt;&gt;&gt; class A(object):... def __init__(self):... self.attr = 1... def foo(self):... print self.attr...&gt;&gt;&gt; a = A()&gt;&gt;&gt; dir(a)['__class__', '__delattr__', '__dict__', '__doc__', '__format__', '__getattribute__', '__hash__', '__init__', '__module__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'attr', 'foo']&gt;&gt;&gt; dir(A)['__class__', '__delattr__', '__dict__', '__doc__', '__format__', '__getattribute__', '__hash__', '__init__', '__module__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'foo']&gt;&gt;&gt; a.__dict__&#123;'attr': 1&#125;&gt;&gt;&gt; A.__dict__dict_proxy(&#123;'__module__': '__main__', '__dict__': &lt;attribute '__dict__' of 'A' objects&gt;, 'foo': &lt;function foo at 0x101bba668&gt;, '__weakref__': &lt;attribute '__weakref__' of 'A' objects&gt;, '__doc__': None, '__init__': &lt;function __init__ at 0x101bba5f0&gt;&#125;) 注意到在A类中定义了一个foo函数，像这样的函数在C++语言中被称为成员函数，但是可以看到在a.__dict__中没有foo，在A.__dict__中有。其实通过访问，可以看出a.__dict__中保存的都是一些变量属性。这么理解，在C++中成员函数是被所有对象所共享的，不会为没个对象复制一份，这里也一样，可以看作是类的一个属性，不是实例的属性。那其实在python中，这么做是牵涉到了它的另外的两个概念，绑定，未绑定函数和描述符。先说一下，所有的类成员函数都是non-data despriptor。后面会继续解释 In a nutshell, a descriptor is a way to customize what happens when you reference an attribute on a model.from – Python Descriptors, Part 1 of 2 Descriptor are the mechanism behind properties, methods, static methods, class methods and super()from – Descriptor HowTo Guide 访问属性查找属性的访问顺序建议先把下面的看了再来看这个 我之所以说先看下面，又不得不把这个主题先放上来，是因为其实描述符归根结底，目前看到就是对属性的取值赋值操作，只不过是对这个操作封装了一下而已。12a.attr = 1tmp = a.attr 一般的取值赋值就是这样子的，如果attr事先在类里面定义好了的self.attr = arg 上面的a.attr = 1其实就是重新将“标签”a.attr贴到1数值上去，如果没有那就是动态生成attr属性。但是这样的赋值太单一了，什么意思，也就是说，如果我要对赋入的值做下额外的检查，比如学生的成绩，不可能出现负数，身高也不可能出现负数。所以想到了在__init__当中增加一些逻辑代码进行检查123def __init__(self,score): assert score&gt;=0,"value error" self.score = score 但是这样只是在初始化的时候，像a = A(-1)会报错，那之后如果a.score = -100像这样的误操作，也没人阻止。那我们又有了另一种思路123456def get_score(self): return self.scoredef set_score(self,new_score): assert new_score&gt;=0,"value error" self.score = new_score 通过a.set_score(-100)，调用一个函数，并在函数体内进行检查来进行赋值。 总的来讲，python的属性获取，设置，这个属性只是一个存储的地方，只是一个容器，但往往你可能需要更多的功能，比如赋值的时候检验，然后，一般的，是用一些方法来做这些事情，但是如果对于已经存在了的属性，你想用函数代替取值，赋值，你就要重写代码，找到所有用到这些属性的方法，然后改成函数，比如上面的所有a.score = 1像这样的操作改成a.set_score(1)。这样就增加了工作量，这也是为什么在java程序中一个简单的取值都要封装成一个函数，就是为了避免何种情况，常见的模式也就是属性定义为私有变量，然后开放一个公有接口。python中的描述符只不过是另一种方法来实现这种对属性额外控制的需求而已 描述符实例描述符的用法应该不局限于下面给出的例子，要多看其他高人的代码！！！12345678910111213class Positive(object): def __init__(self,name): self.name = name def __get__(self,instance,owner): if instance is None: return self #这里相当于如果通过类调用,Student.score，就返回是类似&lt;descriptor.Positive object at 0x123455..&gt;之类的 return instance.__dict__[self.name] def __set__(self,instance,value): if value &lt; 0: raise ValueError("negative value error...") instance.__dict__[self.name] = value 上面就定义了一个描述符。其实就是一个类，描述符只是个名称而已。在我的世界里，我想叫它皮皮虾都可以。只是全世界就这么流通规定了12345class Student(object): score = Positive('score') #这句话就将score属性让描述符代理了 def __init__(self,name,score): self.name = name self.score = score 现在如果有这么一个语句s = Student(&#39;cy&#39;,100);a = s.score，其实是相当于在做a = type(s).__dict__[&#39;score&#39;].__get__(s,type(s))可以查看Student.__dict__中的score属性是&#39;score&#39;: &lt;__main__.Positive object at 0x101bb8ed0&gt;这样子的。当作了type(s).__dict__[&#39;score&#39;]时其实就是获得了一个实例，之后还可以继续用点运算符往下接着做。 Q&amp;APositive 描述符中的__set__为什么参数中没有类？1234567&gt;&gt;&gt; Student.__dict__dict_proxy(&#123;'__module__': '__main__', 'score': &lt;__main__.Positive object at 0x101bb8ed0&gt;, '__dict__': &lt;attribute '__dict__' of 'Student' objects&gt;, '__weakref__': &lt;attribute '__weakref__' of 'Student' objects&gt;, '__doc__': None, '__init__': &lt;function __init__ at 0x101bbaaa0&gt;&#125;)#注意上面的score属性的值&gt;&gt;&gt; Student.score = 12 # 通过类访问&gt;&gt;&gt; Student.__dict__dict_proxy(&#123;'__module__': '__main__', 'score': 12, '__dict__': &lt;attribute '__dict__' of 'Student' objects&gt;, '__weakref__': &lt;attribute '__weakref__' of 'Student' objects&gt;, '__doc__': None, '__init__': &lt;function __init__ at 0x101bbaaa0&gt;&#125;)#再对比一下score的值 当类调用的时候，其实就是设置同名新值了，它将原来的描述符给替换覆盖了。 Student类里面的score和self.score,到底用的是哪个？？可以先看一下12345&gt;&gt;&gt; s = Student('cy','100')&gt;&gt;&gt; s.__dict__&#123;'score': '100', 'name': 'cy'&#125;&gt;&gt;&gt; Student.__dict__dict_proxy(&#123;'__module__': '__main__', 'score': &lt;__main__.Positive object at 0x101bb8ed0&gt;, '__dict__': &lt;attribute '__dict__' of 'Student' objects&gt;, '__weakref__': &lt;attribute '__weakref__' of 'Student' objects&gt;, '__doc__': None, '__init__': &lt;function __init__ at 0x101bbaaa0&gt;&#125;) 其实这里涉及到一个优先级的问题，也就是上面的访问属性的顺序链接。这里可以再跳回去看。因为描述符的优先级高！并且会改变默认的get,set方法。 If an instance’s dictionary has an entry with the same name as a data descriptor, the data descriptor takes precedence. If an instance’s dictionary has entry with the same name as a non-data descriptor,the dictionary entry takes precedence.from Descriptor HowTo Guide 什么是non-data descriptor后面会说明。 2引申的一个问题就是如果self.score = score没有定义会是什么情况1234567891011121314&gt;&gt;&gt; class Student(object):... score = Positive('score')... def __init__(self,name):... self.name = name...&gt;&gt;&gt; s = Student('cy')&gt;&gt;&gt; s.score = 10&gt;&gt;&gt; s.__dict__&#123;'score': 10, 'name': 'cy'&#125;&gt;&gt;&gt; s.score = -10Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "&lt;stdin&gt;", line 10, in __set__ValueError: negative error 还是照样行得通。因为instance.__dict__[self.name] = value.虽然初始化的时候没有score这个属性，但其实后面的字典操作，相当于动态增加了这个属性，而且访问的优先级照样根据那个顺序来 如果是self.score = Positive(&#39;score&#39;)会怎么样1234567891011&gt;&gt;&gt; class Student(object):... def __init__(self,name):... self.name = name... self.score = Positive('score')...&gt;&gt;&gt; s = Student('cy')&gt;&gt;&gt; s.__dict__&#123;'score': &lt;__main__.Positive object at 0x101bc70d0&gt;, 'name': 'cy'&#125;&gt;&gt;&gt; s.score = -10&gt;&gt;&gt; s.__dict__&#123;'score': -10, 'name': 'cy'&#125; 没有起到作用，这是必然的。如果你知道访问顺序了之后，访问s.score时，因为类中没有同名的描述符，所以到实例中的__dict__看，如果有这个key，返回，但这里是赋值操作，参考另一篇python name and values，s.scorei = -10只不过是将score这个name重新贴标签贴到数值-10上去。 __get__中参数owner什么用，也没有用到它啊？后面在classmethod中就会用到这个参数。其实函数参数写在哪里，也不一定都要用到，但更关心为什么要这么设计。后面看看源代码 看一个图： 应用场景python中有个叫修饰器的东西，property()，它是描述符的简介版123456789@propertydef score(self): return self.__score@score.setterdef score(self,score): if score &lt; 0: raise ValueError('negative') self.__score = score calling propery() is a succinct way of building a data descriptor that triggers function calls upon access to an attributefrom Descriptor HowTo Guide 上面的写法@property使用到了装饰器 但是如果一个类里面有很多属性是相同的限制，比如学生的身高不能负数，成绩不能负数，体重不能负数，如果用property的话，那就多了很多重复的代码，每个属性都要像上面一样写一遍。这时候就可以考虑用写一个描述符类来“一统天下”了 在之前说的对于已存在的属性，如果要对它们要进行限制，通过方法的话要找到每一处，这样很不方便，如果使用描述符只需要在类中加上tall = Positive(&#39;tall&#39;)像这样的语句就可以了，而且完全没有任何副作用！！ If looked-up value is an object defining one of the descriptor methods, then python may override the default behavior and invoke the descriptor method instead.from Descriptor HowTo Guide 描述符的种类 学习也要遵循20/80定律，学到的20%就足够写程序了，先跑起来再来完善接下来的80%– 尔东诚霍划夫斯基描述符分data descriptor和non-data descriptor两者之前的区别就是，后者只定义了__get__。也就是没有设置。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>descriptor</tag>
        <tag>object</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zlt-project]]></title>
    <url>%2F2017%2F03%2F01%2Fzlt-project%2F</url>
    <content type="text"><![CDATA[最近一直在用python写，这个也用python试试。需求图示 用到： 正则表达式：用来匹配test.py中的test名的 shutil模块，shutil.copy复制 os模块，切换目录用的。os.listdir,os.path.isfile等 sys模块，sys.argv命令行参数 Tkinter，图形化界面 主要的拷贝逻辑写出来12345678910111213141516171819import reimport osimport shutilimport syspath_a = sys.argv[1]path_b = sys.argv[2]candidate_list = [x for x in os.listdir(path_b) if os.path.isfile(x) and x[0]!='.']p = re.compile('\w+')candidate = [p.match(file_name).group() for file_name in candidate_list]#先把B文件中的文件名提取出来for prefix in candidate: for every_file in os.listdir(path_a): if predix in every_file: file_path = path_a + '/' + every_file shutil.copy(file_path,path_b) print 'copy %s to %s'%(every_file,path_b) 接下来就是披上一件外衣了，Tkinter。下面是代码 zlt_main_frame_listbox.py 这个是显示文件夹功能的窗口123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112#!/usr/bin/python#-*- coding: utf-8 -*-# File Name: zlt.py# Created Time: Sun Mar 5 21:56:03 2017__author__ = 'Crayon Chaney &lt;mmmmmcclxxvii@gmail.com&gt;'import osfrom Tkinter import *from time import sleepimport pdbclass ShowList(Frame): # count = 0 def __init__(self,parent,initdir=None): # super(ShowList,self).__init__(parent) """ 上面这个为什么不行？？？ """ Frame.__init__(self,parent) self.parent = parent self.cwd = StringVar(self) self.wholecwd = StringVar(self) self.dir_display = Label(self,font = ('Helvetica',12,'bold'),fg = 'blue') self.dir_display.pack() self.dirfm = Frame(self) self.dirsb_y = Scrollbar(self.dirfm) self.dirsb_x = Scrollbar(self.dirfm,orient="horizontal") self.dirlb = Listbox(self.dirfm,yscrollcommand = self.dirsb_y.set,xscrollcommand = self.dirsb_x.set,height =20,width = 30 ) self.dirsb_y.config(command = self.dirlb.yview) self.dirsb_x.config(command = self.dirlb.xview) self.dirlb.bind('&lt;Double-1&gt;',func=self.selectAndGo) self.dirsb_y.pack(side = RIGHT,fill=Y) self.dirsb_x.pack(side = BOTTOM,fill=X) self.dirlb.pack(side=LEFT,fill=BOTH) self.dirfm.pack() self.input = Entry(self,textvariable=self.cwd) self.input.bind('&lt;Return&gt;',func = self.doLs) self.input.pack() self.dirbuttonfm = Frame(self) self.clrbutton = Button(self.dirbuttonfm,text='clear',command=self.clrEntry) self.clrbutton.pack(side=LEFT) self.listbutton = Button(self.dirbuttonfm,text='List Directory',command=self.doLs) self.listbutton.pack(side=LEFT) self.dirbuttonfm.pack() if initdir: self.cwd.set(initdir) self.doLs() def clrEntry(self,ev = None): self.cwd.set('') def selectAndGo(self,ev=None): self.last = self.cwd.get() self.dirlb.config(selectbackground='red') self.cwd.set(self.dirlb.selection_get()) self.doLs() def doLs(self,ev = None): cur = self.cwd.get() error = '' if not os.path.exists(cur): error = '%s is not exists'%cur elif not os.path.isdir(cur): error = "%s is not dir"%cur if error: self.cwd.set(error) self.parent.update() sleep(2) if not (hasattr(self,'last') and self.last): self.last = os.curdir self.cwd.set(self.last) self.dirlb.config(selectbackground='LightSkyBlue') return self.cwd.set('Fetching...') self.parent.update() dirfiles = os.listdir(cur) os.chdir(cur) self.dir_display.config(text=os.getcwd()) self.wholecwd.set(os.getcwd()) dirfiles.sort() self.dirlb.delete(0,END) self.dirlb.insert(END,os.curdir) self.dirlb.insert(END,os.pardir) for eachdirname in dirfiles: self.dirlb.insert(END,eachdirname) self.cwd.set(os.curdir) self.dirlb.config(selectbackground='LightSkyBlue')if __name__ == '__main__': root = Tk() ShowList(root,os.curdir).pack() root.mainloop() zlt_windows.py 主窗口123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106#!/usr/bin/python#-*- coding: utf-8 -*-# File Name: zlt_windows.py# Created Time: Mon Mar 6 14:13:52 2017__author__ = 'Crayon Chaney &lt;mmmmmcclxxvii@gmail.com&gt;'from zlt_main_frame_listbox import *import shutilimport reimport sysclass CopyDir(object): def __init__(self): self.top = Tk() self.top.title('你花大爷呕心沥血作') # ShowList(self.top).pack(side=LEFT) self.A = ShowList(self.top,os.curdir) self.A.pack(side=LEFT) self.topbuttonfm = Frame(self.top) self.copybutton = Button(self.topbuttonfm,text='&lt;--A copy B--&gt;',width = 15,command = self.confirmCopy) self.copybutton.pack() self.quitbutton = Button(self.topbuttonfm,text='退出',command = self.top.quit) self.quitbutton.pack() self.topbuttonfm.pack(side = LEFT,ipadx = 5) # ShowList(self.top).pack(side=LEFT) self.B = ShowList(self.top,os.curdir) self.B.pack(side=LEFT,ipadx = 5) def confirmCopy(self,ev = None): self.confirmtop = Toplevel(self.top) # pdb.set_trace() self.a_path = self.A.wholecwd.get() self.b_path = self.B.wholecwd.get() listfiles_a = os.listdir(self.a_path) listfiles_b = os.listdir(self.b_path) title_msg = '复制这些到%s'%self.b_path self.confirmtop.title(title_msg) # self.fm = Frame(self.confirmtop) # to be pack self.copy_candidates_info = Text(self.confirmtop,height=30,width = 20) # to be pack pattern = re.compile('\w+') self.to_be_copied_list = [] for to_be_copied in listfiles_b: try: prefix = pattern.match(to_be_copied).group() except AttributeError,e: continue # print e # if 'NoneType' in e: # continue # else: # sys.exit() for eachfile in listfiles_a: if prefix in eachfile :# and os.path.isfile(self.a_path+'/'+prefix): 可能在windows下不支持 self.to_be_copied_list.append(eachfile) # self.copy_candidates_info.delete(0,END) for item in self.to_be_copied_list: self.copy_candidates_info.insert(END,item+'\n') # window下换行符可能不一样 \r\n self.copy_candidates_info.pack(side = LEFT,padx = 10) information = 'copy to %s'%self.b_path self.other_information = Label(self.confirmtop,text = information) self.other_information.pack(side=LEFT,ipadx = 5,ipady = 13) self.fm = Frame(self.confirmtop) self.result_info = Label(self.fm,font = ('Helvetica',12,'bold'),fg='red') self.confirmbutton = Button(self.fm,text='确认',command = self.copyExecute) self.cancelbutton = Button(self.fm,text='取消',command = self.confirmtop.quit) """ 为什么点击取消会全体退出？？？ 想要的效果是只是这个确认窗口退出而已 """ self.result_info.pack(side=LEFT) self.confirmbutton.pack(side = LEFT) self.cancelbutton.pack(side=LEFT) self.fm.pack(side = BOTTOM) def copyExecute(self,ev=None): os.chdir(self.a_path) if not (hasattr(self,'to_be_copied_list') and len(self.to_be_copied_list)): self.result_info.config(text='Failed') return for item in self.to_be_copied_list: try: shutil.copy(item,self.b_path) except Exception,e: self.result_info.config(text=e) else: self.result_info.config(text='Successful') def main(): c = CopyDir() mainloop()if __name__ == '__main__': main() 发现的bug： 因为我现在是在一个窗口生成了两个文件夹展示的frame，但是在一个进程中，一个文件夹切换了路径，另一个就跟着切换了导致出现bug，解决方法，要用多线程]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>project</tag>
        <tag>Tkinter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python types and objects]]></title>
    <url>%2F2016%2F12%2F03%2Fpython-types-and-objects%2F</url>
    <content type="text"><![CDATA[Python Types and Objects这篇文章解释了： 什么是&lt;type &#39;type&#39;&gt;和 用户自定义的类和实例是怎么联系在一起的以及和内建类型的联系 什么是metaclass元类 type和object从之前的学习面向对象编程来看，我们可以通过继承来定义一个类，也可以查看一个对象属于哪个类。其实这就可以抽象出两种关系图中虚线就是type，表示一个对象(又称‘实例’)的类型是尖头指向的那个图中的实线是base，表示一个类的基类是尖头指向的那个 the type and base(if exist) are important, coz they define special relationships an object with other objects. 因为在python中一切皆为对象，所以base到头了就是object，这个是在python中一切类的祖宗。而因为python中一切皆为对象, 它就有类型，object也是一个对象，它的类型就是type，type本身也是一个对象，为了满足python这样的设定，它的类型就是它自己。type既是一个对象，也是一个类。就说我们自己定义了一个类1234567&gt;&gt;&gt; class A(object):... pass...&gt;&gt;&gt; A.__bases__(&lt;type 'object'&gt;,)&gt;&gt;&gt; A.__class__&lt;type 'type'&gt; 他也有类型，就是type类型 keep in mind that the types and bases of objects just other objects 既然像类也是一种”对象”,那它是谁的对象？？答案就是metaclass，type就是metaclass。先有鸡还是先有蛋？ 类和类型的统一这个问题在知乎上有一个解答不错 旧式类的实现不够好，类是类，实例是实例，类的类型是classobj，实例的类型是instance，两者的联系只在于class，这和内置对象是不同的，int对象的类型就是int，同时int()返回的也是int类型的对象，内置对象和自定义对象不同就对代码统一实现带来很大困难。比如说有段代码输入一个对象，返回一个默认构造的同类型对象，本来应该写作type(obj)()，现在就必须写成：obj.class() if hasattr(obj, ‘class‘) else type(obj)()。如果想用自定义的类去替代一些系统内置类型，比如说自定义一个dictionary，这样的不一致就会出问题新式类之后自定义类和内置类型就一致了：1. 所有类型的类型都是type2. 所有类型调用的结果都是构造，返回这个类型的实例3. 所有类型都是object的子类这样就不再需要区分自定义类和类型了。实现这件事其实并不容易，理性上来想，type的基类是object，而object的类型是type，这是一个先有鸡还是先有蛋的问题。Python通过对这几个类的特殊处理实现了这样的逻辑。 作者：灵剑链接：https://www.zhihu.com/question/38803693/answer/103128686来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 自定义类和内建类型图片来自那个文章顶部那个链接,这篇文章写的很详细了 Dashed lines cross spacial boundaries (i.e. go from object to meta-object). Only exception is (which is good, otherwise we would need another space to the left of it, and another, and another…). Solid lines do not cross space boundaries. Again, -&gt; is an exception. Solid lines are not allowed in the rightmost space. These objects are too concrete to be subclassed. Dashed line arrow heads are not allowed rightmost space. These objects are too concrete to be instantiated. Left two spaces contain types. Rightmost space contains non-types. If we created a new object by subclassing it would be in the leftmost space, and would also be both a subclass and instance of . 两个对象python中分Type对象和Non-Type对象，这个Non-Type不是一个正式的概念，只是这么称呼，这类对象，比如2，就是2，2怎么再派生？怎么再实例化，不行，所以是too concrete。怎么判断，只要type(obj)出来的是&lt;type &#39;type&#39;&gt;就是Type对象，不然就是Non-Type对象 Type objects - can create instances, can be subclassed. Non-type objects - cannot create instances, cannot be subclassed. objectname.__class__ exists for every object and points the type of the object. objectname.__bases__ exists for every type object and points the superclasses of the object. It is empty only for &lt;type &#39;object&#39;&gt;. Some non-type objects can be created using special Python syntax. For example, [1, 2, 3] creates an instance of &lt;type &#39;list&#39;&gt;. 两个动作两种关系对应两种动作可以生成两种对象。有可能是Type对象,也有可能是Non-Type对象。两个动作就是subclassing和instantiating. subclassing这个动作具体就是class语句,定义一个类，或者说定一个type， This means you can create a new object that is somewhat similar to existing type objects. To create a new object using subclassing, we use the class statement and specify the bases (and, optionally, the type) of the new object. This always creates a type object. 这段代码抽象代表的就是一个类 instantiating这个动作就是实例化，由一个type实例化出对象，type相当于一个工厂的模型，具体就是通过()操作。 To create a new object using instantiation, we use the call operator (()) on the type object we want to use. This may create a type or a non-type object, depending on which type object was used. This means you can create a new object that is an instance of the existing type object. python中的内建类型是在启动python后生成的。比如1234567&gt;&gt;&gt; type(list)&lt;type 'type'&gt;&gt;&gt;&gt; list.__bases__(&lt;type 'object'&gt;,) # list是从object派生而来了&gt;&gt;&gt; ml = [1,2,3]&gt;&gt;&gt; type(ml)&lt;type 'list'&gt; 如果问[1,2,3]是什么类型啊？列表类型啊。列表类型是什么类型啊？type类型啊。type类型是什么类型啊？type类型。。。当我们创建{‘a’:1,’b’:2},(1,2)这种，是从&lt;type &#39;list&#39;&gt;,&lt;type &#39;dict&#39;&gt;实例化出来的，也就是相应的type，包括自定义。 metaclass很重要的一点就是，当我class语句定义了一个类，我就自动的有了一个type，其实也就是说__class__（新式类）12class C(object): pass type(C)就已经定了。它是根据所继承的父类的type延续下来的，因为object的类型是type所以12&gt;&gt;&gt;type(C)&lt;type 'type'&gt; 那其实这样追溯下去，因为object类型是type类，所以所有的类都是type类。除了Non-Type对象的类型是相对应的类。所以那幅图的前面两列的虚线都指到type。这里有一个问题就是它是由继承关系决定的，那如果是多重继承呢？是继承哪个？1234567891011121314151617181920212223&gt;&gt;&gt; class M1(type):... pass...&gt;&gt;&gt; class M2(type):... pass...&gt;&gt;&gt; class A(object):... __metaclass__ = M1...&gt;&gt;&gt; class B(object):... __metaclass__ = M2...&gt;&gt;&gt; type(A)&lt;class '__main__.M1'&gt;&gt;&gt;&gt; type(B)&lt;class '__main__.M2'&gt;&gt;&gt;&gt; class C(A,B):... pass...Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; TypeError: Error when calling the metaclass bases metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases 如果大家的metaclass都一样，那就没得说了，如果不一样，那么就会混乱，这时候要指定。什么时候会不一样呢？一般情况下都是type，除非自己定义specialType然后派生。但建议是不要用这个特性。 另一个问题就是，到底怎么自定义specialType？上面例子已经给出答案了。12class C(object): __metaclass__ = specialType 隐式关系图片来自文章顶部链接文章中的： issubclass问的是一个class是不是subclass of 另一个class。class和class之间的关系isinstance问的是一个object是不是instance of 另一个class。object和class之间的关系 12345678910111213141516&gt;&gt;&gt; isinstance(type,type) #虚线，type指向自己 True&gt;&gt;&gt; isinstance(type,object) #因为type是自身的实例，type又是object的子类，所以type是object的实例True&gt;&gt;&gt; isinstance(object,object) #因为object是type的实例，type又是object的子类，所以object是object的实例True&gt;&gt;&gt; isinstance(object,type) # 虚线True&gt;&gt;&gt; issubclass(type,type) # A class is considered a subclass of itselfTrue&gt;&gt;&gt; issubclass(type,object) # 实线True&gt;&gt;&gt; issubclass(object,object) # 任何类都是object的子类True&gt;&gt;&gt; issubclass(object,type) # object在类的金字塔顶端，它上面就没人啦False A class is considered a subclass of itself Q&amp;A class,object,instance的关系 An object is an instance of a class, and may be called a class instance or class object; instantiation is then also known as construction. Not all classes can be instantiated – abstract classes cannot be instantiated, while classes that can be instantiated are called concrete classes. How does python really create a new object? Internally, when python creates a new object, it always uses a type and creates an instance of that object. Specifically it uses the new() and init() methods of the type. In a sense, the type serves as a factory that can churn out new objects, the type of these manufactured objects will be the type object used to create them. This is why every object has a type.]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>object</tag>
        <tag>type</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Interesting experience -- challenge school master swimming]]></title>
    <url>%2F2016%2F11%2F11%2Fswimming-with-master%2F</url>
    <content type="text"><![CDATA[–update–其实现在想想，可能当初会有更成熟的做法。 其实真的，在决定要去雷励的时候，众筹这个任务就已经压在我的肩上了，虽然后来真的校长答应我的挑战促使了我的任务圆满完成，但这其中的历程更值得细嚼慢咽 公开信的问题发邮件给学校办公室，给校长邮箱，我是不知道会不会有人看到，或者能有多大的反响，站在我自己的角度上，我肯定是希望校长本人能看见，然后我还想像着趁校长吃饭的空隙，上演5分钟演讲感动全世界的戏码。其实就在我点发送的一瞬间，多米诺效应就开始了。首先指出我的几个问题，我把事情想象的太简单了。 道德绑架我是出于一种目的来挑战校长的比赛，虽然说以公益的名义，但是糊里糊涂的校长就被我拉上船了，在与管理学校社交平台的学长的沟通上，也是这个问题阻碍了帮我转发。 我没写输了怎么办我只写了赢了，好，校长你施舍点我吧。但是我真想不出来，我输了能怎么办，我还卖身不成么？简直胡闹么，这样影响更不好。 这两点是最致命的。我是接到了辅导员的电话，才知道我的信已经被学校宣传部拦下来了，在老师中间已经传开了，但是校长在意大利调研，所以还没回国。辅导员对我说基于这个目的是好的，但是不保证能不能行。其实我知道基于那两个致命的缺陷，校长能有一百个理由拒绝。然后又出现了一个更要命的，更“政治化”的问题。那就是学校和公益组织之间的关系，他们想知道为什么做公益还要众筹（这是雷励的传统，因此也更有挑战，基金拿来项目地的建材费用等）。他们考虑到是不是行骗组织，因为前几年清华大学就出了一件乌龙事件，自称罗斯柴尔德家族的人来访，清华大学以最高的规格接待，结果发现是骗子。基于对学生的保护，也基于对学校名誉的保护，任何情况下，校长做决定都是谨慎的。因为即使现在没有组织的任何负面新闻，不代表将来没有，所以这一点，只要校长应战了，学校和组织之间就捆绑了。 但是想不到的是，校长答应了。听说还很爽快。 关于推动这个挑战中的问题这里面的问题更多的设计营销推广文案的问题。最主要的就是我没能很好的把那么大量的阅读者人引流到众筹平台。最重要的原因就是没有做好链接。其实我重写了公开信，但是转发的都是第一版的，所以那部分上千人的受众群体其实是流失了的。想想每个人捐我1元，任务也都完成了。后来我还特地的关于众筹的写了另一个版本的面向大学生的公开信，希望能引流一部分。我还增加了很多众筹回报。在微博平台上的长微博中发布中不是还有文字描述么，这里可以增加好几个链接，我一开始增加了好几个链接到众筹回报，会长告诉我说，不要，什么都不要，直入主题，就只放一个众筹平台的链接。后来想想这才是我推文的主要目的。这无疑的正确的。 大道至简，直奔主题，细节决定成败 备战其实之前我是不抱有任何希望的，对于这件事能不能行，但是后来接到记者的电话，再得到辅导员的证实，我心情异常的激动。连我最好的一个朋友原来也说亮瞎了的想法，变成惊呆了。也是。我要是变成那么忙的人，我也会避轻就重。纵观这件事情，最要紧的点就是校长金口开了，答应了，才有了故事的后续。我并不觉得我做了多么了不起的事，我没有想象中的很努力的去争取这个机会，整天堵在校长办公室门口或怎样，寻找一个能面对面交流然后获得机会这样一个场景。我只不是在电脑前打了几行字而已。但既然要比赛了，我就努力吧。我之前基本上游泳因为场地，时间问题就没怎么游了。但还是要练，时间也挺紧张的，我当时在转塘凤凰创意园学影视后期制作，最近的游泳场所，我要去定安游泳馆，来回要三个多小时，但还是在有限的时间去了几次，在那里我遇到美院游泳队的漂亮姐姐，然后我就上去请她们指导，还有一个很有经验的老头，也请他指导我的动作，基本上一些技术性的小细节事临时改过来的。直到比赛当天上午，我还去游了1000米，但是我始终没有测试过800米到底多少成绩，然后有多大的底气。这里非常感谢陪伴我的一个朋友，赖志鹏，帮我记录了练习跳水的镜头。 梦想还是要有的，万一实现了呢？-马云最重要的是，要时刻准备着 -me火花 跟外界沟通没有和记者朋友打过交道，但毕竟看过新闻，也知道一些舆论力量，所以在接到采访电话的时候，我几乎是不敢乱说话的，就怕好事被搅浑了，没见过大场面，hold不住这架势，没打过着交道，不知道里边是怎样的。一开始我还天真的什么都说，把自己知道的都说出来，但关键就在这，你不知道你自己知道的到底是不是真的，但媒体会信以为真。后来雷励CEO 陆丰老师还打电话过来，跟我聊了。之后我尽量只谈我自己的东西，关于组织的，学校的，我就告诉他们找官方。然后陆丰老师还要求我在记者发稿的时候要看一下最终稿有没有问题。 毕竟我还承担着两方的某些利益，小心驶得万年船。还好这一环节没出什么大问题。不知道怎么放链接，我就不把新闻整理出来了。 对所说的话负责。保证知道的都是权威的。 赛后这又是我没想到的一个点。涉世未深。不过在我看来，这应该不是什么大问题，只是这种现象已经根深在人们印象中了。就是我到底该不该赢。这个问题是马后炮。因为，我事先也不知道校长的实力，校长也不知道我的实力，大家更不知道，体军部的老师也不知道。我只是一股脑的想赢，这样挑战也名正言顺。但是后来某些人说你不应该赢，我就方了，我不会做错事了吧，想想也是，我算哪根葱，校长给你面子了，你不给校长面子？我没想到这个问题，但其实在我比赛环节之前有一个老师对学生的接力友谊赛，算是热身赛，然后有队员说，老师让我们游慢一点，故意输。但我没想到我身上。想想赛后一个记者过来和我握手说，我没想到你会赢。这是看不起我还是？不过后来校领导开过会讨论过了，党组织部的老师说这样的结果是最好的，青出于蓝而胜于蓝，而且学校游泳队取得了不俗的成绩，比不过老师说不过去。各位，你们想想，我是个年轻人，体力上本来就占有一定的优势，校长58岁，还能保持这样的竞技状态，这样的生活态度，这才是重点。况且我赢的不多，才十几秒，我一点都没放水，要不是途中多次咬牙坚持，我还很又可能输。就凭这一点，我真的很佩服我们校长。 不过我真是感受了一把受网络键盘侠攻击的滋味。 辅导员也说，这些人很多的啊，不要管。但我想想，很大的原因，还是因为信息的不对称，媒体没有很好的做好中介，把事情原本的样子展现出来。 但愿我不被规矩世俗束缚，追求本真 最后谢谢钱江晚报的一个朋友，帮我做的一个简短的视频，记录这美妙的时刻。]]></content>
      <categories>
        <category>life</category>
      </categories>
      <tags>
        <tag>life</tag>
        <tag>rock the boat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[编码总结]]></title>
    <url>%2F2016%2F10%2F04%2Fencoding%2F</url>
    <content type="text"><![CDATA[这篇很长！！！先看一下目录。 更新： python脚本文件的编码 添加vim编码的链接 问题的根源因为计算机是二进制的，为了能在计算机上显示字符，又因为是电脑是美国人发明的，他们定义了字符表（ascii码表），也就是字符和数字的对应，比如在ascii码表中65表示A，这样就有一对一的映射关系，字符就能用数字表示了，那样计算机也就算懂得“文字”了。而ascii码表是用到了0~127这样一个范围，0*** **** 7位二进制，但是电脑普及之后，其他国家也想在电脑上显示自己的文字，因为一个字节是8位么，有些可以把8位中的最高位利用起来，定义一些其他字符，然后兼容ascii码，但是有些国家像中国，8位是远远不够的，所以就有了像gbk,gb2312这样的自己定义的一组字符编码表。后来国际上统一制定了一个叫unicode的字符编码表，能够包含所有国家的文字 那unicode到底是什么？这里其实有好几个不同的概念 不要混淆概念 字符集(Abstract character repertoire) 编码字符集(Coded character set) 字符编码方式 (Character encoding form) 字符编码方案 (Character encoding scheme) 字符集第一层，可以看作是抽象层，我就是我们人类的视角，看到的我们的语言的文字集合 不同文字系统在记录信息上的能力是等价的。进一步讲，文字只是信息的载体，而非信息本身。不用文字，用其他的载体（数字）也可以存储同样意义的信息。吴军《数学之美》 编码字符集就是给抽象的字符编上数字，可以看作逻辑层。 如gb2312中的定义的字符，每个字符都有个整数和它对应。一个整数只对应-着一个字符。反过来，则不一定是这个说法有点模糊，反过来不一定是，是说在这个gb2312定义的字符中，一个字符能有多个整数对应，一个整数只对应一个字符的意思吗？一对多的关系？如果是这样，那没有意义啊，如果是因为在不同编码方式下，比如,这里只是假设打比方啊，在a编码表中，&quot;中&quot;对应52,在b编码中&quot;中&quot;对应77,这样说一个字符对应不同的整数还说的通，但是这样77在a中就能对应其他字符了，与一个整数只对应着一个字符在这个条件下也就矛盾了。所以我不知道这句话说的到底是什么意思 但只需要知道这里所说的映射关系，是数学意义上的映射关系，编码字符集是与计算机无关的,unicode就在这一层 字符编码方式记得组原里面的逻辑结构和存储结构的概念，这里的字符编码方式就对应着存储结构的这个概念，它是与计算机有关的 通俗的说，意思就是怎么样才能将字符所对应的整数的放进计算机内存，或文件、或网络中。于是，不同人有不同的实现方式，所谓的万码奔腾，就是指这个。gb2312，utf-8,utf-16,utf-32等都在这一层。 这里就有问题了，既然像unicode已经定义了文字对数字的对应了，那直接就那样存就行了？too young, too simple， 不是那么简单。要考虑到存储空间，提一下，因为会有很多零，考虑到这些，所以逻辑形式和存储形式会不一样。下面详解 字符编码方案 这个更加与计算机密切相关。具体是与操作系统密切相关。主要是解决大小字节序的问题。对于UTF-16和UTF-32编码，Unicode都支持big-endian 和 little-endian两种编码方案。一般来说，我们所说的编码，都在第三层完成（字符编码方式）。具体到一个软件系统中，则很复杂。浏览器－apache－tomcat（包括tomcat内部的jsp编码、编译，文件读取）－数据库之间，只要存在数据交互，就有可能发生编码不一致，如果在读取数据时，没有正确的decode和encode，出现乱码就是家常便饭了。 我理解就是这一层就是考虑大端还是小端存储，这是和不同计算机具体设计所不同的。 unicode刚说了unicode是在第二层，只是理论上的，什么叫只是理论上的，它是理想的，他定义了字符与一个数字的关系，仅仅而此。他没有定义编码在电脑中的具体存储形式。比如 中 对应是4E2D 0100 1110 0010 1101 它不就这样存着就好了么？ 不是这样的。看A 是41,0000 0000 0100 0001 如果都按照这样直接存着，有一个问题就是太浪费资源了，8位还好，16位的话，有那么多个0，存储空间都浪费了，而且传输的时候也浪费不必要的带宽，所以这是理论上编码和具体实现的差别。在实际存储到计算机上要考虑其他因素，正是有这些因素，导致了utf-8，utf-16,utf-32等，基于unicode的编码方式。 但有些编码不只是定义了影射关系，除了有字符集同时也包含了字符编码的含义，也就是这样定义的也是这样存的。如ASCII,GBK,GB2312等， unicode 只是定义了编码。没有定义怎么具体实现。 unicode 作为字符集(usc)是唯一的，编码方案(utf)才是有很多种。 也就是怎么存储，比如中，用的最多的是utf-8 utf-8 具体utf-8是怎么和unicode对应不是这里的讨论重点，终点是unicode和utf-8的关系，unicode是理想的，虚浮的，utf-8才是真实的显示的。unicode是一个code point，他还是需要被表示成一个一个binary,这就需要encode. In Unicode, a letter maps to something called a code point which is still just a theoretical concept. How that code point is represented in memory or on disk is a whole nuther story. 例子1234567891011&gt;&gt;&gt; import sys&gt;&gt;&gt; sys.stdin.encoding'UTF-8'&gt;&gt;&gt; c = '中文'&gt;&gt;&gt; c'\xe4\xb8\xad\xe6\x96\x87'&gt;&gt;&gt; cu = c.decode('utf-8')&gt;&gt;&gt; cuu'\u4e2d\u6587'&gt;&gt;&gt; cu.encode('gbk')'\xd6\xd0\xce\xc4' It does not make sense to have a string without knowing what encoding it uses. 这句话很重要。这里就先知道c这个字符串是由utf-8编码的。也就是计算机里面存的就是\xe4\xb8\xad\xe6\x96\x87对应的二进制。其实编码可以看作一个给unicode加密的过程,解码就是从字符串到unicode解密的过程。其实最终在计算机里只是一些010101010这样的数字，关键就是看你怎么看待它，怎么去翻译它的问题，翻译不正确就没有意义。 c 是由utf-8来编码的，解码之后unicode code point 是4e2d 6587, 代表&#39;中文&#39;，再对它进行gbk编码，它则变成了&#39;\xd6\xd0\xce\xc4&#39;, 所以字符集在不同编码方式下可能对应的实际存储形式是不一样的。 但反过来。给你一串这个数字 ， 不知道它的编码方式是毫无意义的。因为unicode定义了这个地球所有的字符和数字的映射关系，看作是一个“上层建筑”，一个蓝图，各个编码就是具体的施工，因为地形的原因，气候关系，各个国家根据这个蓝图都会有有些变动（这个例子不够好）。 同一个unicode在不同编码下肯定是不一样的,但是不同的unicode在不同的编码下有可能是一样的。这个很容易验证，只要随便找个字符字节，decode一下，只要能decode出来，这个字节符合编码的格式，然后还原出来的unicode就是在那个编码下对应的unicode但是两者是相同的字节。下面有一个例子，看下面。所以，像\xe9这种给出不一定就是utf-8编码方式，有些只是刚好符合编码格式，但是不一定有意义。 1234&gt;&gt;&gt; c.decode('ascii')Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; UnicodeDecodeError: 'ascii' codec can't decode byte 0xe4 in position 0: ordinal not in range(128) 因为c不是utf-8来编码的所以用ascii来“解密”这个逆过程是行不通的当得到了unicode又可以用不同的“加密方式”加密了。 python中的编码深入（python2）首先明确0x41和\x41的区别123456789&gt;&gt;&gt; 0x4165&gt;&gt;&gt; \x41 File "&lt;stdin&gt;", line 1 \x41 ^SyntaxError: unexpected character after line continuation character&gt;&gt;&gt; '\x41''A' 0x41是numeric ，\x41是 character，它只有在字符串中才有意义。 两者虽然在电脑中都是存着01000001,但是看待它的角度不一样。 str类和unicode类str和unicode是两个不同的类在python的REPL中，类似w = &#39;{whatever}&#39;，这样给出的，代表w是一个str， str hold bytes ! str hold bytes ! str hold bytes !str 存储的是已经编码后的字节序列，输出是看到每个字节用16进制表示，以\x开头，每个汉字会占用3个字节的长度。 str is string of bytesunicode is string of unicode character 1234567891011121314&gt;&gt;&gt; c='中文'&gt;&gt;&gt; c'\xe4\xb8\xad\xe6\x96\x87'&gt;&gt;&gt; cu=u'中文'&gt;&gt;&gt; cuu'\u4e2d\u6587'&gt;&gt;&gt; print c中文&gt;&gt;&gt; print cu中文&gt;&gt;&gt; len(c)6&gt;&gt;&gt; len(cu)2 cu=u&#39;中文&#39;表示cu的编码指定为unicode了。这个是python的内部编码。我现在有一个疑问，那这个cu在内存中保存的是什么样的？？？ [Todo] 一个以bytes 为单位，一个以unicode character 为单位 Unicode started out using 16-bit characters instead of 8-bit characters.!!! 我的理解是len(cu) == 2 表示cu里面有2个code pointlen（c) == 6 表示c有6个bytes 那这里就有两个问题了-[x] str存储已经编码后的字节序列，是用什么编码？？从键盘上按下到屏幕上显示的这一步我们先不管，我猜想是涉及到键盘的工作原理Todo和输入法的原理[Todo],改天再把这一块补上，现在先就关注再python内部的编码。123import sys&gt;&gt;&gt; sys.stdin.encoding'UTF-8' 是默认用sys.stdin.encoding来编码输入的字符。 说到这里，python中有好几个有关编码的函数或值 sys.stdin.encoding sys.stdout.encoding sys.getdefaultencoding() sys.getfilesystemencoding() 各自的用处都不一样 -[] w＝&#39;中文&#39; 是需要编码一下的 用utf-8那这样 w = &#39;\xe9&#39;也要先utf-8编码？这个我还不清楚，因为不可能一个不编码，一个编码，应该是统一的形式，但是对\xe9进行utf-8的编码是不行的因为对于但字节的，utf-8是高位是0开头的，所以这个不可能用utf-8编码成功，所以我猜测是因为\x,有这个，直接以字节码的形式传入进来了不用编码了。 print当做print c的时候，会把c的byte string， 也就是字节流传到终端，终端接受到这一组字节流要用终端的编码来解码这个字节流（毕竟不是字符集，传送过来的只是编码方式，所以找字符对应关系还得还原），这样就又回到了unicode的形式，然后接下来就是字符怎么显示到计算机屏幕上的问题了 实验12345&gt;&gt;&gt; c = '中文'&gt;&gt;&gt; c.decode('utf-8')u'\u4e2d\u6587'&gt;&gt;&gt; c.decode('utf-8').encode('gb2312')'\xd6\xd0\xce\xc4' 我在iTerm下先把Terminal的Character Encoding改为GB 2312可以看到结果是被正确打印出来但当我把编码随便改成另外国家的然后再打印的时候就不对了但是！ cg里面保存是一样的 这也就是说当你终端的编码和在python中处理字符的编码不一致的时候，打印结果可能出现问题。之所以是可能，因为如果都是英文的话，因为都兼容ascii码,所以会打印出你想要看到的样子。 12345&gt;&gt;&gt; cg = '\xd6\xd0\xce\xc4'&gt;&gt;&gt; cg.decode('iso 8859-11')u'\u0e36\u0e30\u0e2e\u0e24'&gt;&gt;&gt; cg.decode('gb2312')u'\u4e2d\u6587' 这里就是不同unicode在不同的编码下有着相同的字节的例子然后1234&gt;&gt;&gt; cg.decode('iso 2022-jp')Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; UnicodeDecodeError: 'iso2022_jp' codec can't decode byte 0xd6 in position 0: illegal multibyte sequence 上面那个能对iso 8859-11解码也只是凑巧，这个对iso 2022-jp就不行。 实验2如果是print一个unicode对象的话12345&gt;&gt;&gt; cgt = cg.decode('iso 8859-11')&gt;&gt;&gt; print cgtTraceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; UnicodeEncodeError: 'ascii' codec can't encode characters in position 0-3: ordinal not in range(128) 看着样子好像是要转化成字节流传送到终端再解码。那这样不会出现什么问题么？因为unicode的code point和字符之间是一一对应的，我编码成utf-8也好，gbk也好，其他什么的也好，只要能编成，我只是用它做个过度，我只需确保解码的时候用的是一致的编码的就行了，现在这里的问题就是ascii码不能编成，因为格式不支持。这个ascii应该是sys.getdefaultencoding()的。以下终端编码是utf-812345&gt;&gt;&gt; cgt = cg.decode('iso 8859-11')&gt;&gt;&gt; cgt.encode('utf-8')'\xe0\xb8\xb6\xe0\xb8\xb0\xe0\xb8\xae\xe0\xb8\xa4'&gt;&gt;&gt; print '\xe0\xb8\xb6\xe0\xb8\xb0\xe0\xb8\xae\xe0\xb8\xa4'ะฮฤ 这个显示的不知道是不是一致的，看着又像又不像，少了一个点貌似，到底对不对？？ 读取文件读文件，文件的编码现在我先建立一个gbk.txt的文件，在vim中:set fileencoding=gbk,有关vim中的编码看这里输入内容我叫陈烨保存。先看一下utf-8的编码长什么样，gbk编码长什么样12345&gt;&gt;&gt; c = '我叫陈烨'&gt;&gt;&gt; c'\xe6\x88\x91\xe5\x8f\xab\xe9\x99\x88\xe7\x83\xa8'&gt;&gt;&gt; c.decode('utf-8').encode('gbk')'\xce\xd2\xbd\xd0\xb3\xc2\xec\xc7' 然后读取文件1234&gt;&gt;&gt; f = open('gbk.txt')&gt;&gt;&gt; fr = f.read()&gt;&gt;&gt; fr'\xce\xd2\xbd\xd0\xb3\xc2\xec\xc7\n' 可以看出，我保存的是gbk编码格式，现在读入的也是gbk编码的格式，因为计算机他操作的就在“第三层”（这里先忽略第四层）所以，如果我不知道原来文件的编码是什么，直接操作文件内容也是没有意义的，只是现在大部分都是utf-8，一切都恰好行的通，等出现乱码的时候就应该知道是编码出现问题了。 读文件，文件内容的操作现在我建立一个文件叫做wr.TARIN , 这是里面的内容是你好 中国 Hello China 1 2 31234567&gt;&gt;&gt; import sys&gt;&gt;&gt; sys.getfilesystemencoding()'utf-8'&gt;&gt;&gt; f = open('wr.TRAIN')&gt;&gt;&gt; content=f.readline()&gt;&gt;&gt; content'\xe4\xbd\xa0\xe5\xa5\xbd \xe4\xb8\xad\xe5\x9b\xbd Hello China 1 2 3\n' 这个sys.getfilesystemencoding()是不是用来文件解码的还不清楚！！！【Todo】文件都是以字节流的方式读进来的？ 但不管怎么样，读进来的是一段字符串，重点是你怎么看，都是这样的01010的数字，关键在于怎么翻译，所以要知道它文件原来的编码方式。123456789&gt;&gt;&gt; content_list = content.split()&gt;&gt;&gt; content_list['\xe4\xbd\xa0\xe5\xa5\xbd', '\xe4\xb8\xad\xe5\x9b\xbd', 'Hello', 'China', '1', '2', '3']&gt;&gt;&gt; print content你好 中国 Hello China 1 2 3&gt;&gt;&gt; print content_list['\xe4\xbd\xa0\xe5\xa5\xbd', '\xe4\xb8\xad\xe5\x9b\xbd', 'Hello', 'China', '1', '2', '3']&gt;&gt;&gt; print content_list[0]你好 那这里就有一个问题，为什么print content_list显示的是以这样的形式，而不是[&#39;你好&#39;,&#39;中国&#39;,&#39;Hello&#39;,&#39;China&#39;,&#39;1&#39;,&#39;2&#39;,&#39;3&#39;]这样子？这其实是两个问题。content_list是list类型，它不是一个str！！！123456789&gt;&gt;&gt; l = ['中文','你好']&gt;&gt;&gt; l['\xe4\xb8\xad\xe6\x96\x87', '\xe4\xbd\xa0\xe5\xa5\xbd']&gt;&gt;&gt; print l['\xe4\xb8\xad\xe6\x96\x87', '\xe4\xbd\xa0\xe5\xa5\xbd']&gt;&gt;&gt; print str(l)['\xe4\xb8\xad\xe6\x96\x87', '\xe4\xbd\xa0\xe5\xa5\xbd']&gt;&gt;&gt; str(l)"['\\xe4\\xb8\\xad\\xe6\\x96\\x87', '\\xe4\\xbd\\xa0\\xe5\\xa5\\xbd']" 在打印list类型的时候，会先把list转为str，这样就发现\x编程了\\x，相当于\xe4原本表示编码的，被当成字符串处理了，说了一切看你怎么看的问题。但其实本来是list转为字符串格式的话，会调用repr来转化，但是效果是和str是一样的。12&gt;&gt;&gt; repr(l)"['\\xe4\\xb8\\xad\\xe6\\x96\\x87', '\\xe4\\xbd\\xa0\\xe5\\xa5\\xbd']" 12345&gt;&gt;&gt; lc = ','.join(l)&gt;&gt;&gt; print lc中文,你好&gt;&gt;&gt; lc'\xe4\xb8\xad\xe6\x96\x87,\xe4\xbd\xa0\xe5\xa5\xbd' 但是如果想要有[...]的效果怎么办12&gt;&gt;&gt; print str(l).decode('string_escape')['中文', '世界'] string_escape是转义字符123456&gt;&gt;&gt; repr(l)"['\\xe4\\xb8\\xad\\xe6\\x96\\x87', '\\xe4\\xbd\\xa0\\xe5\\xa5\\xbd']"&gt;&gt;&gt; repr(l).decode('string_escape')"['\xe4\xb8\xad\xe6\x96\x87', '\xe4\xbd\xa0\xe5\xa5\xbd']"&gt;&gt;&gt; print "['\xe4\xb8\xad\xe6\x96\x87', '\xe4\xbd\xa0\xe5\xa5\xbd']"['中文', '你好'] 也就是相当于把\\x还原回\x了的一步操作。如果已经是\x再这样弄，没什么效果。 写入文件12345&gt;&gt;&gt; ','.join(content_list)'\xe4\xbd\xa0\xe5\xa5\xbd,\xe4\xb8\xad\xe5\x9b\xbd,Hello,China,1,2,3'&gt;&gt;&gt; fw = open('out.TEST','w')&gt;&gt;&gt; fw.write(','.join(content_list))&gt;&gt;&gt; fw.close() 还可以用unicode统一来处理文本，不过在写入文件时，还是要转换为“第三层”的格式，毕竟unicode是虚浮的！！！12345678910&gt;&gt;&gt; fw=open('out.TEST','w')&gt;&gt;&gt; content_u_list_conjunction = ','.join(content_u_list)&gt;&gt;&gt; content_u_list_conjunctionu'\u4f60\u597d,\u4e2d\u56fd,Hello,China,1,2,3'&gt;&gt;&gt; fw.write(content_u_list_conjunction)Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;UnicodeEncodeError: 'ascii' codec cant encode characters in position 0-1: ordinal not in range(128)&gt;&gt;&gt; fw.write(content_u_list_conjunction.encode('utf-8')) #要指定encode编码，不然用默认的&gt;&gt;&gt; fw.close() 这个默认的应该就是sys.getdefaultencoding()指定的吧。 python 脚本文件的编码经常可以看到一些.py文件的头两行是怎么写的1234#!/usr/bin/env/python# coding=utf-8# 或# -*- coding: utf-8 -*- If a comment in the first or second line of the Python script matches the regular expression coding[=:]\s*([-\w.]+), this comment is processed as an encoding declaration; the first group of this expression names the encoding of the source code file. The encoding declaration must appear on a line of its own. If it is the second line, the first line must also be a comment-only line. The recommended forms of an encoding expression are # -*- coding: &lt;encoding-name&gt; -*-from Encoding declarations Python will default to ASCII as standard encoding if no other encoding hints are given.from PEP 263 – Defining Python Source Code Encodings 如果没有指定，脚本默认会用ascii码来解析文件内容，这时如果遇到有中文的，那就会报错 还有一些example 参考资料 The Absolute Minimum Every Software Developer Absolutely, Positively Must Know About Unicode and Character Sets (No Excuses!) python新手必碰到的问题—encode与decode，中文乱码 字符编码详解 Unicode HOWTO Meaning of 0x and \x in python hex strings? unicode-table Why does Python print unicode characters when the default encoding is ASCII? len() with unicode strings Python, len and slices on unicode strings len(unicode string) Python 2.7 解决写入文件的中文乱码问题 python write file dealing with encode Pragmatic Unicode Python编程的中文问题 Python2字符编码问题小结 1,2,4,7,13,14 推荐要看一下 一些重要的摘出来4 The Unicode standard describes how characters are represented by code points. A code point is an integer value, usually denoted in base 16. In the standard, a code point is written using the notation U+12ca to mean the character with value 0x12ca (4810 decimal). The Unicode standard contains a lot of tables listing characters and their corresponding code points:123456&gt; 0061 &apos;a&apos;; LATIN SMALL LETTER A&gt; 0062 &apos;b&apos;; LATIN SMALL LETTER B&gt; 0063 &apos;c&apos;; LATIN SMALL LETTER C&gt; ...&gt; 007B &apos;&#123;&apos;; LEFT CURLY BRACKET&gt; Strictly, these definitions imply that it’s meaningless to say ‘this is character U+12ca’. U+12ca is a code point, which represents some particular character; in this case, it represents the character ‘ETHIOPIC SYLLABLE WI’. In informal contexts, this distinction between code points and characters will sometimes be forgotten. A character is represented on a screen or on paper by a set of graphical elements that’s called a glyph. The glyph for an uppercase A, for example, is two diagonal strokes and a horizontal stroke, though the exact details will depend on the font being used. Most Python code doesn’t need to worry about glyphs; figuring out the correct glyph to display is generally the job of a GUI toolkit or a terminal’s font renderer. a Unicode string is a sequence of code points, which are numbers from 0 to 0x10ffff. This sequence needs to be represented as a set of bytes (meaning, values from 0-255) in memory. The rules for translating a Unicode string into a sequence of bytes are called an encoding. 12There are many encodings and they define 128-255 differently. For example, character 185 (0xB9) is ą in windows-1250 encoding, but it is š in iso-8859-2 encoding.So, what happens if you print \xb9? It depends on the encoding used in the console. In my case (my console uses cp852 encoding) it is:123&gt; &gt;&gt;&gt; print '\xb9'&gt; ╣&gt; Because of that ambiguity, string ‘\xb9’ will never be represented as ‘╣’ (nor ‘ą’…). That would hide the true value. (这里解释了为什么用\xb9这样字节来保存，而不打印出来实际的字符)It will be represented as the numeric value:123456&gt; &gt;&gt;&gt; '\xb9'&gt; '\xb9'&gt; #Also:&gt; &gt;&gt;&gt; '╣'&gt; '\xb9'&gt; But what happens if variable is just entered in the console?When a variable is enteren in cosole without print, its representation is printed. It is the same as the following:123&gt; &gt;&gt;&gt; print repr(content)&gt; '\xe4\xbd\xa0\xe5\xa5\xbd \xe4\xb8\xad\xe5\x9b\xbd Hello China 1 2 3\n'&gt; Unlike str objects, which are strings of bytes, unicode objects are strings of unicode characterscharacters != bytes. a utf16 character is 2 bytes, but only one character 14 内置的open()方法打开文件时，read()读取的是str，读取后需要使用正确的编码格式进行decode()。write()写入时，如果参数是unicode，则需要使用你希望写入的编码进行encode()，如果是其他编码格式的str，则需要先用该str的编码进行decode()，转成unicode后再使用写入的编码进行encode()。如果直接将unicode作为参数传入write()方法，Python将先使用源代码文件声明的字符编码进行编码然后写入。]]></content>
      <categories>
        <category>砍树人</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>encode</tag>
        <tag>unicode</tag>
        <tag>utf-8</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[project of stackoverflow - python piece (一)]]></title>
    <url>%2F2016%2F02%2F12%2Fstackoverflow-python-piece-1%2F</url>
    <content type="text"><![CDATA[Why does Python print unicode characters when the default encoding is ASCII? 在python 2.6的交互式界面中：123456&gt;&gt;&gt; import sys&gt;&gt;&gt; print sys.getdefaultencoding()ascii&gt;&gt;&gt; print u'\xe9'é&gt;&gt;&gt; 我原本预想打印出来的结果是乱码或者直接报错，因为字符 “é” 并不是ASCII码所定义的范围，而且我没有指定编码。我想我是不是没有懂这个ASCII码作为默认编码的真正意思。 73票的回答： 谢谢不同回复的各方面的回答，我觉得我们可以连起来成一个解释当尝试着去打印unicode字符串的时候，u&#39;\xe9&#39;，Python会隐式的先尝试去对这个字符串用sys.stdout.encoding返回的编码方案编码。实际上，python在一开始初始化的时候就记录了这个设置。如果不能在环境中找到合适的编码，才会使用默认的ASCII码编码。 比如，我使用一个默认编码是UTF-8的bash shell。当我在它上启动python，它会使用这个设置：12345$ python&gt;&gt;&gt; import sys&gt;&gt;&gt; print sys.stdout.encodingUTF-8 让我们先暂时退出python shell然后重新用一些伪造的编码设置bash的环境12$ export LC_CTYPE=klingon# we should get some error message here, just ignore it. 然后重新启动python shell，证实一下他确实恢复到它默认的acsii编码12345$ python&gt;&gt;&gt; import sys&gt;&gt;&gt; print sys.stdout.encodingANSI_X3.4-1968 那就对了！ 如果现在你要打印一些在ascii码定义之外的unicode字符，你就会得到漂亮的错误提示123&gt;&gt;&gt; print u'\xe9'UnicodeEncodeError: 'ascii' codec can't encode character u'\xe9' in position 0: ordinal not in range(128) 让我们退出python，不要管bash shell 我们现在在python输出字符后观察会发生什么。为了能够观察，我们需要在图形界面的终端启动bash shell(我使用的是Gnome Terminal)然后我们设置终端的输出编码为ISO-8859-1 aka latin-1(图形界面的终端通常在下拉菜单里面都有可以设置字符编码的选项)注意，这个不会改变shell 真正的环境编码。他只改变终端自己对于给出输出的解码方式，有点像浏览器的行为。因此你可以改变终端的编码，那是和shell环境的编码是相互独立的。然后启动从shell中启动python，核实一下sys.stdout.encodin是被设置成shell的环境编码(我的是UTF-8)： (我：插一句，bash shell的环境编码是由LC_CTYPE决定的。然后终端改为latin-1的编码，应该先在编码正常utf-8的时候先启动，然后再改编码，否则，至少我尝试下来如果一开始用latin-1编码启动终端，注意是启动终端，sys.stdou.encoding是ascii) 1234567891011121314$ python&gt;&gt;&gt; import sys&gt;&gt;&gt; print sys.stdout.encodingUTF-8&gt;&gt;&gt; print '\xe9' # (1)é&gt;&gt;&gt; print u'\xe9' # (2)Ã©&gt;&gt;&gt; print u'\xe9'.encode('latin-1') # (3)é&gt;&gt;&gt; (1) python 如实的输出二进制字节字符串，然后终端接受到这个，然后尝试着去用latin-1的字符映射来匹配它的值。在latin-1，0xe9或者233对应字符&quot;é&quot;,这也是终端的显示 (2) 不管当前设置在sys.stdou.encoding的编码方案是什么，python先隐式的用这个来编码unicode，在这个例子中是UTF-8。在UTF-8编码完了后,编成了一串二进制字符串\xc3\xa9（后面会解释）。终端接受到这个字节流后然后尝试着去用latin-1去解码0xc3a9，但是latin-1的范围是0到255，所以会一个字节一个字节的解码，0xc3a9是2个字节长，因此latin-1的解码器会解释成0xc3(195)和0xa9(169),这两个对应的字符分别是Ã和©. (3) python 会用latin-1的编码方案来编码unicode的code point u&#39;\x9&#39;(233)。事实是latin-1的code point的范围是0-255,然后刚好好unicode字符指向在那个范围内（Turns out latin-1 code points range is 0-255 and points to the exact same character as Unicode within that range. ）。因此，在那个范围内的unicode code point 用latin-1编码会产生相同的值。所以u&#39;\xe9&#39;(233)在用latin-1编码后，会产生二进制字符串\xe9。终端接受这个值后，尝试这种latin-1的字符映射来匹配这个值，就像第（1）中情况一样，它对应&quot;é&quot;，在屏幕上也是这么显示的。 (我：在二进制的时候，是直接去找对应关系，不用用这个编码去解码到unicode再去找对应，我理解错了。更新：应该是，如果是隐式的编码成二进制字节流传到终端，终端会再解码。像第二种情况。) 现在我们在下拉菜单下面将终端的编码设置为UTF-8（就像你改变浏览器编码一样）。不需要中断python或重启shell。现在终端的编码和python的一致了，我们来重新尝试打印：1234567&gt;&gt;&gt; print '\xe9' # (4)&gt;&gt;&gt; print u'\xe9' # (5)é&gt;&gt;&gt; print u'\xe9'.encode('latin-1') # (6)&gt;&gt;&gt; (4) python 输出这个二进制字符串。终端尝试用UTF-8来解码这个流。但是UTF-8并不能合法的解码0xe9(稍后解释），所以它不能被转化成unicode的code point.没有找到code point，那就没有字符串打印出来。 (5) python尝试隐式的用sys.stdou.encoding中的方案来编码unicode字符串，这里还是”UTF-8”.二进制结果是\xc3\xa9。终端接收到字节流然后尝试着用UTF-8去解码，然后产生回值为0xe9(233)，这个在unicode字符映射里面对应的符号是”é”,所以终端显示“é”。 (6) python用latin-1 来编码unicode字符串，他产生了相同值的二进制字符串\xe9。同样的，对于终端而言，这和第4种情况差不多。 结论：python将不是unicode字符串的按照原始数据输出，而且并不考虑它默认编码。如果终端恰好能够显示他们只是因为当前的编码方案刚好能匹配数据。python 用sys.stdout.encoding的编码方案来编码unicode字符串然后输出，这个方案设置是来自shell的环境。那终端是根据自己的编码设置来显示输出。终端的编码和shell的是互相独立的。 (我：那意思是 输入 -&gt; 终端 -&gt; python -&gt; 终端 -&gt; 输出, 因为终端是上层么，用户接触的是终端，然后python内部处理。python输出的分unicode,和non-unicode，它输出的对象是终端。）]]></content>
      <categories>
        <category>stackoverflow</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>python-piece</tag>
        <tag>stackoverflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[how character display on screen]]></title>
    <url>%2F2015%2F11%2F12%2Fhow-character-display-on-screen%2F</url>
    <content type="text"><![CDATA[我知道ascii码2c 是“，”逗号，但是计算机是怎么知道它是“逗号”的？ 简答：有时候不是会安装字体font么，里面就有对应的字型。要显卡渲染形成的。大体过程是：字符编码（Unicode）→字体的形索引（Glyph ID）→字形轮廓→点阵图字形 计算机是如何显示文字的呢？计算机要对文字进行存储后就需要显示出来，而我们的液晶屏都是一个个的像素点组成的，这就必须要对文字进行渲染绘制，发送到显卡中进行栅格化和显示等操作。Dos下最简单，利用主板BIOS就能对ascii码进行点阵化输出。 字符显示器，显示字符的方法以点阵为基础，点阵是指由m*n个点组成的阵列，点阵的多少取决于显示字符的质量和字符窗口的大小。 字符窗口是指每个字符在屏幕是那个所占的点数。它包括字符显示点阵和字符间隔。 将点阵存入由rom构成的字符发生其中，在CRT进行光栅扫描的过程中，从字符发生器中一次读出某个字符的点阵，按照点阵中0和1的代码不同控制电子束的开或关，从而在屏幕上显示出字符，对应每个字符窗口，所需显示字符的ACSII代码被存放在视频存储器VRAM中，以备刷新 参考 假如说这个程序是 xterm ，它会通过 X core font API ，将这个字符直接送给 Xorg ，由 Xorg 来完成字体渲染（当然现在 xterm 也支持 libXft 了，不过先不管这个）。Xorg 拿到应用程序送来的请求之后，会在字体中检索每个字对应的字形，然后渲染出来。这个检索过程中用到的索引，就是我们之前给字符编上的号。如果要指定字体，需要向Xorg提供一个长得像这样：“-adobe-times-medium-r-normal–12-120-75-75-p-64-iso8859-1” 的字符串来指定字体。 作者：乌鸦链接：https://www.zhihu.com/question/24340504/answer/28902204来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 在UNIX终端上和DOS里 ， 字符是终端或显卡（使用内置字库）绘制的，不但跟unicode和freetype什么的没有任何关系，而且跟操作系统都没有关系。打印机也是如此：当你把一个文本文件直接发送给打印机，打印机使用内置的字库绘制每个文字和符号著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。作者：姜维链接：http://www.zhihu.com/question/24340504/answer/27969692来源：知乎 介绍到这里，大家应该对整个字体的绘制过程有个整体的认识了，首先是经过字符编解码，将硬盘中存储的有对应编码的文本文件进行加载，例如Java的文件IO，变成内存中的字符串对象，也就是符合本语言字符串存储特性的数据，（当然如果你愿意，也可以当做二进制读入，然后再手段转换编码，也是可以的），绘制时则首先调用对应的CodePage进行编码的索引查找，找到对应的字体字形索引，然后根据字形索引获取到字库中的数据，根据系统提供的绘制曲线绘制样条线的方法进行图形渲染，这样就能得到显示器上的图像了。而更高级的就是对字体进行反走样，锐化，等更为细节的操作了。著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。作者：孙笑凡链接：http://www.zhihu.com/question/24340504/answer/29927340来源：知乎]]></content>
      <categories>
        <category>砍树人</category>
      </categories>
      <tags>
        <tag>unicode</tag>
        <tag>glyph</tag>
        <tag>computer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用c画函数]]></title>
    <url>%2F2015%2F06%2F02%2Fc-draw-cos%2F</url>
    <content type="text"><![CDATA[打印cos函数c的控制台程序打印是逐行打印。所以每一行都要一次性计算出所有的位置。其实就是找规律主要就是两个循环，一个是纵轴的，一个是横轴的，纵轴方向控制行，横轴方向控制打印cos这个函数是对称的.周期是0~2pi,pi是3.1415，所以横轴方向的长度是2pi，也就是6.28，纵轴方向可以通过一个for循环从1到-1,通过acos反三角函数计算出横轴。为了显示方便可以放大倍数因为是对称，每行两个*的横坐标是关于pi对称的。 1234567891011void draw_cos()&#123; double y; int m,x; for(y=1;y&gt;=-1;y-=0.1)&#123; x = acos(y)*10; //这里和下面的62-x的62是对应的。放大的倍数 for(m = 1;m&lt;x;m++) printf(" "); printf("*"); for(;m&lt;62-x;m++) printf(" "); //其实62表示的就是总的宽度 printf("*\n"); &#125;&#125; 如果放大了20倍，而宽度还是62的话。1x = acos(y) * 20 可以看到，当x计算出来的超过了31（对称线）的时候，因为m这个循环变量也已经超过31，m &lt; 62 - x这个控制语句已经不起作用了，所以就不正确了。当要放大20倍的时候，宽度也要相应的放大2倍。 打印的两种思路for(坐标) 由坐标来控制也就是先计算出这一行要打印的坐标，然后控制循环，到你这之前要打印什么，到你这之后要打印什么。上面打印cos的就是 for(范围) 在范围里面询问这个范围是定义域，在定义域里面循环，到这了，比较一下这个地方是不是要打印的哪个坐标点，如果是，打印哪个，如果不是做哪些事。 同时打印cos和sin12345678910111213141516171819202122232425262728void draw_cos_sin()&#123; double y; int m,n,x; //这里将m,x声明为int类型很重要，因为，如果不是int类型，是double类型，可能图像是打印的不完整的 //因为，接下来涉及到比较，== 符号，double型的话，因为acos，这种都是无理数，如果要完全相等，基本上不可能。 //申明为int类型，这样从0开始遍历到62，就能保证我能“卡”住。 for(y=1;y&gt;=-1;y-=.1)&#123; m=acos(y)*10; //acos值域（0～pi／2） n=asin(y)*10; //asin值域（-pi／2～pi／2） for(x=0;x&lt;=62;x++)&#123; if(x==m) printf("*"); else if(x==62-m) printf("*"); //上面是打印COS的 else if(x==n) printf("+"); else if(x == 31-n) printf("+"); //else if(x == 62-n) printf("+"); //else if(x == 31+n) printf("+"); //本来以为要计算四段，但是错误，因为asin的值域是(-PI/2~PI/2)，然后 //y从0遍历到-1的时候，按照上面的规则是错的，上面的规则默认是从0~PI/2那段的 //sin衍生计算出来的。 else if(x == n+62) printf("+");//周期性 //上面是打印SIN的 //因为优先打印cos所以重叠的部分是打印出cos的*状 else printf(" "); &#125; printf("\n"); &#125;&#125; acos的值域是(0,pi/2)asin的值域是(-pi/2,pi/2) 注释里面也说明了，怎么计算出sin(x)的坐标点，这里要注意的就是，因为y从1往-1算，都在acos和asin的定义域里面，所以它的值域范围都会覆盖到，从图像上看 cos是计算出来x=pi这条直线的左半边，然后根据对称可以直接算出右半边，这是可以的， 因为这样覆盖了cos的我们要打印的定义域(0,2pi),也没有浪费acos的值域(0,pi/2).这里很关键！！！ 我一开始考虑sin的时候，我只利用sin图像的(0,pi/2)部分，先是关于x=pi/2对称，然后在关于点(pi,0)对称，将(pi/2,2pi)部分分三个部分来计算了。(关于对点对称的计算，其实就是两点连起来中间点是这个对称点，也就是(x1+x2)/2=x,y类同) 但是，没把当y计算到0~-1的时候，asin就是(-pi/2,0),图像上看就是y轴的左边部分，考虑进去。因为这样安装上面的规则，当y计算到0~-1的时候，先关于x=pi/2对称的时候，这部分是可以计算出(pi,3pi/2)部分的，但是用y轴左边部分的来用关于点(pi,0)对称规则计算出来的，就不是sin的(3pi/2,2pi)部分， 因为asin的范围是(-pi/2,pi/2),也就是sin图中的(-pi/2,pi/2)的那部分，这部分按照关于x=pi/2线对称是可以算出(pi/2,3pi/2)部分的，然后剩下(3pi/2,2pi)可以按照周期性，加上一个周期，这时候问了，那y在1～0这部分周期也要算？对，但没关系啊，因为for循环规定了x的范围是（0，62）, y在1～0这部分算出的超过了这个范围，所以“询问”不到，这个词要体会。 总结这个打印其实就是y=#横线，从上往下横下去，然后碰到曲线有交点了，记录下这个坐标。有条性质很重要，函数的性质，一个x只能对应一个y，但一个y可能有多个x`，也就是竖线，左右平移的话，都只有一个交点，但横线上下平移，可能会有好多个交点。这时候要注意定义域，值域，然后根据一些规则，计算出所有的交点。]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>C-practice</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【转】如何从菜鸟程序员成长为高手]]></title>
    <url>%2F2015%2F04%2F07%2Frookie-to-master%2F</url>
    <content type="text"><![CDATA[原文链接 下面这篇优秀的文章来自Axb的自我修养，写得很直白、很真实，很有营养，分享在这里与君共勉！口头禅 这其实是两个问题 （不要混淆概念）还有没有更好的方案 （不要思维局限）能不能举个例子 （理论实际相结合）能不能给个一句话总结 （说明自己掌握了重点） 摘要最近有一些毕业不久的同事问我：“你工作的时候有没有什么窍门？怎么才能快速成为高手？” 想起当初刚入职，新人培训的时候，也跟其他同事讨论过这个问题：如何才能成为业界大牛？当时自己只是觉得兴趣是最好的老师，思路方法什么的没有多想。 加入微博平台架构部的时间也不短了，趁着快过春节总结了一下自己入职微博以来的工作情况，从互联网开发的半个门外汉，到如今能设计一些架构、排查一些问题、分享一些经验，收获颇多，感想颇多,也逐渐意识到思路和方法的重要性，在此跟大家分享一下。主要分为学、做、想三方面。 学会学习学习无疑是程序员最为重要的素质之一，尤其是互联网这种日新月异的行业，把学习当做工作的一大半也不为过。 自主学习最近发现身边的人并不是不想学习，只是每天都在纠结自己到底学什么好：简单的没挑战，复杂的看不懂；旧技术怕过时，新技术没方向…… 讲讲自己毕业后的经历，毕业之后去了个不大不小的公司，工作主要是做一些XX管理系统之类的东西，没什么挑战，也用不上什么技术，基本上前端用个extjs后面套个sql server就解决了。工作稳定了几年，业余时间除了wow没别的事情做，觉得这么闲下去不是办法，于是之后一年的时间里，用上班摸鱼和下班休息的时间学了这些东西： 闲着无聊想做个小游戏，发现游戏相关的书大多是英文的，看不懂，一咬牙翻译了《Real-time rending 3rd》的前几章，刚开始前言都看不懂，只能一个词一个词的翻字典，一句话要琢磨几个钟头到底作者说的到底是什么意思。翻译了几百页英文书之后，发现自己看英文书没什么障碍了，于是开始每天用休息和摸鱼的时间看书。 看完游戏引擎的书之后，把irrlicht引擎的代码看了一遍，然后自己山寨了一个3d渲染的场景管理器，还有个朴素的渲染引擎。 给自己的游戏引擎写了个基于脚本语言的解释器，为此看了不少编译原理和虚拟机的书，了解了程序究竟是什么东西，这是我觉得收益很大的一件事情。 看编译原理的书的时候发现操作系统的知识有些欠缺，又去看了linux内核相关的书。之后买了个开发板天天修改内核玩，毕业以后又一次了解了内核的cpu调度、内存管理和文件系统，了解了应用是怎么跑在操作系统上，操作系统又是怎么运行在硬件上的，这也是收益很大的一件事情。 看完操作系统又顺着看网络相关的书，之后把lighthttpd的代码看了一遍，用c写了个linux下的http服务器，把几种网络编程模型挨个实现了一遍。 实现http服务器的过程中觉得自己编码能力还是有欠缺，把代码大全翻了一遍，顺着又去看了设计模式的书，并且用自己的理解把每个模式用文字重新描述了一遍。 中间还看了很多语言和框架相关的书，就不一一列举了。 我把学习的方向分为三类： 为了工作，满足当前工作所必备的知识 为了提升，与当前工作相关的知识（深度） 拓展视野，与当前工作无关的知识（广度） 学习（1）之后只是个熟练工，2和3才是提升自己的途径，伴随着知识储备的提升，接触新事物时更容易找到相似的知识加以类比，加快理解，也更容易掌握本质。如果每天都在纠结“到底学什么”，那么只能说明还是学的太少了。（真正没什么可学的大牛们应该不会读到这里吧……） 所以，如果觉着没什么东西可以学的时候，那么可以考虑一下学一下更有深度的知识（比如虚拟机或编译器），或者完全不同的知识（新的语言或当前比较火的方向），甚至完全不相干的知识（单纯练习英文阅读，学习ppt排版之类）吧。随着知识储备增加，自己的不足和未来的学习的方向也会更加明确起来。 向历史学习以微博为例，在微博发展的过程中经历了不少波折，并逐渐衍生出了目前的系统架构。很多新人最喜欢问的问题便是“现在线上是怎么做的？” 这个问题不错，但是还不够好。在程序员的世界里罕有能解决所有问题的“银弹”，当前的做法用不了多久也会被替换掉，如果想了解一件事情，那么就多关注一下“它是怎么变成今天这样的”吧。学会用发展的眼光看问题，了解一些经历过的经验教训，收获会比单纯学会一件什么事情多的多。 那么，如何向历史学习？ 公司内部的资料库、wiki等大都会有旧时的资料，刚入职时大多不会太忙，这些资料库简直是挖不完的宝藏 部门内部分享，比如我当初入职时经常去听“微博XXXX架构演化历程”之类的内部分享 多问一下自己”它为什么不那么设计 老员工忆苦思甜吹牛逼的时候多奉承几句 向他人学习这里有两个极端， 有的人喜欢自己闷头捣鼓，什么也不问，这必然是不利于自己提高的； 也有人碰到问题就问，这也有问题，浪费他人时间不说，更关键的是说明这人向他人学习的思路错了，要学习他人的并不是具体某个知识（要学知识看书就能解决了），而是学习别人的思维方式。 但是思维方式这种东西很难通过交流的方式学到，后来我发现有个很简单的学习方式：口头禅。举几个例子，大家体会一下： “这个其实是两个问题” “有没有更好的方案” “能不能举个例子” “能不能给个一句话总结”除了口头禅，很多牛人都会有非常鲜明的思维方式和处事原则，如果有幸与业界的大牛共事，那么恭喜你，只要多交流、多观察、多思考，那么提升速度会提升好几个数量级。 多做有意义的事情有的人每天时间浪费在跟问题本身无关的事情上，比如我要设计架构的时候还要考虑架构图怎么画，写完代码还要反复部署测试好几轮才pass，查bug的时候把时间浪费在扫日志上。人的精力总是有限的，把时间浪费在这些事情上面，让自己提高的时间就变得少了。 练习，更多的练习这里有个误区：“做有意义的事情”不等于“只做自己没做过的事情”。 对于程序员来说，写代码是基本功中的基本功，编码的规范、设计的权衡、甚至顺手的IDE快捷键都要靠平日的试错和积累，很难通过几本书或者几天培训领悟到。 曾经目睹一些人写代码一年之后开始做一些小项目的设计，然后就迫不及待的把重心全都转移到设计甚至架构上，这种没有基础能力支撑做出的设计和架构最多只能算是高级意淫，大多没等落地就荒废了，意义不大。究其原因，大多是设计出来的东西“不好做”或者“不好用”，就像是只看过一遍课本就去参加高数考试，现实吗？（学霸们我错了……） 举个例子，几年前在看设计模式的过程中，用qt做了个看漫画的应用，把能用的模式都试了一遍，当然有很多用的不合适的地方，正是这些不合适的地方让我对面向对象编程和设计模式的思考深入了很多，如何权衡灵活性和复杂性也有了新的认识。之后在设计很多系统的时候少走了很多弯路，既保证了时间点又保证了质量。如果当时指望着“用的时候再说”，大概已经被项目坑的不能自理了。 善用工具工具能解决的事情就用工具去解决，好的工具能节约大把的时间用在更有意义的事情上。 工具的范畴很广，比如linux的各种命令、比如团队内部的各种系统、比如顺手的应用、甚至包括上下班骑的自行车。只要能节约时间、提高效率，那就值得一试。 在这里我列举几个大幅度提升了我的效率的东西： 双屏显示器 顺手的键盘 google（不是baidu！不是bing！） mac mac上的应用：idea、alfread、omnifocus、甚至synergy和istats menus之类跟开发本身关系不大的应用。 我更倾向于把“使用工具”作为一种生活态度：是否希望让自己的生活专注于有意义的事情。如果你认同这个观点，那么想一想投入和回报比例，还是很可观的。 （当然，为了不花钱而自己破解应用的大神也是极叼的……） 提高时间的利用率时间是所有期待提升自己的人最宝贵的资源，效率再高，没时间做也没意义。 网上有个流传挺广的图：打扰程序员的成本。事实上我每天的工作时间非常碎片化，来到公司之后可能不断的接电话、被问问题、被拉去开会、回复邮件等等；也经常会有时间不够用或者没事做的困惑，这里分享一下心得： GTD可以整合很多碎片时间。除了把事做完之外，把上下文相关的事情集中在一起完成也很有帮助。比如把几件想去其他办公室做的事情整合成一趟完成。 减少无意义的时间浪费，比如家住在公司边上可以每天节省几个小时的时间用来学习或者做别的事情。（但如果节省下来的时间用来刷微博，那就没有必要了。） 另外一个很有趣的现象：一个软件的注册费就10几刀，贵些的几百刀，把日常用到的所有工具的费用全加起来都顶不上一个肾6贵，但是很多人还是坚持着没有破解不用的观念，为了几百块钱浪费了大把时间。 加班可以创造很多时间，并且能有效减少被打扰的几率，但是也会给身体和精神带来很大负担。因此加班做的事情必须能对个人进步产生足够多的收益。如果加班只是用来处理无意义的工作的话，那应该是日常工作出了什么问题。 事情可以分成紧急重要、紧急不重要、重要不紧急、不重要不紧急四类，在todo列表里随时要有重要不紧急的事情。 学会思考深究当有什么问题解决不了的时候，很多人会有畏难或者拖延的情绪，典型口头禅就是“就这么凑合着用吧”或者“先这样吧，以后有时间再研究”，说这些话的人大多并不是真的那么忙，甚至有人一边刷着微博一边跟我说没时间研究……(你tm在逗我？) 要克服畏难情绪其实很简单，找一个具体的似懂非懂的问题，想尽办法把问题研究清楚，体会几次解决问题时的愉悦感，建立自信。 大部分问题其实没有什么高深的科学原理，甚至只要翻几页书就解决了，但是遇到问题不深究，久而久之会形成自我暗示：这些问题是我懂的，那些是我不懂的，自己反而把自己进步的路给堵上了。 说到如何深究，也有几条心得： 遇事多想为什么，并且要反复问为什么。很多貌似理解了的问题过一阵再重新想想，往往会发现之前还有没考虑到的地方 问题要有明确答案，哲学之类的就别纠结了 查找资料时选权威的书籍或者网站，避免被误导 找人讨论，或者直接拉小伙伴入伙，既可以互相交流，又可以互相监督 分享你的成果 不要所有事情全都深究，会给自己太多压力 多说，多写，多交流平常工作中有一个感受，有交流和写作习惯的人思路会更清晰一些，能接触到的观点也会多一些。这方面其实属于我的弱项，大概总结几个观点。 隔一段时间最好能书面形式总结一下最近的工作，比如说写个心得感悟，或者持续更新自己的简历 写作的时候有两个难点：对要说明的事情做总结和抽象，形成观点统一、调理清晰的主线；从对方的视角考虑，把事情说明白，避免自言自语。 找人讨论之前自己先要有个基本完整的思路，否则大部分的时间都要耗在解释原理之类的上网查反而更快的事情上。 讨论之后要有一句话就能说明白的结论和描述清晰的时间点。 有些人喜欢纠结于“这个不是我的问题，为什么要我处理”之类的事情。在我看来这是很好的机会。既能增长见识，又能展示水平，还能留个认真负责的好名声，何乐而不为呢。 最后最后分享一下关于我理解的程序员的自我修养，在我看来，可以总结为：负责任，重名声。 负责任，说的更具体些：写的代码自己有没有测过、做的框架自己有没有用过、设计的架构自己有没有认真权衡过。 重名声，说的直接些：没有测过的代码、没有用过的框架、没有权衡过的方案有没有脸交付给别人。 与各位共勉。]]></content>
      <categories>
        <category>life</category>
      </categories>
      <tags>
        <tag>namaste</tag>
      </tags>
  </entry>
</search>
